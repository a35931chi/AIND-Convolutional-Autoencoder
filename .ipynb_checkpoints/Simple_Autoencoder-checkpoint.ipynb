{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Simple Autoencoder\n",
    "\n",
    "We'll start off by building a simple autoencoder to compress the MNIST dataset. With autoencoders, we pass input data through an encoder that makes a compressed representation of the input. Then, this representation is passed through a decoder to reconstruct the input data. Generally the encoder and decoder will be built with neural networks, then trained on example data.\n",
    "\n",
    "![Autoencoder](assets/autoencoder_1.png)\n",
    "\n",
    "In this notebook, we'll be build a simple network architecture for the encoder and decoder. Let's get started by importing our libraries and getting the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', validation_size=0) \n",
    "#the reason for validation_size = 0 is because we are not trying to build a model. \n",
    "#We are trying to figure out how to encode and decode with minimum information loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I'm plotting an example image from the MNIST dataset. These are 28x28 grayscale images of handwritten digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x29c55488b70>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nl5u5+5iuaAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29c55077438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = mnist.train.images[1]\n",
    "plt.imshow(img.reshape((28, 28)), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x29c55705c88>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADQBJREFUeJzt3V2IXPUZx/HfL/ENkoIvwSXaYFKRagm+lEV8o0TbqNVI\n9CLSXJSUqutFhRYqVNKLCrUgxbR4JWxJNBaNKRjJEsRoQzEtVkkimkRtEqspzRqTxoi1F1KTPL2Y\nE9nGnTObmTNzZvf5fmDZmfPMmfNw2N/+z5kzM39HhADkM63uBgDUg/ADSRF+ICnCDyRF+IGkCD+Q\nFOEHkiL8QFKEH0jqlF5uzDZvJwS6LCI8kcd1NPLbvtn2Ltvv2n6gk+cC0Ftu9739tqdL2i1poaR9\nkrZIWhoRb5esw8gPdFkvRv4rJb0bEe9FxH8lPSNpcQfPB6CHOgn/+ZL+Oeb+vmLZ/7E9ZHur7a0d\nbAtAxbr+gl9EDEsaljjsB/pJJyP/qKQ5Y+5/tVgGYBLoJPxbJF1ke57t0yR9T9JINW0B6La2D/sj\n4ojt+yRtlDRd0qqIeKuyzgB0VduX+traGOf8QNf15E0+ACYvwg8kRfiBpAg/kBThB5Ii/EBShB9I\nivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQf\nSIrwA0kRfiApwg8kRfiBpAg/kBThB5Jqe4puSbK9V9Knko5KOhIRg1U0BVRhyZIlTWuPP/546brX\nXnttaf3NN99sq6d+0lH4C9dHxKEKngdAD3HYDyTVafhD0ou2t9keqqIhAL3R6WH/dRExavtcSS/Z\n/ltEbB77gOKfAv8YgD7T0cgfEaPF74OSnpN05TiPGY6IQV4MBPpL2+G3PcP2V47flnSjpJ1VNQag\nuzo57B+Q9Jzt48/zdES8UElXALqu7fBHxHuSLquwl65avHhxaX3WrFml9ZUrV1bZDnrgqquualrb\ns2dPDzvpT1zqA5Ii/EBShB9IivADSRF+ICnCDyRVxaf6JoWFCxeW1ufPn19a51Jf/5k2rXzsuvji\ni5vWBgYGStct3r8ypTHyA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBSjojebczu3cZO8NFHH5XWd+zY\nUVpfsGBBhd2gChdccEFp/f33329ae/nll0vXvf7669vqqR9ExITepMDIDyRF+IGkCD+QFOEHkiL8\nQFKEH0iK8ANJpfk8f6vPfmPyGRkZaXvdnTuZX4ZEAEkRfiApwg8kRfiBpAg/kBThB5Ii/EBSLa/z\n214laZGkgxExv1h2tqS1kuZK2ivpzoj4uHtttlY2HbMkzZgxo0edoFdmzpzZ9robNmyosJPJaSIj\n/xOSbj5h2QOSNkXERZI2FfcBTCItwx8RmyUdPmHxYkmri9urJd1ecV8Auqzdc/6BiNhf3P5QUvnc\nRwD6Tsfv7Y+IKPtuPttDkoY63Q6AarU78h+wPVuSit8Hmz0wIoYjYjAiBtvcFoAuaDf8I5KWFbeX\nSVpfTTsAeqVl+G2vkfRXSV+3vc/2XZIelrTQ9h5J3ynuA5hEWp7zR8TSJqVvV9xLR5YsWVJaP+WU\nNF9dMGWcd955pfVzzz237efevXt32+tOFbzDD0iK8ANJEX4gKcIPJEX4gaQIP5DUlLn+ddlll3W0\n/rZt2yrqBFV5+umnS+utPqZ96NChprVPPvmkrZ6mEkZ+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0hq\nylzn79Srr75adwuT0plnnllaX7q02SfCpbvvvrt03UsvvbStno576KGHmtYOHz7xO2nzYeQHkiL8\nQFKEH0iK8ANJEX4gKcIPJEX4gaS4zl8455xzatv2NddcU1qfPn16aX3RokVNa/PmzStd9/TTTy+t\n33TTTaV126X1I0eONK3t2rWrdN2jR4+W1qdNKx+7Nm/eXFrPjpEfSIrwA0kRfiApwg8kRfiBpAg/\nkBThB5JyRJQ/wF4laZGkgxExv1j2oKR7JP2reNjyiHi+5cbs8o11YP369aX12267rbT+2Weflda7\n+fnvVlNRt3Ls2LGmtc8//7x03Q8++KC0vmXLltL6K6+8UlofGRlpWhsdHS1d9+OPPy6tn3HGGaX1\nrNOyR0T5my8KExn5n5B08zjLfxsRlxc/LYMPoL+0DH9EbJbE154AU0wn5/z32d5ue5XtsyrrCEBP\ntBv+xyRdKOlySfslrWj2QNtDtrfa3trmtgB0QVvhj4gDEXE0Io5J+p2kK0seOxwRgxEx2G6TAKrX\nVvhtzx5z9w5JO6tpB0CvtLwWYnuNpAWSZtneJ+kXkhbYvlxSSNor6d4u9gigC1pe5690Y128zt/K\nI488UlpfsGBBbxppw9q1a0vr27dvb1rbuHFj1e1UZvny5aX1su/dl1q/D6DO72ioU5XX+QFMQYQf\nSIrwA0kRfiApwg8kRfiBpNJ85vH++++vuwWc4NZbb+1o/Q0bNlTUSU6M/EBShB9IivADSRF+ICnC\nDyRF+IGkCD+QVJrr/Jh61qxZU3cLkxojP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBTh\nB5Ii/EBShB9IivADSRF+ICnCDyTV8vP8tudIelLSgKSQNBwRj9o+W9JaSXMl7ZV0Z0SUz5kMnAS7\nfKbpSy65pLT+wgsvVNnOlDORkf+IpJ9GxDckXSXpR7a/IekBSZsi4iJJm4r7ACaJluGPiP0R8Xpx\n+1NJ70g6X9JiSauLh62WdHu3mgRQvZM657c9V9IVkl6TNBAR+4vSh2qcFgCYJCb8HX62Z0p6VtJP\nIuLfY8/HIiJsR5P1hiQNddoogGpNaOS3faoawX8qItYViw/Ynl3UZ0s6ON66ETEcEYMRMVhFwwCq\n0TL8bgzxKyW9ExG/GVMakbSsuL1M0vrq2wPQLRM57L9W0vcl7bD9RrFsuaSHJf3B9l2S/iHpzu60\niKwixj2T/MK0abxNpRMtwx8Rf5HU7ILrt6ttB0Cv8K8TSIrwA0kRfiApwg8kRfiBpAg/kBRTdGPS\nuuGGG0rrK1as6FEnkxMjP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kxXV+9K1WX92NzjDyA0kRfiAp\nwg8kRfiBpAg/kBThB5Ii/EBSXOdHbdatW1dav/rqq3vUSU6M/EBShB9IivADSRF+ICnCDyRF+IGk\nCD+QlFvNgW57jqQnJQ1ICknDEfGo7Qcl3SPpX8VDl0fE8y2eq3xjADoWERP6IoSJhH+2pNkR8brt\nr0jaJul2SXdK+k9EPDLRpgg/0H0TDX/Ld/hFxH5J+4vbn9p+R9L5nbUHoG4ndc5ve66kKyS9Viy6\nz/Z226tsn9VknSHbW21v7ahTAJVqedj/xQPtmZJelvSriFhne0DSITVeB/ilGqcGP2zxHBz2A11W\n2Tm/JNk+VdIGSRsj4jfj1OdK2hAR81s8D+EHumyi4W952O/GV6iulPTO2OAXLwQed4eknSfbJID6\nTOTV/usk/VnSDknHisXLJS2VdLkah/17Jd1bvDhY9lyM/ECXVXrYXxXCD3RfZYf9AKYmwg8kRfiB\npAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFK9nqL7kKR/jLk/q1jWj/q1\nt37tS6K3dlXZ2wUTfWBPP8//pY3bWyNisLYGSvRrb/3al0Rv7aqrNw77gaQIP5BU3eEfrnn7Zfq1\nt37tS6K3dtXSW63n/ADqU/fID6AmtYTf9s22d9l+1/YDdfTQjO29tnfYfqPuKcaKadAO2t45ZtnZ\ntl+yvaf4Pe40aTX19qDt0WLfvWH7lpp6m2P7T7bftv2W7R8Xy2vddyV91bLfen7Yb3u6pN2SFkra\nJ2mLpKUR8XZPG2nC9l5JgxFR+zVh29+S9B9JTx6fDcn2ryUdjoiHi3+cZ0XEz/qktwd1kjM3d6m3\nZjNL/0A17rsqZ7yuQh0j/5WS3o2I9yLiv5KekbS4hj76XkRslnT4hMWLJa0ubq9W44+n55r01hci\nYn9EvF7c/lTS8Zmla913JX3Voo7wny/pn2Pu71N/Tfkdkl60vc32UN3NjGNgzMxIH0oaqLOZcbSc\nubmXTphZum/2XTszXleNF/y+7LqI+Kak70r6UXF425eicc7WT5drHpN0oRrTuO2XtKLOZoqZpZ+V\n9JOI+PfYWp37bpy+atlvdYR/VNKcMfe/WizrCxExWvw+KOk5NU5T+smB45OkFr8P1tzPFyLiQEQc\njYhjkn6nGvddMbP0s5Keioh1xeLa9914fdW13+oI/xZJF9meZ/s0Sd+TNFJDH19ie0bxQoxsz5B0\no/pv9uERScuK28skra+xl//TLzM3N5tZWjXvu76b8Toiev4j6RY1XvH/u6Sf19FDk76+JunN4uet\nunuTtEaNw8DP1Xht5C5J50jaJGmPpD9KOruPevu9GrM5b1cjaLNr6u06NQ7pt0t6o/i5pe59V9JX\nLfuNd/gBSfGCH5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpP4HP6UKl5AU0MsAAAAASUVORK5C\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29c55494a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = mnist.train.images[2]\n",
    "plt.imshow(img.reshape((28, 28)), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll train an autoencoder with these images by flattening them into 784 length vectors. The images from this dataset are already normalized such that the values are between 0 and 1. Let's start by building basically the simplest autoencoder with a **single ReLU hidden layer**. This layer will be used as the compressed representation. Then, the encoder is the input layer and the hidden layer. The decoder is the hidden layer and the output layer. Since the images are normalized between 0 and 1, we need to use a **sigmoid activation on the output layer** to get values matching the input.\n",
    "\n",
    "![Autoencoder architecture](assets/simple_autoencoder.png)\n",
    "\n",
    "\n",
    "> **Exercise:** Build the graph for the autoencoder in the cell below. The input images will be flattened into 784 length vectors. The targets are the same as the inputs. And there should be one hidden layer with a ReLU activation and an output layer with a sigmoid activation. Feel free to use TensorFlow's higher level API, `tf.layers`. For instance, you would use [`tf.layers.dense(inputs, units, activation=tf.nn.relu)`](https://www.tensorflow.org/api_docs/python/tf/layers/dense) to create a fully connected layer with a ReLU activation. The loss should be calculated with the cross-entropy loss, there is a convenient TensorFlow function for this `tf.nn.sigmoid_cross_entropy_with_logits` ([documentation](https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits)). You should note that `tf.nn.sigmoid_cross_entropy_with_logits` takes the logits, but to get the reconstructed images you'll need to pass the logits through the sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of the encoding layer (the hidden layer)\n",
    "encoding_dim = 32 # feel free to change this value, this is how many hidden nodes we have\n",
    "image_size = mnist.train.images.shape[1] #we'll be suing this because we need to provide an input and output dimension\n",
    "# Input and target placeholders\n",
    "inputs_ = tf.placeholder(tf.float32, [None, image_size]) #this is a tf placeholder for inputs\n",
    "targets_ = tf.placeholder(tf.float32, [None, image_size]) #this is a tf placeholder for targets\n",
    "\n",
    "# Output of hidden layer, single fully connected layer here with ReLU activation\n",
    "encoded = tf.layers.dense(inputs_, encoding_dim, activation = tf.nn.relu) #this is to get to the hidden layer\n",
    "#that's why you see that the encoding_dim is implemented here. \n",
    "#note that we didn't use tf.add, tf.matmul, we didn't define and initialize weights or bias. reason being we are using tf.layers.dense, which is a convenent way to skip all that\n",
    "\n",
    "# Output layer logits, fully connected layer with no activation\n",
    "logits = tf.layers.dense(encoded, image_size) #we again used tf.layers.dense. Also note that we didn't specify an activation function\n",
    "#reason being we'll need to use the logits to calculate loss, and we can apply sigmoid separately with another line of code\n",
    "# Sigmoid output from logits\n",
    "decoded = tf.nn.sigmoid(logits)\n",
    "\n",
    "# Sigmoid cross-entropy loss, define loss using cross entropy with logits\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels = targets_, logits = logits)\n",
    "# Mean of the loss, define cost, which is addition of all the loss\n",
    "cost = tf.reduce_mean(loss)\n",
    "\n",
    "# Adam optimizer\n",
    "opt = tf.train.AdamOptimizer(0.001).minimize(cost) #specify optimizer, and things to minimize: cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the session\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I'll write a bit of code to train the network. I'm not too interested in validation here, so I'll just monitor the training loss. \n",
    "\n",
    "Calling `mnist.train.next_batch(batch_size)` will return a tuple of `(images, labels)`. We're not concerned with the labels here, we just need the images. Otherwise this is pretty straightfoward training with TensorFlow. We initialize the variables with `sess.run(tf.global_variables_initializer())`. Then, run the optimizer and get the loss with `batch_cost, _ = sess.run([cost, opt], feed_dict=feed)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20... Training loss: 0.6936\n",
      "Epoch: 1/20... Training loss: 0.6908\n",
      "Epoch: 1/20... Training loss: 0.6879\n",
      "Epoch: 1/20... Training loss: 0.6845\n",
      "Epoch: 1/20... Training loss: 0.6800\n",
      "Epoch: 1/20... Training loss: 0.6741\n",
      "Epoch: 1/20... Training loss: 0.6670\n",
      "Epoch: 1/20... Training loss: 0.6583\n",
      "Epoch: 1/20... Training loss: 0.6500\n",
      "Epoch: 1/20... Training loss: 0.6396\n",
      "Epoch: 1/20... Training loss: 0.6247\n",
      "Epoch: 1/20... Training loss: 0.6120\n",
      "Epoch: 1/20... Training loss: 0.5982\n",
      "Epoch: 1/20... Training loss: 0.5786\n",
      "Epoch: 1/20... Training loss: 0.5660\n",
      "Epoch: 1/20... Training loss: 0.5464\n",
      "Epoch: 1/20... Training loss: 0.5317\n",
      "Epoch: 1/20... Training loss: 0.5088\n",
      "Epoch: 1/20... Training loss: 0.4891\n",
      "Epoch: 1/20... Training loss: 0.4735\n",
      "Epoch: 1/20... Training loss: 0.4526\n",
      "Epoch: 1/20... Training loss: 0.4393\n",
      "Epoch: 1/20... Training loss: 0.4195\n",
      "Epoch: 1/20... Training loss: 0.4045\n",
      "Epoch: 1/20... Training loss: 0.3907\n",
      "Epoch: 1/20... Training loss: 0.3814\n",
      "Epoch: 1/20... Training loss: 0.3704\n",
      "Epoch: 1/20... Training loss: 0.3654\n",
      "Epoch: 1/20... Training loss: 0.3482\n",
      "Epoch: 1/20... Training loss: 0.3367\n",
      "Epoch: 1/20... Training loss: 0.3348\n",
      "Epoch: 1/20... Training loss: 0.3232\n",
      "Epoch: 1/20... Training loss: 0.3299\n",
      "Epoch: 1/20... Training loss: 0.3242\n",
      "Epoch: 1/20... Training loss: 0.3174\n",
      "Epoch: 1/20... Training loss: 0.2995\n",
      "Epoch: 1/20... Training loss: 0.3058\n",
      "Epoch: 1/20... Training loss: 0.3051\n",
      "Epoch: 1/20... Training loss: 0.3032\n",
      "Epoch: 1/20... Training loss: 0.3026\n",
      "Epoch: 1/20... Training loss: 0.2968\n",
      "Epoch: 1/20... Training loss: 0.2947\n",
      "Epoch: 1/20... Training loss: 0.2879\n",
      "Epoch: 1/20... Training loss: 0.2907\n",
      "Epoch: 1/20... Training loss: 0.2891\n",
      "Epoch: 1/20... Training loss: 0.2893\n",
      "Epoch: 1/20... Training loss: 0.2898\n",
      "Epoch: 1/20... Training loss: 0.2843\n",
      "Epoch: 1/20... Training loss: 0.2847\n",
      "Epoch: 1/20... Training loss: 0.2808\n",
      "Epoch: 1/20... Training loss: 0.2805\n",
      "Epoch: 1/20... Training loss: 0.2788\n",
      "Epoch: 1/20... Training loss: 0.2836\n",
      "Epoch: 1/20... Training loss: 0.2833\n",
      "Epoch: 1/20... Training loss: 0.2807\n",
      "Epoch: 1/20... Training loss: 0.2756\n",
      "Epoch: 1/20... Training loss: 0.2806\n",
      "Epoch: 1/20... Training loss: 0.2831\n",
      "Epoch: 1/20... Training loss: 0.2735\n",
      "Epoch: 1/20... Training loss: 0.2727\n",
      "Epoch: 1/20... Training loss: 0.2743\n",
      "Epoch: 1/20... Training loss: 0.2769\n",
      "Epoch: 1/20... Training loss: 0.2754\n",
      "Epoch: 1/20... Training loss: 0.2804\n",
      "Epoch: 1/20... Training loss: 0.2768\n",
      "Epoch: 1/20... Training loss: 0.2716\n",
      "Epoch: 1/20... Training loss: 0.2724\n",
      "Epoch: 1/20... Training loss: 0.2654\n",
      "Epoch: 1/20... Training loss: 0.2670\n",
      "Epoch: 1/20... Training loss: 0.2719\n",
      "Epoch: 1/20... Training loss: 0.2639\n",
      "Epoch: 1/20... Training loss: 0.2620\n",
      "Epoch: 1/20... Training loss: 0.2650\n",
      "Epoch: 1/20... Training loss: 0.2605\n",
      "Epoch: 1/20... Training loss: 0.2574\n",
      "Epoch: 1/20... Training loss: 0.2629\n",
      "Epoch: 1/20... Training loss: 0.2630\n",
      "Epoch: 1/20... Training loss: 0.2648\n",
      "Epoch: 1/20... Training loss: 0.2650\n",
      "Epoch: 1/20... Training loss: 0.2626\n",
      "Epoch: 1/20... Training loss: 0.2585\n",
      "Epoch: 1/20... Training loss: 0.2568\n",
      "Epoch: 1/20... Training loss: 0.2593\n",
      "Epoch: 1/20... Training loss: 0.2569\n",
      "Epoch: 1/20... Training loss: 0.2578\n",
      "Epoch: 1/20... Training loss: 0.2660\n",
      "Epoch: 1/20... Training loss: 0.2519\n",
      "Epoch: 1/20... Training loss: 0.2522\n",
      "Epoch: 1/20... Training loss: 0.2551\n",
      "Epoch: 1/20... Training loss: 0.2464\n",
      "Epoch: 1/20... Training loss: 0.2537\n",
      "Epoch: 1/20... Training loss: 0.2596\n",
      "Epoch: 1/20... Training loss: 0.2488\n",
      "Epoch: 1/20... Training loss: 0.2510\n",
      "Epoch: 1/20... Training loss: 0.2481\n",
      "Epoch: 1/20... Training loss: 0.2457\n",
      "Epoch: 1/20... Training loss: 0.2451\n",
      "Epoch: 1/20... Training loss: 0.2477\n",
      "Epoch: 1/20... Training loss: 0.2528\n",
      "Epoch: 1/20... Training loss: 0.2504\n",
      "Epoch: 1/20... Training loss: 0.2488\n",
      "Epoch: 1/20... Training loss: 0.2444\n",
      "Epoch: 1/20... Training loss: 0.2514\n",
      "Epoch: 1/20... Training loss: 0.2490\n",
      "Epoch: 1/20... Training loss: 0.2460\n",
      "Epoch: 1/20... Training loss: 0.2439\n",
      "Epoch: 1/20... Training loss: 0.2449\n",
      "Epoch: 1/20... Training loss: 0.2421\n",
      "Epoch: 1/20... Training loss: 0.2430\n",
      "Epoch: 1/20... Training loss: 0.2496\n",
      "Epoch: 1/20... Training loss: 0.2377\n",
      "Epoch: 1/20... Training loss: 0.2442\n",
      "Epoch: 1/20... Training loss: 0.2358\n",
      "Epoch: 1/20... Training loss: 0.2393\n",
      "Epoch: 1/20... Training loss: 0.2429\n",
      "Epoch: 1/20... Training loss: 0.2394\n",
      "Epoch: 1/20... Training loss: 0.2359\n",
      "Epoch: 1/20... Training loss: 0.2389\n",
      "Epoch: 1/20... Training loss: 0.2381\n",
      "Epoch: 1/20... Training loss: 0.2326\n",
      "Epoch: 1/20... Training loss: 0.2406\n",
      "Epoch: 1/20... Training loss: 0.2282\n",
      "Epoch: 1/20... Training loss: 0.2348\n",
      "Epoch: 1/20... Training loss: 0.2346\n",
      "Epoch: 1/20... Training loss: 0.2355\n",
      "Epoch: 1/20... Training loss: 0.2305\n",
      "Epoch: 1/20... Training loss: 0.2349\n",
      "Epoch: 1/20... Training loss: 0.2327\n",
      "Epoch: 1/20... Training loss: 0.2289\n",
      "Epoch: 1/20... Training loss: 0.2366\n",
      "Epoch: 1/20... Training loss: 0.2298\n",
      "Epoch: 1/20... Training loss: 0.2331\n",
      "Epoch: 1/20... Training loss: 0.2329\n",
      "Epoch: 1/20... Training loss: 0.2293\n",
      "Epoch: 1/20... Training loss: 0.2339\n",
      "Epoch: 1/20... Training loss: 0.2291\n",
      "Epoch: 1/20... Training loss: 0.2356\n",
      "Epoch: 1/20... Training loss: 0.2299\n",
      "Epoch: 1/20... Training loss: 0.2374\n",
      "Epoch: 1/20... Training loss: 0.2296\n",
      "Epoch: 1/20... Training loss: 0.2265\n",
      "Epoch: 1/20... Training loss: 0.2245\n",
      "Epoch: 1/20... Training loss: 0.2242\n",
      "Epoch: 1/20... Training loss: 0.2209\n",
      "Epoch: 1/20... Training loss: 0.2300\n",
      "Epoch: 1/20... Training loss: 0.2233\n",
      "Epoch: 1/20... Training loss: 0.2222\n",
      "Epoch: 1/20... Training loss: 0.2193\n",
      "Epoch: 1/20... Training loss: 0.2238\n",
      "Epoch: 1/20... Training loss: 0.2252\n",
      "Epoch: 1/20... Training loss: 0.2195\n",
      "Epoch: 1/20... Training loss: 0.2224\n",
      "Epoch: 1/20... Training loss: 0.2248\n",
      "Epoch: 1/20... Training loss: 0.2187\n",
      "Epoch: 1/20... Training loss: 0.2170\n",
      "Epoch: 1/20... Training loss: 0.2195\n",
      "Epoch: 1/20... Training loss: 0.2196\n",
      "Epoch: 1/20... Training loss: 0.2245\n",
      "Epoch: 1/20... Training loss: 0.2160\n",
      "Epoch: 1/20... Training loss: 0.2249\n",
      "Epoch: 1/20... Training loss: 0.2196\n",
      "Epoch: 1/20... Training loss: 0.2134\n",
      "Epoch: 1/20... Training loss: 0.2135\n",
      "Epoch: 1/20... Training loss: 0.2234\n",
      "Epoch: 1/20... Training loss: 0.2140\n",
      "Epoch: 1/20... Training loss: 0.2151\n",
      "Epoch: 1/20... Training loss: 0.2200\n",
      "Epoch: 1/20... Training loss: 0.2147\n",
      "Epoch: 1/20... Training loss: 0.2146\n",
      "Epoch: 1/20... Training loss: 0.2200\n",
      "Epoch: 1/20... Training loss: 0.2122\n",
      "Epoch: 1/20... Training loss: 0.2181\n",
      "Epoch: 1/20... Training loss: 0.2086\n",
      "Epoch: 1/20... Training loss: 0.2112\n",
      "Epoch: 1/20... Training loss: 0.2166\n",
      "Epoch: 1/20... Training loss: 0.2183\n",
      "Epoch: 1/20... Training loss: 0.2122\n",
      "Epoch: 1/20... Training loss: 0.2200\n",
      "Epoch: 1/20... Training loss: 0.2085\n",
      "Epoch: 1/20... Training loss: 0.2233\n",
      "Epoch: 1/20... Training loss: 0.2047\n",
      "Epoch: 1/20... Training loss: 0.2098\n",
      "Epoch: 1/20... Training loss: 0.2135\n",
      "Epoch: 1/20... Training loss: 0.2045\n",
      "Epoch: 1/20... Training loss: 0.2140\n",
      "Epoch: 1/20... Training loss: 0.2071\n",
      "Epoch: 1/20... Training loss: 0.2056\n",
      "Epoch: 1/20... Training loss: 0.2083\n",
      "Epoch: 1/20... Training loss: 0.2092\n",
      "Epoch: 1/20... Training loss: 0.2141\n",
      "Epoch: 1/20... Training loss: 0.1985\n",
      "Epoch: 1/20... Training loss: 0.2033\n",
      "Epoch: 1/20... Training loss: 0.2103\n",
      "Epoch: 1/20... Training loss: 0.2055\n",
      "Epoch: 1/20... Training loss: 0.2002\n",
      "Epoch: 1/20... Training loss: 0.2080\n",
      "Epoch: 1/20... Training loss: 0.2052\n",
      "Epoch: 1/20... Training loss: 0.2026\n",
      "Epoch: 1/20... Training loss: 0.2045\n",
      "Epoch: 1/20... Training loss: 0.2033\n",
      "Epoch: 1/20... Training loss: 0.2087\n",
      "Epoch: 1/20... Training loss: 0.2037\n",
      "Epoch: 1/20... Training loss: 0.2073\n",
      "Epoch: 1/20... Training loss: 0.1975\n",
      "Epoch: 1/20... Training loss: 0.2037\n",
      "Epoch: 1/20... Training loss: 0.2048\n",
      "Epoch: 1/20... Training loss: 0.2001\n",
      "Epoch: 1/20... Training loss: 0.1988\n",
      "Epoch: 1/20... Training loss: 0.2008\n",
      "Epoch: 1/20... Training loss: 0.1992\n",
      "Epoch: 1/20... Training loss: 0.2017\n",
      "Epoch: 1/20... Training loss: 0.2021\n",
      "Epoch: 1/20... Training loss: 0.2031\n",
      "Epoch: 1/20... Training loss: 0.2112\n",
      "Epoch: 1/20... Training loss: 0.1979\n",
      "Epoch: 1/20... Training loss: 0.1969\n",
      "Epoch: 1/20... Training loss: 0.2054\n",
      "Epoch: 1/20... Training loss: 0.2013\n",
      "Epoch: 1/20... Training loss: 0.1961\n",
      "Epoch: 1/20... Training loss: 0.1989\n",
      "Epoch: 1/20... Training loss: 0.1928\n",
      "Epoch: 1/20... Training loss: 0.1958\n",
      "Epoch: 1/20... Training loss: 0.2034\n",
      "Epoch: 1/20... Training loss: 0.1968\n",
      "Epoch: 1/20... Training loss: 0.2037\n",
      "Epoch: 1/20... Training loss: 0.1926\n",
      "Epoch: 1/20... Training loss: 0.1914\n",
      "Epoch: 1/20... Training loss: 0.1942\n",
      "Epoch: 1/20... Training loss: 0.2008\n",
      "Epoch: 1/20... Training loss: 0.1959\n",
      "Epoch: 1/20... Training loss: 0.1937\n",
      "Epoch: 1/20... Training loss: 0.1896\n",
      "Epoch: 1/20... Training loss: 0.1953\n",
      "Epoch: 1/20... Training loss: 0.1933\n",
      "Epoch: 1/20... Training loss: 0.1950\n",
      "Epoch: 1/20... Training loss: 0.1902\n",
      "Epoch: 1/20... Training loss: 0.1900\n",
      "Epoch: 1/20... Training loss: 0.1953\n",
      "Epoch: 1/20... Training loss: 0.1971\n",
      "Epoch: 1/20... Training loss: 0.1925\n",
      "Epoch: 1/20... Training loss: 0.1963\n",
      "Epoch: 1/20... Training loss: 0.1963\n",
      "Epoch: 1/20... Training loss: 0.1893\n",
      "Epoch: 1/20... Training loss: 0.1949\n",
      "Epoch: 1/20... Training loss: 0.1869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20... Training loss: 0.1923\n",
      "Epoch: 1/20... Training loss: 0.1948\n",
      "Epoch: 1/20... Training loss: 0.1883\n",
      "Epoch: 1/20... Training loss: 0.1906\n",
      "Epoch: 1/20... Training loss: 0.1900\n",
      "Epoch: 1/20... Training loss: 0.1861\n",
      "Epoch: 1/20... Training loss: 0.1890\n",
      "Epoch: 1/20... Training loss: 0.1892\n",
      "Epoch: 1/20... Training loss: 0.1879\n",
      "Epoch: 1/20... Training loss: 0.1933\n",
      "Epoch: 1/20... Training loss: 0.1929\n",
      "Epoch: 1/20... Training loss: 0.1877\n",
      "Epoch: 1/20... Training loss: 0.1857\n",
      "Epoch: 1/20... Training loss: 0.1841\n",
      "Epoch: 1/20... Training loss: 0.1876\n",
      "Epoch: 1/20... Training loss: 0.1944\n",
      "Epoch: 1/20... Training loss: 0.1865\n",
      "Epoch: 1/20... Training loss: 0.1910\n",
      "Epoch: 1/20... Training loss: 0.1855\n",
      "Epoch: 1/20... Training loss: 0.1817\n",
      "Epoch: 1/20... Training loss: 0.1791\n",
      "Epoch: 1/20... Training loss: 0.1939\n",
      "Epoch: 1/20... Training loss: 0.1887\n",
      "Epoch: 1/20... Training loss: 0.1852\n",
      "Epoch: 1/20... Training loss: 0.1803\n",
      "Epoch: 1/20... Training loss: 0.1897\n",
      "Epoch: 1/20... Training loss: 0.1772\n",
      "Epoch: 1/20... Training loss: 0.1889\n",
      "Epoch: 1/20... Training loss: 0.1824\n",
      "Epoch: 1/20... Training loss: 0.1806\n",
      "Epoch: 1/20... Training loss: 0.1911\n",
      "Epoch: 1/20... Training loss: 0.1854\n",
      "Epoch: 1/20... Training loss: 0.1870\n",
      "Epoch: 1/20... Training loss: 0.1881\n",
      "Epoch: 1/20... Training loss: 0.1882\n",
      "Epoch: 1/20... Training loss: 0.1846\n",
      "Epoch: 1/20... Training loss: 0.1897\n",
      "Epoch: 1/20... Training loss: 0.1855\n",
      "Epoch: 1/20... Training loss: 0.1844\n",
      "Epoch: 1/20... Training loss: 0.1836\n",
      "Epoch: 1/20... Training loss: 0.1764\n",
      "Epoch: 1/20... Training loss: 0.1871\n",
      "Epoch: 1/20... Training loss: 0.1874\n",
      "Epoch: 1/20... Training loss: 0.1846\n",
      "Epoch: 1/20... Training loss: 0.1790\n",
      "Epoch: 1/20... Training loss: 0.1799\n",
      "Epoch: 1/20... Training loss: 0.1810\n",
      "Epoch: 1/20... Training loss: 0.1772\n",
      "Epoch: 1/20... Training loss: 0.1820\n",
      "Epoch: 1/20... Training loss: 0.1789\n",
      "Epoch: 1/20... Training loss: 0.1810\n",
      "Epoch: 1/20... Training loss: 0.1742\n",
      "Epoch: 1/20... Training loss: 0.1797\n",
      "Epoch: 1/20... Training loss: 0.1823\n",
      "Epoch: 1/20... Training loss: 0.1776\n",
      "Epoch: 2/20... Training loss: 0.1757\n",
      "Epoch: 2/20... Training loss: 0.1817\n",
      "Epoch: 2/20... Training loss: 0.1858\n",
      "Epoch: 2/20... Training loss: 0.1748\n",
      "Epoch: 2/20... Training loss: 0.1753\n",
      "Epoch: 2/20... Training loss: 0.1778\n",
      "Epoch: 2/20... Training loss: 0.1766\n",
      "Epoch: 2/20... Training loss: 0.1830\n",
      "Epoch: 2/20... Training loss: 0.1794\n",
      "Epoch: 2/20... Training loss: 0.1793\n",
      "Epoch: 2/20... Training loss: 0.1767\n",
      "Epoch: 2/20... Training loss: 0.1779\n",
      "Epoch: 2/20... Training loss: 0.1729\n",
      "Epoch: 2/20... Training loss: 0.1741\n",
      "Epoch: 2/20... Training loss: 0.1744\n",
      "Epoch: 2/20... Training loss: 0.1759\n",
      "Epoch: 2/20... Training loss: 0.1778\n",
      "Epoch: 2/20... Training loss: 0.1770\n",
      "Epoch: 2/20... Training loss: 0.1772\n",
      "Epoch: 2/20... Training loss: 0.1731\n",
      "Epoch: 2/20... Training loss: 0.1721\n",
      "Epoch: 2/20... Training loss: 0.1722\n",
      "Epoch: 2/20... Training loss: 0.1757\n",
      "Epoch: 2/20... Training loss: 0.1744\n",
      "Epoch: 2/20... Training loss: 0.1721\n",
      "Epoch: 2/20... Training loss: 0.1783\n",
      "Epoch: 2/20... Training loss: 0.1780\n",
      "Epoch: 2/20... Training loss: 0.1797\n",
      "Epoch: 2/20... Training loss: 0.1765\n",
      "Epoch: 2/20... Training loss: 0.1768\n",
      "Epoch: 2/20... Training loss: 0.1789\n",
      "Epoch: 2/20... Training loss: 0.1715\n",
      "Epoch: 2/20... Training loss: 0.1727\n",
      "Epoch: 2/20... Training loss: 0.1824\n",
      "Epoch: 2/20... Training loss: 0.1766\n",
      "Epoch: 2/20... Training loss: 0.1688\n",
      "Epoch: 2/20... Training loss: 0.1730\n",
      "Epoch: 2/20... Training loss: 0.1692\n",
      "Epoch: 2/20... Training loss: 0.1732\n",
      "Epoch: 2/20... Training loss: 0.1721\n",
      "Epoch: 2/20... Training loss: 0.1650\n",
      "Epoch: 2/20... Training loss: 0.1716\n",
      "Epoch: 2/20... Training loss: 0.1688\n",
      "Epoch: 2/20... Training loss: 0.1759\n",
      "Epoch: 2/20... Training loss: 0.1740\n",
      "Epoch: 2/20... Training loss: 0.1671\n",
      "Epoch: 2/20... Training loss: 0.1720\n",
      "Epoch: 2/20... Training loss: 0.1752\n",
      "Epoch: 2/20... Training loss: 0.1660\n",
      "Epoch: 2/20... Training loss: 0.1684\n",
      "Epoch: 2/20... Training loss: 0.1726\n",
      "Epoch: 2/20... Training loss: 0.1703\n",
      "Epoch: 2/20... Training loss: 0.1654\n",
      "Epoch: 2/20... Training loss: 0.1797\n",
      "Epoch: 2/20... Training loss: 0.1701\n",
      "Epoch: 2/20... Training loss: 0.1704\n",
      "Epoch: 2/20... Training loss: 0.1671\n",
      "Epoch: 2/20... Training loss: 0.1725\n",
      "Epoch: 2/20... Training loss: 0.1717\n",
      "Epoch: 2/20... Training loss: 0.1686\n",
      "Epoch: 2/20... Training loss: 0.1668\n",
      "Epoch: 2/20... Training loss: 0.1717\n",
      "Epoch: 2/20... Training loss: 0.1700\n",
      "Epoch: 2/20... Training loss: 0.1673\n",
      "Epoch: 2/20... Training loss: 0.1696\n",
      "Epoch: 2/20... Training loss: 0.1728\n",
      "Epoch: 2/20... Training loss: 0.1666\n",
      "Epoch: 2/20... Training loss: 0.1714\n",
      "Epoch: 2/20... Training loss: 0.1684\n",
      "Epoch: 2/20... Training loss: 0.1636\n",
      "Epoch: 2/20... Training loss: 0.1689\n",
      "Epoch: 2/20... Training loss: 0.1700\n",
      "Epoch: 2/20... Training loss: 0.1725\n",
      "Epoch: 2/20... Training loss: 0.1668\n",
      "Epoch: 2/20... Training loss: 0.1651\n",
      "Epoch: 2/20... Training loss: 0.1641\n",
      "Epoch: 2/20... Training loss: 0.1666\n",
      "Epoch: 2/20... Training loss: 0.1668\n",
      "Epoch: 2/20... Training loss: 0.1645\n",
      "Epoch: 2/20... Training loss: 0.1631\n",
      "Epoch: 2/20... Training loss: 0.1686\n",
      "Epoch: 2/20... Training loss: 0.1649\n",
      "Epoch: 2/20... Training loss: 0.1707\n",
      "Epoch: 2/20... Training loss: 0.1638\n",
      "Epoch: 2/20... Training loss: 0.1696\n",
      "Epoch: 2/20... Training loss: 0.1692\n",
      "Epoch: 2/20... Training loss: 0.1713\n",
      "Epoch: 2/20... Training loss: 0.1659\n",
      "Epoch: 2/20... Training loss: 0.1723\n",
      "Epoch: 2/20... Training loss: 0.1686\n",
      "Epoch: 2/20... Training loss: 0.1694\n",
      "Epoch: 2/20... Training loss: 0.1684\n",
      "Epoch: 2/20... Training loss: 0.1653\n",
      "Epoch: 2/20... Training loss: 0.1683\n",
      "Epoch: 2/20... Training loss: 0.1688\n",
      "Epoch: 2/20... Training loss: 0.1686\n",
      "Epoch: 2/20... Training loss: 0.1627\n",
      "Epoch: 2/20... Training loss: 0.1734\n",
      "Epoch: 2/20... Training loss: 0.1697\n",
      "Epoch: 2/20... Training loss: 0.1688\n",
      "Epoch: 2/20... Training loss: 0.1612\n",
      "Epoch: 2/20... Training loss: 0.1607\n",
      "Epoch: 2/20... Training loss: 0.1692\n",
      "Epoch: 2/20... Training loss: 0.1662\n",
      "Epoch: 2/20... Training loss: 0.1647\n",
      "Epoch: 2/20... Training loss: 0.1600\n",
      "Epoch: 2/20... Training loss: 0.1685\n",
      "Epoch: 2/20... Training loss: 0.1614\n",
      "Epoch: 2/20... Training loss: 0.1646\n",
      "Epoch: 2/20... Training loss: 0.1647\n",
      "Epoch: 2/20... Training loss: 0.1654\n",
      "Epoch: 2/20... Training loss: 0.1571\n",
      "Epoch: 2/20... Training loss: 0.1620\n",
      "Epoch: 2/20... Training loss: 0.1616\n",
      "Epoch: 2/20... Training loss: 0.1667\n",
      "Epoch: 2/20... Training loss: 0.1630\n",
      "Epoch: 2/20... Training loss: 0.1636\n",
      "Epoch: 2/20... Training loss: 0.1624\n",
      "Epoch: 2/20... Training loss: 0.1609\n",
      "Epoch: 2/20... Training loss: 0.1675\n",
      "Epoch: 2/20... Training loss: 0.1607\n",
      "Epoch: 2/20... Training loss: 0.1649\n",
      "Epoch: 2/20... Training loss: 0.1562\n",
      "Epoch: 2/20... Training loss: 0.1648\n",
      "Epoch: 2/20... Training loss: 0.1616\n",
      "Epoch: 2/20... Training loss: 0.1605\n",
      "Epoch: 2/20... Training loss: 0.1648\n",
      "Epoch: 2/20... Training loss: 0.1654\n",
      "Epoch: 2/20... Training loss: 0.1606\n",
      "Epoch: 2/20... Training loss: 0.1626\n",
      "Epoch: 2/20... Training loss: 0.1668\n",
      "Epoch: 2/20... Training loss: 0.1633\n",
      "Epoch: 2/20... Training loss: 0.1627\n",
      "Epoch: 2/20... Training loss: 0.1614\n",
      "Epoch: 2/20... Training loss: 0.1607\n",
      "Epoch: 2/20... Training loss: 0.1635\n",
      "Epoch: 2/20... Training loss: 0.1628\n",
      "Epoch: 2/20... Training loss: 0.1642\n",
      "Epoch: 2/20... Training loss: 0.1623\n",
      "Epoch: 2/20... Training loss: 0.1607\n",
      "Epoch: 2/20... Training loss: 0.1662\n",
      "Epoch: 2/20... Training loss: 0.1606\n",
      "Epoch: 2/20... Training loss: 0.1678\n",
      "Epoch: 2/20... Training loss: 0.1594\n",
      "Epoch: 2/20... Training loss: 0.1551\n",
      "Epoch: 2/20... Training loss: 0.1628\n",
      "Epoch: 2/20... Training loss: 0.1526\n",
      "Epoch: 2/20... Training loss: 0.1609\n",
      "Epoch: 2/20... Training loss: 0.1621\n",
      "Epoch: 2/20... Training loss: 0.1603\n",
      "Epoch: 2/20... Training loss: 0.1603\n",
      "Epoch: 2/20... Training loss: 0.1573\n",
      "Epoch: 2/20... Training loss: 0.1553\n",
      "Epoch: 2/20... Training loss: 0.1508\n",
      "Epoch: 2/20... Training loss: 0.1578\n",
      "Epoch: 2/20... Training loss: 0.1604\n",
      "Epoch: 2/20... Training loss: 0.1639\n",
      "Epoch: 2/20... Training loss: 0.1551\n",
      "Epoch: 2/20... Training loss: 0.1543\n",
      "Epoch: 2/20... Training loss: 0.1552\n",
      "Epoch: 2/20... Training loss: 0.1602\n",
      "Epoch: 2/20... Training loss: 0.1603\n",
      "Epoch: 2/20... Training loss: 0.1606\n",
      "Epoch: 2/20... Training loss: 0.1626\n",
      "Epoch: 2/20... Training loss: 0.1537\n",
      "Epoch: 2/20... Training loss: 0.1557\n",
      "Epoch: 2/20... Training loss: 0.1592\n",
      "Epoch: 2/20... Training loss: 0.1612\n",
      "Epoch: 2/20... Training loss: 0.1677\n",
      "Epoch: 2/20... Training loss: 0.1622\n",
      "Epoch: 2/20... Training loss: 0.1603\n",
      "Epoch: 2/20... Training loss: 0.1608\n",
      "Epoch: 2/20... Training loss: 0.1517\n",
      "Epoch: 2/20... Training loss: 0.1572\n",
      "Epoch: 2/20... Training loss: 0.1561\n",
      "Epoch: 2/20... Training loss: 0.1573\n",
      "Epoch: 2/20... Training loss: 0.1610\n",
      "Epoch: 2/20... Training loss: 0.1581\n",
      "Epoch: 2/20... Training loss: 0.1533\n",
      "Epoch: 2/20... Training loss: 0.1615\n",
      "Epoch: 2/20... Training loss: 0.1594\n",
      "Epoch: 2/20... Training loss: 0.1565\n",
      "Epoch: 2/20... Training loss: 0.1539\n",
      "Epoch: 2/20... Training loss: 0.1522\n",
      "Epoch: 2/20... Training loss: 0.1575\n",
      "Epoch: 2/20... Training loss: 0.1524\n",
      "Epoch: 2/20... Training loss: 0.1497\n",
      "Epoch: 2/20... Training loss: 0.1534\n",
      "Epoch: 2/20... Training loss: 0.1543\n",
      "Epoch: 2/20... Training loss: 0.1557\n",
      "Epoch: 2/20... Training loss: 0.1534\n",
      "Epoch: 2/20... Training loss: 0.1538\n",
      "Epoch: 2/20... Training loss: 0.1545\n",
      "Epoch: 2/20... Training loss: 0.1584\n",
      "Epoch: 2/20... Training loss: 0.1578\n",
      "Epoch: 2/20... Training loss: 0.1507\n",
      "Epoch: 2/20... Training loss: 0.1569\n",
      "Epoch: 2/20... Training loss: 0.1538\n",
      "Epoch: 2/20... Training loss: 0.1507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/20... Training loss: 0.1569\n",
      "Epoch: 2/20... Training loss: 0.1551\n",
      "Epoch: 2/20... Training loss: 0.1545\n",
      "Epoch: 2/20... Training loss: 0.1543\n",
      "Epoch: 2/20... Training loss: 0.1521\n",
      "Epoch: 2/20... Training loss: 0.1539\n",
      "Epoch: 2/20... Training loss: 0.1507\n",
      "Epoch: 2/20... Training loss: 0.1546\n",
      "Epoch: 2/20... Training loss: 0.1540\n",
      "Epoch: 2/20... Training loss: 0.1500\n",
      "Epoch: 2/20... Training loss: 0.1552\n",
      "Epoch: 2/20... Training loss: 0.1532\n",
      "Epoch: 2/20... Training loss: 0.1579\n",
      "Epoch: 2/20... Training loss: 0.1564\n",
      "Epoch: 2/20... Training loss: 0.1523\n",
      "Epoch: 2/20... Training loss: 0.1526\n",
      "Epoch: 2/20... Training loss: 0.1549\n",
      "Epoch: 2/20... Training loss: 0.1522\n",
      "Epoch: 2/20... Training loss: 0.1515\n",
      "Epoch: 2/20... Training loss: 0.1577\n",
      "Epoch: 2/20... Training loss: 0.1539\n",
      "Epoch: 2/20... Training loss: 0.1483\n",
      "Epoch: 2/20... Training loss: 0.1531\n",
      "Epoch: 2/20... Training loss: 0.1521\n",
      "Epoch: 2/20... Training loss: 0.1516\n",
      "Epoch: 2/20... Training loss: 0.1504\n",
      "Epoch: 2/20... Training loss: 0.1504\n",
      "Epoch: 2/20... Training loss: 0.1509\n",
      "Epoch: 2/20... Training loss: 0.1507\n",
      "Epoch: 2/20... Training loss: 0.1507\n",
      "Epoch: 2/20... Training loss: 0.1516\n",
      "Epoch: 2/20... Training loss: 0.1525\n",
      "Epoch: 2/20... Training loss: 0.1491\n",
      "Epoch: 2/20... Training loss: 0.1474\n",
      "Epoch: 2/20... Training loss: 0.1454\n",
      "Epoch: 2/20... Training loss: 0.1450\n",
      "Epoch: 2/20... Training loss: 0.1472\n",
      "Epoch: 2/20... Training loss: 0.1479\n",
      "Epoch: 2/20... Training loss: 0.1548\n",
      "Epoch: 2/20... Training loss: 0.1561\n",
      "Epoch: 2/20... Training loss: 0.1448\n",
      "Epoch: 2/20... Training loss: 0.1469\n",
      "Epoch: 2/20... Training loss: 0.1561\n",
      "Epoch: 2/20... Training loss: 0.1491\n",
      "Epoch: 2/20... Training loss: 0.1547\n",
      "Epoch: 2/20... Training loss: 0.1576\n",
      "Epoch: 2/20... Training loss: 0.1529\n",
      "Epoch: 2/20... Training loss: 0.1463\n",
      "Epoch: 2/20... Training loss: 0.1520\n",
      "Epoch: 2/20... Training loss: 0.1477\n",
      "Epoch: 2/20... Training loss: 0.1485\n",
      "Epoch: 2/20... Training loss: 0.1490\n",
      "Epoch: 2/20... Training loss: 0.1431\n",
      "Epoch: 2/20... Training loss: 0.1562\n",
      "Epoch: 2/20... Training loss: 0.1525\n",
      "Epoch: 2/20... Training loss: 0.1533\n",
      "Epoch: 2/20... Training loss: 0.1517\n",
      "Epoch: 2/20... Training loss: 0.1482\n",
      "Epoch: 2/20... Training loss: 0.1506\n",
      "Epoch: 2/20... Training loss: 0.1479\n",
      "Epoch: 2/20... Training loss: 0.1540\n",
      "Epoch: 2/20... Training loss: 0.1469\n",
      "Epoch: 2/20... Training loss: 0.1504\n",
      "Epoch: 2/20... Training loss: 0.1461\n",
      "Epoch: 2/20... Training loss: 0.1474\n",
      "Epoch: 2/20... Training loss: 0.1467\n",
      "Epoch: 2/20... Training loss: 0.1490\n",
      "Epoch: 2/20... Training loss: 0.1493\n",
      "Epoch: 2/20... Training loss: 0.1485\n",
      "Epoch: 2/20... Training loss: 0.1487\n",
      "Epoch: 2/20... Training loss: 0.1529\n",
      "Epoch: 2/20... Training loss: 0.1480\n",
      "Epoch: 2/20... Training loss: 0.1442\n",
      "Epoch: 2/20... Training loss: 0.1487\n",
      "Epoch: 2/20... Training loss: 0.1490\n",
      "Epoch: 2/20... Training loss: 0.1486\n",
      "Epoch: 2/20... Training loss: 0.1491\n",
      "Epoch: 2/20... Training loss: 0.1480\n",
      "Epoch: 2/20... Training loss: 0.1453\n",
      "Epoch: 2/20... Training loss: 0.1464\n",
      "Epoch: 2/20... Training loss: 0.1509\n",
      "Epoch: 2/20... Training loss: 0.1478\n",
      "Epoch: 2/20... Training loss: 0.1484\n",
      "Epoch: 2/20... Training loss: 0.1488\n",
      "Epoch: 2/20... Training loss: 0.1489\n",
      "Epoch: 2/20... Training loss: 0.1446\n",
      "Epoch: 2/20... Training loss: 0.1524\n",
      "Epoch: 2/20... Training loss: 0.1489\n",
      "Epoch: 2/20... Training loss: 0.1480\n",
      "Epoch: 2/20... Training loss: 0.1492\n",
      "Epoch: 2/20... Training loss: 0.1446\n",
      "Epoch: 2/20... Training loss: 0.1489\n",
      "Epoch: 2/20... Training loss: 0.1456\n",
      "Epoch: 2/20... Training loss: 0.1521\n",
      "Epoch: 2/20... Training loss: 0.1448\n",
      "Epoch: 2/20... Training loss: 0.1443\n",
      "Epoch: 2/20... Training loss: 0.1436\n",
      "Epoch: 2/20... Training loss: 0.1439\n",
      "Epoch: 2/20... Training loss: 0.1407\n",
      "Epoch: 2/20... Training loss: 0.1432\n",
      "Epoch: 2/20... Training loss: 0.1413\n",
      "Epoch: 3/20... Training loss: 0.1423\n",
      "Epoch: 3/20... Training loss: 0.1492\n",
      "Epoch: 3/20... Training loss: 0.1500\n",
      "Epoch: 3/20... Training loss: 0.1411\n",
      "Epoch: 3/20... Training loss: 0.1398\n",
      "Epoch: 3/20... Training loss: 0.1497\n",
      "Epoch: 3/20... Training loss: 0.1449\n",
      "Epoch: 3/20... Training loss: 0.1462\n",
      "Epoch: 3/20... Training loss: 0.1460\n",
      "Epoch: 3/20... Training loss: 0.1469\n",
      "Epoch: 3/20... Training loss: 0.1452\n",
      "Epoch: 3/20... Training loss: 0.1478\n",
      "Epoch: 3/20... Training loss: 0.1468\n",
      "Epoch: 3/20... Training loss: 0.1458\n",
      "Epoch: 3/20... Training loss: 0.1426\n",
      "Epoch: 3/20... Training loss: 0.1420\n",
      "Epoch: 3/20... Training loss: 0.1437\n",
      "Epoch: 3/20... Training loss: 0.1386\n",
      "Epoch: 3/20... Training loss: 0.1415\n",
      "Epoch: 3/20... Training loss: 0.1421\n",
      "Epoch: 3/20... Training loss: 0.1440\n",
      "Epoch: 3/20... Training loss: 0.1465\n",
      "Epoch: 3/20... Training loss: 0.1492\n",
      "Epoch: 3/20... Training loss: 0.1425\n",
      "Epoch: 3/20... Training loss: 0.1413\n",
      "Epoch: 3/20... Training loss: 0.1454\n",
      "Epoch: 3/20... Training loss: 0.1428\n",
      "Epoch: 3/20... Training loss: 0.1425\n",
      "Epoch: 3/20... Training loss: 0.1433\n",
      "Epoch: 3/20... Training loss: 0.1462\n",
      "Epoch: 3/20... Training loss: 0.1398\n",
      "Epoch: 3/20... Training loss: 0.1426\n",
      "Epoch: 3/20... Training loss: 0.1460\n",
      "Epoch: 3/20... Training loss: 0.1422\n",
      "Epoch: 3/20... Training loss: 0.1455\n",
      "Epoch: 3/20... Training loss: 0.1513\n",
      "Epoch: 3/20... Training loss: 0.1466\n",
      "Epoch: 3/20... Training loss: 0.1417\n",
      "Epoch: 3/20... Training loss: 0.1422\n",
      "Epoch: 3/20... Training loss: 0.1461\n",
      "Epoch: 3/20... Training loss: 0.1378\n",
      "Epoch: 3/20... Training loss: 0.1441\n",
      "Epoch: 3/20... Training loss: 0.1448\n",
      "Epoch: 3/20... Training loss: 0.1416\n",
      "Epoch: 3/20... Training loss: 0.1416\n",
      "Epoch: 3/20... Training loss: 0.1458\n",
      "Epoch: 3/20... Training loss: 0.1435\n",
      "Epoch: 3/20... Training loss: 0.1405\n",
      "Epoch: 3/20... Training loss: 0.1434\n",
      "Epoch: 3/20... Training loss: 0.1418\n",
      "Epoch: 3/20... Training loss: 0.1434\n",
      "Epoch: 3/20... Training loss: 0.1386\n",
      "Epoch: 3/20... Training loss: 0.1379\n",
      "Epoch: 3/20... Training loss: 0.1419\n",
      "Epoch: 3/20... Training loss: 0.1422\n",
      "Epoch: 3/20... Training loss: 0.1389\n",
      "Epoch: 3/20... Training loss: 0.1420\n",
      "Epoch: 3/20... Training loss: 0.1387\n",
      "Epoch: 3/20... Training loss: 0.1399\n",
      "Epoch: 3/20... Training loss: 0.1418\n",
      "Epoch: 3/20... Training loss: 0.1402\n",
      "Epoch: 3/20... Training loss: 0.1426\n",
      "Epoch: 3/20... Training loss: 0.1405\n",
      "Epoch: 3/20... Training loss: 0.1405\n",
      "Epoch: 3/20... Training loss: 0.1428\n",
      "Epoch: 3/20... Training loss: 0.1436\n",
      "Epoch: 3/20... Training loss: 0.1404\n",
      "Epoch: 3/20... Training loss: 0.1378\n",
      "Epoch: 3/20... Training loss: 0.1409\n",
      "Epoch: 3/20... Training loss: 0.1359\n",
      "Epoch: 3/20... Training loss: 0.1393\n",
      "Epoch: 3/20... Training loss: 0.1420\n",
      "Epoch: 3/20... Training loss: 0.1396\n",
      "Epoch: 3/20... Training loss: 0.1371\n",
      "Epoch: 3/20... Training loss: 0.1405\n",
      "Epoch: 3/20... Training loss: 0.1424\n",
      "Epoch: 3/20... Training loss: 0.1386\n",
      "Epoch: 3/20... Training loss: 0.1425\n",
      "Epoch: 3/20... Training loss: 0.1395\n",
      "Epoch: 3/20... Training loss: 0.1376\n",
      "Epoch: 3/20... Training loss: 0.1409\n",
      "Epoch: 3/20... Training loss: 0.1365\n",
      "Epoch: 3/20... Training loss: 0.1384\n",
      "Epoch: 3/20... Training loss: 0.1354\n",
      "Epoch: 3/20... Training loss: 0.1438\n",
      "Epoch: 3/20... Training loss: 0.1328\n",
      "Epoch: 3/20... Training loss: 0.1341\n",
      "Epoch: 3/20... Training loss: 0.1356\n",
      "Epoch: 3/20... Training loss: 0.1367\n",
      "Epoch: 3/20... Training loss: 0.1379\n",
      "Epoch: 3/20... Training loss: 0.1394\n",
      "Epoch: 3/20... Training loss: 0.1435\n",
      "Epoch: 3/20... Training loss: 0.1367\n",
      "Epoch: 3/20... Training loss: 0.1445\n",
      "Epoch: 3/20... Training loss: 0.1408\n",
      "Epoch: 3/20... Training loss: 0.1375\n",
      "Epoch: 3/20... Training loss: 0.1409\n",
      "Epoch: 3/20... Training loss: 0.1356\n",
      "Epoch: 3/20... Training loss: 0.1376\n",
      "Epoch: 3/20... Training loss: 0.1459\n",
      "Epoch: 3/20... Training loss: 0.1415\n",
      "Epoch: 3/20... Training loss: 0.1400\n",
      "Epoch: 3/20... Training loss: 0.1418\n",
      "Epoch: 3/20... Training loss: 0.1395\n",
      "Epoch: 3/20... Training loss: 0.1376\n",
      "Epoch: 3/20... Training loss: 0.1373\n",
      "Epoch: 3/20... Training loss: 0.1342\n",
      "Epoch: 3/20... Training loss: 0.1301\n",
      "Epoch: 3/20... Training loss: 0.1406\n",
      "Epoch: 3/20... Training loss: 0.1424\n",
      "Epoch: 3/20... Training loss: 0.1440\n",
      "Epoch: 3/20... Training loss: 0.1408\n",
      "Epoch: 3/20... Training loss: 0.1331\n",
      "Epoch: 3/20... Training loss: 0.1358\n",
      "Epoch: 3/20... Training loss: 0.1344\n",
      "Epoch: 3/20... Training loss: 0.1432\n",
      "Epoch: 3/20... Training loss: 0.1370\n",
      "Epoch: 3/20... Training loss: 0.1384\n",
      "Epoch: 3/20... Training loss: 0.1373\n",
      "Epoch: 3/20... Training loss: 0.1392\n",
      "Epoch: 3/20... Training loss: 0.1357\n",
      "Epoch: 3/20... Training loss: 0.1346\n",
      "Epoch: 3/20... Training loss: 0.1387\n",
      "Epoch: 3/20... Training loss: 0.1422\n",
      "Epoch: 3/20... Training loss: 0.1366\n",
      "Epoch: 3/20... Training loss: 0.1350\n",
      "Epoch: 3/20... Training loss: 0.1342\n",
      "Epoch: 3/20... Training loss: 0.1364\n",
      "Epoch: 3/20... Training loss: 0.1361\n",
      "Epoch: 3/20... Training loss: 0.1378\n",
      "Epoch: 3/20... Training loss: 0.1341\n",
      "Epoch: 3/20... Training loss: 0.1336\n",
      "Epoch: 3/20... Training loss: 0.1416\n",
      "Epoch: 3/20... Training loss: 0.1354\n",
      "Epoch: 3/20... Training loss: 0.1384\n",
      "Epoch: 3/20... Training loss: 0.1354\n",
      "Epoch: 3/20... Training loss: 0.1410\n",
      "Epoch: 3/20... Training loss: 0.1336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/20... Training loss: 0.1370\n",
      "Epoch: 3/20... Training loss: 0.1382\n",
      "Epoch: 3/20... Training loss: 0.1307\n",
      "Epoch: 3/20... Training loss: 0.1318\n",
      "Epoch: 3/20... Training loss: 0.1354\n",
      "Epoch: 3/20... Training loss: 0.1304\n",
      "Epoch: 3/20... Training loss: 0.1341\n",
      "Epoch: 3/20... Training loss: 0.1397\n",
      "Epoch: 3/20... Training loss: 0.1362\n",
      "Epoch: 3/20... Training loss: 0.1359\n",
      "Epoch: 3/20... Training loss: 0.1373\n",
      "Epoch: 3/20... Training loss: 0.1361\n",
      "Epoch: 3/20... Training loss: 0.1345\n",
      "Epoch: 3/20... Training loss: 0.1347\n",
      "Epoch: 3/20... Training loss: 0.1348\n",
      "Epoch: 3/20... Training loss: 0.1422\n",
      "Epoch: 3/20... Training loss: 0.1349\n",
      "Epoch: 3/20... Training loss: 0.1332\n",
      "Epoch: 3/20... Training loss: 0.1314\n",
      "Epoch: 3/20... Training loss: 0.1328\n",
      "Epoch: 3/20... Training loss: 0.1328\n",
      "Epoch: 3/20... Training loss: 0.1438\n",
      "Epoch: 3/20... Training loss: 0.1373\n",
      "Epoch: 3/20... Training loss: 0.1402\n",
      "Epoch: 3/20... Training loss: 0.1401\n",
      "Epoch: 3/20... Training loss: 0.1368\n",
      "Epoch: 3/20... Training loss: 0.1352\n",
      "Epoch: 3/20... Training loss: 0.1358\n",
      "Epoch: 3/20... Training loss: 0.1389\n",
      "Epoch: 3/20... Training loss: 0.1331\n",
      "Epoch: 3/20... Training loss: 0.1329\n",
      "Epoch: 3/20... Training loss: 0.1293\n",
      "Epoch: 3/20... Training loss: 0.1370\n",
      "Epoch: 3/20... Training loss: 0.1351\n",
      "Epoch: 3/20... Training loss: 0.1279\n",
      "Epoch: 3/20... Training loss: 0.1344\n",
      "Epoch: 3/20... Training loss: 0.1359\n",
      "Epoch: 3/20... Training loss: 0.1355\n",
      "Epoch: 3/20... Training loss: 0.1291\n",
      "Epoch: 3/20... Training loss: 0.1316\n",
      "Epoch: 3/20... Training loss: 0.1318\n",
      "Epoch: 3/20... Training loss: 0.1297\n",
      "Epoch: 3/20... Training loss: 0.1270\n",
      "Epoch: 3/20... Training loss: 0.1333\n",
      "Epoch: 3/20... Training loss: 0.1405\n",
      "Epoch: 3/20... Training loss: 0.1355\n",
      "Epoch: 3/20... Training loss: 0.1331\n",
      "Epoch: 3/20... Training loss: 0.1385\n",
      "Epoch: 3/20... Training loss: 0.1386\n",
      "Epoch: 3/20... Training loss: 0.1283\n",
      "Epoch: 3/20... Training loss: 0.1319\n",
      "Epoch: 3/20... Training loss: 0.1378\n",
      "Epoch: 3/20... Training loss: 0.1315\n",
      "Epoch: 3/20... Training loss: 0.1360\n",
      "Epoch: 3/20... Training loss: 0.1381\n",
      "Epoch: 3/20... Training loss: 0.1314\n",
      "Epoch: 3/20... Training loss: 0.1299\n",
      "Epoch: 3/20... Training loss: 0.1354\n",
      "Epoch: 3/20... Training loss: 0.1293\n",
      "Epoch: 3/20... Training loss: 0.1344\n",
      "Epoch: 3/20... Training loss: 0.1339\n",
      "Epoch: 3/20... Training loss: 0.1333\n",
      "Epoch: 3/20... Training loss: 0.1332\n",
      "Epoch: 3/20... Training loss: 0.1312\n",
      "Epoch: 3/20... Training loss: 0.1341\n",
      "Epoch: 3/20... Training loss: 0.1320\n",
      "Epoch: 3/20... Training loss: 0.1327\n",
      "Epoch: 3/20... Training loss: 0.1350\n",
      "Epoch: 3/20... Training loss: 0.1350\n",
      "Epoch: 3/20... Training loss: 0.1339\n",
      "Epoch: 3/20... Training loss: 0.1305\n",
      "Epoch: 3/20... Training loss: 0.1278\n",
      "Epoch: 3/20... Training loss: 0.1258\n",
      "Epoch: 3/20... Training loss: 0.1297\n",
      "Epoch: 3/20... Training loss: 0.1358\n",
      "Epoch: 3/20... Training loss: 0.1319\n",
      "Epoch: 3/20... Training loss: 0.1317\n",
      "Epoch: 3/20... Training loss: 0.1300\n",
      "Epoch: 3/20... Training loss: 0.1317\n",
      "Epoch: 3/20... Training loss: 0.1324\n",
      "Epoch: 3/20... Training loss: 0.1326\n",
      "Epoch: 3/20... Training loss: 0.1312\n",
      "Epoch: 3/20... Training loss: 0.1359\n",
      "Epoch: 3/20... Training loss: 0.1299\n",
      "Epoch: 3/20... Training loss: 0.1336\n",
      "Epoch: 3/20... Training loss: 0.1265\n",
      "Epoch: 3/20... Training loss: 0.1317\n",
      "Epoch: 3/20... Training loss: 0.1309\n",
      "Epoch: 3/20... Training loss: 0.1320\n",
      "Epoch: 3/20... Training loss: 0.1288\n",
      "Epoch: 3/20... Training loss: 0.1286\n",
      "Epoch: 3/20... Training loss: 0.1300\n",
      "Epoch: 3/20... Training loss: 0.1299\n",
      "Epoch: 3/20... Training loss: 0.1258\n",
      "Epoch: 3/20... Training loss: 0.1341\n",
      "Epoch: 3/20... Training loss: 0.1338\n",
      "Epoch: 3/20... Training loss: 0.1334\n",
      "Epoch: 3/20... Training loss: 0.1338\n",
      "Epoch: 3/20... Training loss: 0.1260\n",
      "Epoch: 3/20... Training loss: 0.1314\n",
      "Epoch: 3/20... Training loss: 0.1339\n",
      "Epoch: 3/20... Training loss: 0.1252\n",
      "Epoch: 3/20... Training loss: 0.1291\n",
      "Epoch: 3/20... Training loss: 0.1283\n",
      "Epoch: 3/20... Training loss: 0.1275\n",
      "Epoch: 3/20... Training loss: 0.1324\n",
      "Epoch: 3/20... Training loss: 0.1301\n",
      "Epoch: 3/20... Training loss: 0.1305\n",
      "Epoch: 3/20... Training loss: 0.1251\n",
      "Epoch: 3/20... Training loss: 0.1270\n",
      "Epoch: 3/20... Training loss: 0.1305\n",
      "Epoch: 3/20... Training loss: 0.1325\n",
      "Epoch: 3/20... Training loss: 0.1300\n",
      "Epoch: 3/20... Training loss: 0.1276\n",
      "Epoch: 3/20... Training loss: 0.1323\n",
      "Epoch: 3/20... Training loss: 0.1322\n",
      "Epoch: 3/20... Training loss: 0.1263\n",
      "Epoch: 3/20... Training loss: 0.1333\n",
      "Epoch: 3/20... Training loss: 0.1297\n",
      "Epoch: 3/20... Training loss: 0.1308\n",
      "Epoch: 3/20... Training loss: 0.1301\n",
      "Epoch: 3/20... Training loss: 0.1255\n",
      "Epoch: 3/20... Training loss: 0.1333\n",
      "Epoch: 3/20... Training loss: 0.1286\n",
      "Epoch: 3/20... Training loss: 0.1301\n",
      "Epoch: 3/20... Training loss: 0.1277\n",
      "Epoch: 3/20... Training loss: 0.1317\n",
      "Epoch: 3/20... Training loss: 0.1278\n",
      "Epoch: 3/20... Training loss: 0.1303\n",
      "Epoch: 3/20... Training loss: 0.1298\n",
      "Epoch: 3/20... Training loss: 0.1257\n",
      "Epoch: 3/20... Training loss: 0.1290\n",
      "Epoch: 3/20... Training loss: 0.1319\n",
      "Epoch: 3/20... Training loss: 0.1245\n",
      "Epoch: 3/20... Training loss: 0.1337\n",
      "Epoch: 3/20... Training loss: 0.1299\n",
      "Epoch: 3/20... Training loss: 0.1266\n",
      "Epoch: 3/20... Training loss: 0.1297\n",
      "Epoch: 3/20... Training loss: 0.1333\n",
      "Epoch: 3/20... Training loss: 0.1292\n",
      "Epoch: 3/20... Training loss: 0.1334\n",
      "Epoch: 3/20... Training loss: 0.1286\n",
      "Epoch: 3/20... Training loss: 0.1283\n",
      "Epoch: 3/20... Training loss: 0.1307\n",
      "Epoch: 3/20... Training loss: 0.1270\n",
      "Epoch: 3/20... Training loss: 0.1256\n",
      "Epoch: 3/20... Training loss: 0.1287\n",
      "Epoch: 3/20... Training loss: 0.1290\n",
      "Epoch: 3/20... Training loss: 0.1293\n",
      "Epoch: 3/20... Training loss: 0.1298\n",
      "Epoch: 3/20... Training loss: 0.1284\n",
      "Epoch: 3/20... Training loss: 0.1258\n",
      "Epoch: 3/20... Training loss: 0.1314\n",
      "Epoch: 3/20... Training loss: 0.1306\n",
      "Epoch: 3/20... Training loss: 0.1268\n",
      "Epoch: 3/20... Training loss: 0.1284\n",
      "Epoch: 3/20... Training loss: 0.1254\n",
      "Epoch: 3/20... Training loss: 0.1243\n",
      "Epoch: 3/20... Training loss: 0.1274\n",
      "Epoch: 3/20... Training loss: 0.1309\n",
      "Epoch: 3/20... Training loss: 0.1223\n",
      "Epoch: 3/20... Training loss: 0.1274\n",
      "Epoch: 4/20... Training loss: 0.1272\n",
      "Epoch: 4/20... Training loss: 0.1264\n",
      "Epoch: 4/20... Training loss: 0.1232\n",
      "Epoch: 4/20... Training loss: 0.1290\n",
      "Epoch: 4/20... Training loss: 0.1287\n",
      "Epoch: 4/20... Training loss: 0.1283\n",
      "Epoch: 4/20... Training loss: 0.1257\n",
      "Epoch: 4/20... Training loss: 0.1260\n",
      "Epoch: 4/20... Training loss: 0.1307\n",
      "Epoch: 4/20... Training loss: 0.1265\n",
      "Epoch: 4/20... Training loss: 0.1326\n",
      "Epoch: 4/20... Training loss: 0.1312\n",
      "Epoch: 4/20... Training loss: 0.1321\n",
      "Epoch: 4/20... Training loss: 0.1270\n",
      "Epoch: 4/20... Training loss: 0.1278\n",
      "Epoch: 4/20... Training loss: 0.1260\n",
      "Epoch: 4/20... Training loss: 0.1225\n",
      "Epoch: 4/20... Training loss: 0.1284\n",
      "Epoch: 4/20... Training loss: 0.1291\n",
      "Epoch: 4/20... Training loss: 0.1229\n",
      "Epoch: 4/20... Training loss: 0.1352\n",
      "Epoch: 4/20... Training loss: 0.1324\n",
      "Epoch: 4/20... Training loss: 0.1281\n",
      "Epoch: 4/20... Training loss: 0.1311\n",
      "Epoch: 4/20... Training loss: 0.1258\n",
      "Epoch: 4/20... Training loss: 0.1252\n",
      "Epoch: 4/20... Training loss: 0.1278\n",
      "Epoch: 4/20... Training loss: 0.1290\n",
      "Epoch: 4/20... Training loss: 0.1256\n",
      "Epoch: 4/20... Training loss: 0.1298\n",
      "Epoch: 4/20... Training loss: 0.1255\n",
      "Epoch: 4/20... Training loss: 0.1289\n",
      "Epoch: 4/20... Training loss: 0.1206\n",
      "Epoch: 4/20... Training loss: 0.1304\n",
      "Epoch: 4/20... Training loss: 0.1277\n",
      "Epoch: 4/20... Training loss: 0.1287\n",
      "Epoch: 4/20... Training loss: 0.1185\n",
      "Epoch: 4/20... Training loss: 0.1243\n",
      "Epoch: 4/20... Training loss: 0.1263\n",
      "Epoch: 4/20... Training loss: 0.1278\n",
      "Epoch: 4/20... Training loss: 0.1281\n",
      "Epoch: 4/20... Training loss: 0.1209\n",
      "Epoch: 4/20... Training loss: 0.1250\n",
      "Epoch: 4/20... Training loss: 0.1294\n",
      "Epoch: 4/20... Training loss: 0.1269\n",
      "Epoch: 4/20... Training loss: 0.1203\n",
      "Epoch: 4/20... Training loss: 0.1242\n",
      "Epoch: 4/20... Training loss: 0.1276\n",
      "Epoch: 4/20... Training loss: 0.1276\n",
      "Epoch: 4/20... Training loss: 0.1245\n",
      "Epoch: 4/20... Training loss: 0.1221\n",
      "Epoch: 4/20... Training loss: 0.1247\n",
      "Epoch: 4/20... Training loss: 0.1256\n",
      "Epoch: 4/20... Training loss: 0.1272\n",
      "Epoch: 4/20... Training loss: 0.1279\n",
      "Epoch: 4/20... Training loss: 0.1246\n",
      "Epoch: 4/20... Training loss: 0.1258\n",
      "Epoch: 4/20... Training loss: 0.1258\n",
      "Epoch: 4/20... Training loss: 0.1294\n",
      "Epoch: 4/20... Training loss: 0.1239\n",
      "Epoch: 4/20... Training loss: 0.1266\n",
      "Epoch: 4/20... Training loss: 0.1236\n",
      "Epoch: 4/20... Training loss: 0.1282\n",
      "Epoch: 4/20... Training loss: 0.1238\n",
      "Epoch: 4/20... Training loss: 0.1205\n",
      "Epoch: 4/20... Training loss: 0.1266\n",
      "Epoch: 4/20... Training loss: 0.1227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/20... Training loss: 0.1263\n",
      "Epoch: 4/20... Training loss: 0.1280\n",
      "Epoch: 4/20... Training loss: 0.1266\n",
      "Epoch: 4/20... Training loss: 0.1217\n",
      "Epoch: 4/20... Training loss: 0.1286\n",
      "Epoch: 4/20... Training loss: 0.1216\n",
      "Epoch: 4/20... Training loss: 0.1294\n",
      "Epoch: 4/20... Training loss: 0.1246\n",
      "Epoch: 4/20... Training loss: 0.1218\n",
      "Epoch: 4/20... Training loss: 0.1286\n",
      "Epoch: 4/20... Training loss: 0.1312\n",
      "Epoch: 4/20... Training loss: 0.1169\n",
      "Epoch: 4/20... Training loss: 0.1296\n",
      "Epoch: 4/20... Training loss: 0.1254\n",
      "Epoch: 4/20... Training loss: 0.1321\n",
      "Epoch: 4/20... Training loss: 0.1218\n",
      "Epoch: 4/20... Training loss: 0.1249\n",
      "Epoch: 4/20... Training loss: 0.1275\n",
      "Epoch: 4/20... Training loss: 0.1266\n",
      "Epoch: 4/20... Training loss: 0.1222\n",
      "Epoch: 4/20... Training loss: 0.1238\n",
      "Epoch: 4/20... Training loss: 0.1262\n",
      "Epoch: 4/20... Training loss: 0.1239\n",
      "Epoch: 4/20... Training loss: 0.1212\n",
      "Epoch: 4/20... Training loss: 0.1265\n",
      "Epoch: 4/20... Training loss: 0.1285\n",
      "Epoch: 4/20... Training loss: 0.1212\n",
      "Epoch: 4/20... Training loss: 0.1214\n",
      "Epoch: 4/20... Training loss: 0.1221\n",
      "Epoch: 4/20... Training loss: 0.1234\n",
      "Epoch: 4/20... Training loss: 0.1236\n",
      "Epoch: 4/20... Training loss: 0.1182\n",
      "Epoch: 4/20... Training loss: 0.1203\n",
      "Epoch: 4/20... Training loss: 0.1251\n",
      "Epoch: 4/20... Training loss: 0.1227\n",
      "Epoch: 4/20... Training loss: 0.1231\n",
      "Epoch: 4/20... Training loss: 0.1231\n",
      "Epoch: 4/20... Training loss: 0.1274\n",
      "Epoch: 4/20... Training loss: 0.1222\n",
      "Epoch: 4/20... Training loss: 0.1232\n",
      "Epoch: 4/20... Training loss: 0.1218\n",
      "Epoch: 4/20... Training loss: 0.1237\n",
      "Epoch: 4/20... Training loss: 0.1251\n",
      "Epoch: 4/20... Training loss: 0.1286\n",
      "Epoch: 4/20... Training loss: 0.1218\n",
      "Epoch: 4/20... Training loss: 0.1239\n",
      "Epoch: 4/20... Training loss: 0.1222\n",
      "Epoch: 4/20... Training loss: 0.1247\n",
      "Epoch: 4/20... Training loss: 0.1186\n",
      "Epoch: 4/20... Training loss: 0.1218\n",
      "Epoch: 4/20... Training loss: 0.1235\n",
      "Epoch: 4/20... Training loss: 0.1262\n",
      "Epoch: 4/20... Training loss: 0.1238\n",
      "Epoch: 4/20... Training loss: 0.1240\n",
      "Epoch: 4/20... Training loss: 0.1198\n",
      "Epoch: 4/20... Training loss: 0.1276\n",
      "Epoch: 4/20... Training loss: 0.1194\n",
      "Epoch: 4/20... Training loss: 0.1203\n",
      "Epoch: 4/20... Training loss: 0.1235\n",
      "Epoch: 4/20... Training loss: 0.1212\n",
      "Epoch: 4/20... Training loss: 0.1200\n",
      "Epoch: 4/20... Training loss: 0.1202\n",
      "Epoch: 4/20... Training loss: 0.1232\n",
      "Epoch: 4/20... Training loss: 0.1270\n",
      "Epoch: 4/20... Training loss: 0.1206\n",
      "Epoch: 4/20... Training loss: 0.1217\n",
      "Epoch: 4/20... Training loss: 0.1223\n",
      "Epoch: 4/20... Training loss: 0.1206\n",
      "Epoch: 4/20... Training loss: 0.1239\n",
      "Epoch: 4/20... Training loss: 0.1238\n",
      "Epoch: 4/20... Training loss: 0.1235\n",
      "Epoch: 4/20... Training loss: 0.1219\n",
      "Epoch: 4/20... Training loss: 0.1234\n",
      "Epoch: 4/20... Training loss: 0.1255\n",
      "Epoch: 4/20... Training loss: 0.1244\n",
      "Epoch: 4/20... Training loss: 0.1180\n",
      "Epoch: 4/20... Training loss: 0.1237\n",
      "Epoch: 4/20... Training loss: 0.1228\n",
      "Epoch: 4/20... Training loss: 0.1189\n",
      "Epoch: 4/20... Training loss: 0.1214\n",
      "Epoch: 4/20... Training loss: 0.1183\n",
      "Epoch: 4/20... Training loss: 0.1178\n",
      "Epoch: 4/20... Training loss: 0.1235\n",
      "Epoch: 4/20... Training loss: 0.1171\n",
      "Epoch: 4/20... Training loss: 0.1203\n",
      "Epoch: 4/20... Training loss: 0.1209\n",
      "Epoch: 4/20... Training loss: 0.1209\n",
      "Epoch: 4/20... Training loss: 0.1197\n",
      "Epoch: 4/20... Training loss: 0.1234\n",
      "Epoch: 4/20... Training loss: 0.1268\n",
      "Epoch: 4/20... Training loss: 0.1237\n",
      "Epoch: 4/20... Training loss: 0.1210\n",
      "Epoch: 4/20... Training loss: 0.1190\n",
      "Epoch: 4/20... Training loss: 0.1210\n",
      "Epoch: 4/20... Training loss: 0.1192\n",
      "Epoch: 4/20... Training loss: 0.1245\n",
      "Epoch: 4/20... Training loss: 0.1143\n",
      "Epoch: 4/20... Training loss: 0.1209\n",
      "Epoch: 4/20... Training loss: 0.1197\n",
      "Epoch: 4/20... Training loss: 0.1184\n",
      "Epoch: 4/20... Training loss: 0.1204\n",
      "Epoch: 4/20... Training loss: 0.1230\n",
      "Epoch: 4/20... Training loss: 0.1167\n",
      "Epoch: 4/20... Training loss: 0.1185\n",
      "Epoch: 4/20... Training loss: 0.1236\n",
      "Epoch: 4/20... Training loss: 0.1211\n",
      "Epoch: 4/20... Training loss: 0.1138\n",
      "Epoch: 4/20... Training loss: 0.1194\n",
      "Epoch: 4/20... Training loss: 0.1205\n",
      "Epoch: 4/20... Training loss: 0.1171\n",
      "Epoch: 4/20... Training loss: 0.1219\n",
      "Epoch: 4/20... Training loss: 0.1261\n",
      "Epoch: 4/20... Training loss: 0.1203\n",
      "Epoch: 4/20... Training loss: 0.1234\n",
      "Epoch: 4/20... Training loss: 0.1229\n",
      "Epoch: 4/20... Training loss: 0.1227\n",
      "Epoch: 4/20... Training loss: 0.1182\n",
      "Epoch: 4/20... Training loss: 0.1197\n",
      "Epoch: 4/20... Training loss: 0.1226\n",
      "Epoch: 4/20... Training loss: 0.1171\n",
      "Epoch: 4/20... Training loss: 0.1177\n",
      "Epoch: 4/20... Training loss: 0.1190\n",
      "Epoch: 4/20... Training loss: 0.1212\n",
      "Epoch: 4/20... Training loss: 0.1204\n",
      "Epoch: 4/20... Training loss: 0.1226\n",
      "Epoch: 4/20... Training loss: 0.1189\n",
      "Epoch: 4/20... Training loss: 0.1203\n",
      "Epoch: 4/20... Training loss: 0.1233\n",
      "Epoch: 4/20... Training loss: 0.1225\n",
      "Epoch: 4/20... Training loss: 0.1211\n",
      "Epoch: 4/20... Training loss: 0.1211\n",
      "Epoch: 4/20... Training loss: 0.1180\n",
      "Epoch: 4/20... Training loss: 0.1160\n",
      "Epoch: 4/20... Training loss: 0.1128\n",
      "Epoch: 4/20... Training loss: 0.1222\n",
      "Epoch: 4/20... Training loss: 0.1157\n",
      "Epoch: 4/20... Training loss: 0.1222\n",
      "Epoch: 4/20... Training loss: 0.1184\n",
      "Epoch: 4/20... Training loss: 0.1187\n",
      "Epoch: 4/20... Training loss: 0.1221\n",
      "Epoch: 4/20... Training loss: 0.1188\n",
      "Epoch: 4/20... Training loss: 0.1207\n",
      "Epoch: 4/20... Training loss: 0.1187\n",
      "Epoch: 4/20... Training loss: 0.1212\n",
      "Epoch: 4/20... Training loss: 0.1145\n",
      "Epoch: 4/20... Training loss: 0.1229\n",
      "Epoch: 4/20... Training loss: 0.1216\n",
      "Epoch: 4/20... Training loss: 0.1204\n",
      "Epoch: 4/20... Training loss: 0.1205\n",
      "Epoch: 4/20... Training loss: 0.1210\n",
      "Epoch: 4/20... Training loss: 0.1179\n",
      "Epoch: 4/20... Training loss: 0.1201\n",
      "Epoch: 4/20... Training loss: 0.1202\n",
      "Epoch: 4/20... Training loss: 0.1187\n",
      "Epoch: 4/20... Training loss: 0.1227\n",
      "Epoch: 4/20... Training loss: 0.1187\n",
      "Epoch: 4/20... Training loss: 0.1222\n",
      "Epoch: 4/20... Training loss: 0.1173\n",
      "Epoch: 4/20... Training loss: 0.1204\n",
      "Epoch: 4/20... Training loss: 0.1206\n",
      "Epoch: 4/20... Training loss: 0.1249\n",
      "Epoch: 4/20... Training loss: 0.1204\n",
      "Epoch: 4/20... Training loss: 0.1212\n",
      "Epoch: 4/20... Training loss: 0.1164\n",
      "Epoch: 4/20... Training loss: 0.1194\n",
      "Epoch: 4/20... Training loss: 0.1157\n",
      "Epoch: 4/20... Training loss: 0.1175\n",
      "Epoch: 4/20... Training loss: 0.1155\n",
      "Epoch: 4/20... Training loss: 0.1199\n",
      "Epoch: 4/20... Training loss: 0.1181\n",
      "Epoch: 4/20... Training loss: 0.1202\n",
      "Epoch: 4/20... Training loss: 0.1185\n",
      "Epoch: 4/20... Training loss: 0.1166\n",
      "Epoch: 4/20... Training loss: 0.1166\n",
      "Epoch: 4/20... Training loss: 0.1205\n",
      "Epoch: 4/20... Training loss: 0.1141\n",
      "Epoch: 4/20... Training loss: 0.1141\n",
      "Epoch: 4/20... Training loss: 0.1184\n",
      "Epoch: 4/20... Training loss: 0.1153\n",
      "Epoch: 4/20... Training loss: 0.1192\n",
      "Epoch: 4/20... Training loss: 0.1213\n",
      "Epoch: 4/20... Training loss: 0.1183\n",
      "Epoch: 4/20... Training loss: 0.1160\n",
      "Epoch: 4/20... Training loss: 0.1142\n",
      "Epoch: 4/20... Training loss: 0.1194\n",
      "Epoch: 4/20... Training loss: 0.1224\n",
      "Epoch: 4/20... Training loss: 0.1183\n",
      "Epoch: 4/20... Training loss: 0.1180\n",
      "Epoch: 4/20... Training loss: 0.1149\n",
      "Epoch: 4/20... Training loss: 0.1175\n",
      "Epoch: 4/20... Training loss: 0.1196\n",
      "Epoch: 4/20... Training loss: 0.1166\n",
      "Epoch: 4/20... Training loss: 0.1123\n",
      "Epoch: 4/20... Training loss: 0.1199\n",
      "Epoch: 4/20... Training loss: 0.1147\n",
      "Epoch: 4/20... Training loss: 0.1140\n",
      "Epoch: 4/20... Training loss: 0.1162\n",
      "Epoch: 4/20... Training loss: 0.1075\n",
      "Epoch: 4/20... Training loss: 0.1188\n",
      "Epoch: 4/20... Training loss: 0.1167\n",
      "Epoch: 4/20... Training loss: 0.1224\n",
      "Epoch: 4/20... Training loss: 0.1153\n",
      "Epoch: 4/20... Training loss: 0.1200\n",
      "Epoch: 4/20... Training loss: 0.1139\n",
      "Epoch: 4/20... Training loss: 0.1195\n",
      "Epoch: 4/20... Training loss: 0.1225\n",
      "Epoch: 4/20... Training loss: 0.1153\n",
      "Epoch: 4/20... Training loss: 0.1136\n",
      "Epoch: 4/20... Training loss: 0.1180\n",
      "Epoch: 4/20... Training loss: 0.1160\n",
      "Epoch: 4/20... Training loss: 0.1170\n",
      "Epoch: 4/20... Training loss: 0.1176\n",
      "Epoch: 4/20... Training loss: 0.1203\n",
      "Epoch: 4/20... Training loss: 0.1153\n",
      "Epoch: 4/20... Training loss: 0.1137\n",
      "Epoch: 4/20... Training loss: 0.1210\n",
      "Epoch: 4/20... Training loss: 0.1216\n",
      "Epoch: 4/20... Training loss: 0.1145\n",
      "Epoch: 4/20... Training loss: 0.1141\n",
      "Epoch: 4/20... Training loss: 0.1158\n",
      "Epoch: 4/20... Training loss: 0.1114\n",
      "Epoch: 4/20... Training loss: 0.1124\n",
      "Epoch: 4/20... Training loss: 0.1184\n",
      "Epoch: 4/20... Training loss: 0.1190\n",
      "Epoch: 4/20... Training loss: 0.1131\n",
      "Epoch: 4/20... Training loss: 0.1159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/20... Training loss: 0.1169\n",
      "Epoch: 4/20... Training loss: 0.1174\n",
      "Epoch: 4/20... Training loss: 0.1133\n",
      "Epoch: 4/20... Training loss: 0.1194\n",
      "Epoch: 4/20... Training loss: 0.1131\n",
      "Epoch: 4/20... Training loss: 0.1131\n",
      "Epoch: 4/20... Training loss: 0.1157\n",
      "Epoch: 5/20... Training loss: 0.1153\n",
      "Epoch: 5/20... Training loss: 0.1184\n",
      "Epoch: 5/20... Training loss: 0.1195\n",
      "Epoch: 5/20... Training loss: 0.1191\n",
      "Epoch: 5/20... Training loss: 0.1167\n",
      "Epoch: 5/20... Training loss: 0.1209\n",
      "Epoch: 5/20... Training loss: 0.1157\n",
      "Epoch: 5/20... Training loss: 0.1189\n",
      "Epoch: 5/20... Training loss: 0.1172\n",
      "Epoch: 5/20... Training loss: 0.1188\n",
      "Epoch: 5/20... Training loss: 0.1174\n",
      "Epoch: 5/20... Training loss: 0.1143\n",
      "Epoch: 5/20... Training loss: 0.1194\n",
      "Epoch: 5/20... Training loss: 0.1127\n",
      "Epoch: 5/20... Training loss: 0.1156\n",
      "Epoch: 5/20... Training loss: 0.1197\n",
      "Epoch: 5/20... Training loss: 0.1197\n",
      "Epoch: 5/20... Training loss: 0.1140\n",
      "Epoch: 5/20... Training loss: 0.1133\n",
      "Epoch: 5/20... Training loss: 0.1134\n",
      "Epoch: 5/20... Training loss: 0.1184\n",
      "Epoch: 5/20... Training loss: 0.1176\n",
      "Epoch: 5/20... Training loss: 0.1212\n",
      "Epoch: 5/20... Training loss: 0.1111\n",
      "Epoch: 5/20... Training loss: 0.1154\n",
      "Epoch: 5/20... Training loss: 0.1138\n",
      "Epoch: 5/20... Training loss: 0.1199\n",
      "Epoch: 5/20... Training loss: 0.1141\n",
      "Epoch: 5/20... Training loss: 0.1115\n",
      "Epoch: 5/20... Training loss: 0.1157\n",
      "Epoch: 5/20... Training loss: 0.1200\n",
      "Epoch: 5/20... Training loss: 0.1139\n",
      "Epoch: 5/20... Training loss: 0.1159\n",
      "Epoch: 5/20... Training loss: 0.1182\n",
      "Epoch: 5/20... Training loss: 0.1149\n",
      "Epoch: 5/20... Training loss: 0.1145\n",
      "Epoch: 5/20... Training loss: 0.1165\n",
      "Epoch: 5/20... Training loss: 0.1141\n",
      "Epoch: 5/20... Training loss: 0.1188\n",
      "Epoch: 5/20... Training loss: 0.1190\n",
      "Epoch: 5/20... Training loss: 0.1148\n",
      "Epoch: 5/20... Training loss: 0.1163\n",
      "Epoch: 5/20... Training loss: 0.1209\n",
      "Epoch: 5/20... Training loss: 0.1151\n",
      "Epoch: 5/20... Training loss: 0.1143\n",
      "Epoch: 5/20... Training loss: 0.1149\n",
      "Epoch: 5/20... Training loss: 0.1142\n",
      "Epoch: 5/20... Training loss: 0.1132\n",
      "Epoch: 5/20... Training loss: 0.1155\n",
      "Epoch: 5/20... Training loss: 0.1198\n",
      "Epoch: 5/20... Training loss: 0.1133\n",
      "Epoch: 5/20... Training loss: 0.1125\n",
      "Epoch: 5/20... Training loss: 0.1168\n",
      "Epoch: 5/20... Training loss: 0.1150\n",
      "Epoch: 5/20... Training loss: 0.1120\n",
      "Epoch: 5/20... Training loss: 0.1194\n",
      "Epoch: 5/20... Training loss: 0.1118\n",
      "Epoch: 5/20... Training loss: 0.1126\n",
      "Epoch: 5/20... Training loss: 0.1176\n",
      "Epoch: 5/20... Training loss: 0.1137\n",
      "Epoch: 5/20... Training loss: 0.1162\n",
      "Epoch: 5/20... Training loss: 0.1142\n",
      "Epoch: 5/20... Training loss: 0.1115\n",
      "Epoch: 5/20... Training loss: 0.1086\n",
      "Epoch: 5/20... Training loss: 0.1144\n",
      "Epoch: 5/20... Training loss: 0.1108\n",
      "Epoch: 5/20... Training loss: 0.1192\n",
      "Epoch: 5/20... Training loss: 0.1117\n",
      "Epoch: 5/20... Training loss: 0.1175\n",
      "Epoch: 5/20... Training loss: 0.1150\n",
      "Epoch: 5/20... Training loss: 0.1199\n",
      "Epoch: 5/20... Training loss: 0.1154\n",
      "Epoch: 5/20... Training loss: 0.1138\n",
      "Epoch: 5/20... Training loss: 0.1157\n",
      "Epoch: 5/20... Training loss: 0.1138\n",
      "Epoch: 5/20... Training loss: 0.1142\n",
      "Epoch: 5/20... Training loss: 0.1144\n",
      "Epoch: 5/20... Training loss: 0.1143\n",
      "Epoch: 5/20... Training loss: 0.1092\n",
      "Epoch: 5/20... Training loss: 0.1117\n",
      "Epoch: 5/20... Training loss: 0.1121\n",
      "Epoch: 5/20... Training loss: 0.1123\n",
      "Epoch: 5/20... Training loss: 0.1107\n",
      "Epoch: 5/20... Training loss: 0.1163\n",
      "Epoch: 5/20... Training loss: 0.1125\n",
      "Epoch: 5/20... Training loss: 0.1184\n",
      "Epoch: 5/20... Training loss: 0.1111\n",
      "Epoch: 5/20... Training loss: 0.1133\n",
      "Epoch: 5/20... Training loss: 0.1115\n",
      "Epoch: 5/20... Training loss: 0.1173\n",
      "Epoch: 5/20... Training loss: 0.1136\n",
      "Epoch: 5/20... Training loss: 0.1136\n",
      "Epoch: 5/20... Training loss: 0.1137\n",
      "Epoch: 5/20... Training loss: 0.1122\n",
      "Epoch: 5/20... Training loss: 0.1135\n",
      "Epoch: 5/20... Training loss: 0.1099\n",
      "Epoch: 5/20... Training loss: 0.1111\n",
      "Epoch: 5/20... Training loss: 0.1147\n",
      "Epoch: 5/20... Training loss: 0.1155\n",
      "Epoch: 5/20... Training loss: 0.1126\n",
      "Epoch: 5/20... Training loss: 0.1120\n",
      "Epoch: 5/20... Training loss: 0.1139\n",
      "Epoch: 5/20... Training loss: 0.1124\n",
      "Epoch: 5/20... Training loss: 0.1124\n",
      "Epoch: 5/20... Training loss: 0.1116\n",
      "Epoch: 5/20... Training loss: 0.1115\n",
      "Epoch: 5/20... Training loss: 0.1150\n",
      "Epoch: 5/20... Training loss: 0.1109\n",
      "Epoch: 5/20... Training loss: 0.1196\n",
      "Epoch: 5/20... Training loss: 0.1130\n",
      "Epoch: 5/20... Training loss: 0.1136\n",
      "Epoch: 5/20... Training loss: 0.1151\n",
      "Epoch: 5/20... Training loss: 0.1137\n",
      "Epoch: 5/20... Training loss: 0.1073\n",
      "Epoch: 5/20... Training loss: 0.1137\n",
      "Epoch: 5/20... Training loss: 0.1147\n",
      "Epoch: 5/20... Training loss: 0.1116\n",
      "Epoch: 5/20... Training loss: 0.1074\n",
      "Epoch: 5/20... Training loss: 0.1160\n",
      "Epoch: 5/20... Training loss: 0.1170\n",
      "Epoch: 5/20... Training loss: 0.1134\n",
      "Epoch: 5/20... Training loss: 0.1143\n",
      "Epoch: 5/20... Training loss: 0.1158\n",
      "Epoch: 5/20... Training loss: 0.1095\n",
      "Epoch: 5/20... Training loss: 0.1147\n",
      "Epoch: 5/20... Training loss: 0.1132\n",
      "Epoch: 5/20... Training loss: 0.1149\n",
      "Epoch: 5/20... Training loss: 0.1147\n",
      "Epoch: 5/20... Training loss: 0.1134\n",
      "Epoch: 5/20... Training loss: 0.1058\n",
      "Epoch: 5/20... Training loss: 0.1108\n",
      "Epoch: 5/20... Training loss: 0.1132\n",
      "Epoch: 5/20... Training loss: 0.1147\n",
      "Epoch: 5/20... Training loss: 0.1091\n",
      "Epoch: 5/20... Training loss: 0.1121\n",
      "Epoch: 5/20... Training loss: 0.1167\n",
      "Epoch: 5/20... Training loss: 0.1105\n",
      "Epoch: 5/20... Training loss: 0.1135\n",
      "Epoch: 5/20... Training loss: 0.1132\n",
      "Epoch: 5/20... Training loss: 0.1136\n",
      "Epoch: 5/20... Training loss: 0.1132\n",
      "Epoch: 5/20... Training loss: 0.1094\n",
      "Epoch: 5/20... Training loss: 0.1133\n",
      "Epoch: 5/20... Training loss: 0.1087\n",
      "Epoch: 5/20... Training loss: 0.1122\n",
      "Epoch: 5/20... Training loss: 0.1131\n",
      "Epoch: 5/20... Training loss: 0.1139\n",
      "Epoch: 5/20... Training loss: 0.1102\n",
      "Epoch: 5/20... Training loss: 0.1113\n",
      "Epoch: 5/20... Training loss: 0.1131\n",
      "Epoch: 5/20... Training loss: 0.1111\n",
      "Epoch: 5/20... Training loss: 0.1071\n",
      "Epoch: 5/20... Training loss: 0.1108\n",
      "Epoch: 5/20... Training loss: 0.1111\n",
      "Epoch: 5/20... Training loss: 0.1126\n",
      "Epoch: 5/20... Training loss: 0.1129\n",
      "Epoch: 5/20... Training loss: 0.1157\n",
      "Epoch: 5/20... Training loss: 0.1115\n",
      "Epoch: 5/20... Training loss: 0.1107\n",
      "Epoch: 5/20... Training loss: 0.1087\n",
      "Epoch: 5/20... Training loss: 0.1093\n",
      "Epoch: 5/20... Training loss: 0.1099\n",
      "Epoch: 5/20... Training loss: 0.1080\n",
      "Epoch: 5/20... Training loss: 0.1135\n",
      "Epoch: 5/20... Training loss: 0.1127\n",
      "Epoch: 5/20... Training loss: 0.1116\n",
      "Epoch: 5/20... Training loss: 0.1077\n",
      "Epoch: 5/20... Training loss: 0.1127\n",
      "Epoch: 5/20... Training loss: 0.1081\n",
      "Epoch: 5/20... Training loss: 0.1122\n",
      "Epoch: 5/20... Training loss: 0.1072\n",
      "Epoch: 5/20... Training loss: 0.1137\n",
      "Epoch: 5/20... Training loss: 0.1086\n",
      "Epoch: 5/20... Training loss: 0.1125\n",
      "Epoch: 5/20... Training loss: 0.1163\n",
      "Epoch: 5/20... Training loss: 0.1135\n",
      "Epoch: 5/20... Training loss: 0.1127\n",
      "Epoch: 5/20... Training loss: 0.1079\n",
      "Epoch: 5/20... Training loss: 0.1121\n",
      "Epoch: 5/20... Training loss: 0.1096\n",
      "Epoch: 5/20... Training loss: 0.1123\n",
      "Epoch: 5/20... Training loss: 0.1133\n",
      "Epoch: 5/20... Training loss: 0.1130\n",
      "Epoch: 5/20... Training loss: 0.1145\n",
      "Epoch: 5/20... Training loss: 0.1086\n",
      "Epoch: 5/20... Training loss: 0.1093\n",
      "Epoch: 5/20... Training loss: 0.1143\n",
      "Epoch: 5/20... Training loss: 0.1122\n",
      "Epoch: 5/20... Training loss: 0.1077\n",
      "Epoch: 5/20... Training loss: 0.1130\n",
      "Epoch: 5/20... Training loss: 0.1163\n",
      "Epoch: 5/20... Training loss: 0.1133\n",
      "Epoch: 5/20... Training loss: 0.1135\n",
      "Epoch: 5/20... Training loss: 0.1094\n",
      "Epoch: 5/20... Training loss: 0.1119\n",
      "Epoch: 5/20... Training loss: 0.1104\n",
      "Epoch: 5/20... Training loss: 0.1137\n",
      "Epoch: 5/20... Training loss: 0.1099\n",
      "Epoch: 5/20... Training loss: 0.1079\n",
      "Epoch: 5/20... Training loss: 0.1160\n",
      "Epoch: 5/20... Training loss: 0.1105\n",
      "Epoch: 5/20... Training loss: 0.1120\n",
      "Epoch: 5/20... Training loss: 0.1096\n",
      "Epoch: 5/20... Training loss: 0.1101\n",
      "Epoch: 5/20... Training loss: 0.1124\n",
      "Epoch: 5/20... Training loss: 0.1070\n",
      "Epoch: 5/20... Training loss: 0.1103\n",
      "Epoch: 5/20... Training loss: 0.1105\n",
      "Epoch: 5/20... Training loss: 0.1135\n",
      "Epoch: 5/20... Training loss: 0.1093\n",
      "Epoch: 5/20... Training loss: 0.1120\n",
      "Epoch: 5/20... Training loss: 0.1103\n",
      "Epoch: 5/20... Training loss: 0.1093\n",
      "Epoch: 5/20... Training loss: 0.1080\n",
      "Epoch: 5/20... Training loss: 0.1059\n",
      "Epoch: 5/20... Training loss: 0.1073\n",
      "Epoch: 5/20... Training loss: 0.1112\n",
      "Epoch: 5/20... Training loss: 0.1156\n",
      "Epoch: 5/20... Training loss: 0.1127\n",
      "Epoch: 5/20... Training loss: 0.1103\n",
      "Epoch: 5/20... Training loss: 0.1071\n",
      "Epoch: 5/20... Training loss: 0.1078\n",
      "Epoch: 5/20... Training loss: 0.1126\n",
      "Epoch: 5/20... Training loss: 0.1091\n",
      "Epoch: 5/20... Training loss: 0.1114\n",
      "Epoch: 5/20... Training loss: 0.1094\n",
      "Epoch: 5/20... Training loss: 0.1071\n",
      "Epoch: 5/20... Training loss: 0.1102\n",
      "Epoch: 5/20... Training loss: 0.1072\n",
      "Epoch: 5/20... Training loss: 0.1081\n",
      "Epoch: 5/20... Training loss: 0.1116\n",
      "Epoch: 5/20... Training loss: 0.1105\n",
      "Epoch: 5/20... Training loss: 0.1102\n",
      "Epoch: 5/20... Training loss: 0.1112\n",
      "Epoch: 5/20... Training loss: 0.1093\n",
      "Epoch: 5/20... Training loss: 0.1142\n",
      "Epoch: 5/20... Training loss: 0.1106\n",
      "Epoch: 5/20... Training loss: 0.1120\n",
      "Epoch: 5/20... Training loss: 0.1146\n",
      "Epoch: 5/20... Training loss: 0.1114\n",
      "Epoch: 5/20... Training loss: 0.1099\n",
      "Epoch: 5/20... Training loss: 0.1104\n",
      "Epoch: 5/20... Training loss: 0.1159\n",
      "Epoch: 5/20... Training loss: 0.1073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/20... Training loss: 0.1112\n",
      "Epoch: 5/20... Training loss: 0.1087\n",
      "Epoch: 5/20... Training loss: 0.1109\n",
      "Epoch: 5/20... Training loss: 0.1070\n",
      "Epoch: 5/20... Training loss: 0.1076\n",
      "Epoch: 5/20... Training loss: 0.1099\n",
      "Epoch: 5/20... Training loss: 0.1088\n",
      "Epoch: 5/20... Training loss: 0.1073\n",
      "Epoch: 5/20... Training loss: 0.1096\n",
      "Epoch: 5/20... Training loss: 0.1098\n",
      "Epoch: 5/20... Training loss: 0.1100\n",
      "Epoch: 5/20... Training loss: 0.1149\n",
      "Epoch: 5/20... Training loss: 0.1107\n",
      "Epoch: 5/20... Training loss: 0.1086\n",
      "Epoch: 5/20... Training loss: 0.1110\n",
      "Epoch: 5/20... Training loss: 0.1087\n",
      "Epoch: 5/20... Training loss: 0.1111\n",
      "Epoch: 5/20... Training loss: 0.1062\n",
      "Epoch: 5/20... Training loss: 0.1114\n",
      "Epoch: 5/20... Training loss: 0.1105\n",
      "Epoch: 5/20... Training loss: 0.1079\n",
      "Epoch: 5/20... Training loss: 0.1107\n",
      "Epoch: 5/20... Training loss: 0.1116\n",
      "Epoch: 5/20... Training loss: 0.1096\n",
      "Epoch: 5/20... Training loss: 0.1103\n",
      "Epoch: 5/20... Training loss: 0.1098\n",
      "Epoch: 5/20... Training loss: 0.1074\n",
      "Epoch: 5/20... Training loss: 0.1125\n",
      "Epoch: 5/20... Training loss: 0.1085\n",
      "Epoch: 5/20... Training loss: 0.1092\n",
      "Epoch: 5/20... Training loss: 0.1092\n",
      "Epoch: 5/20... Training loss: 0.1088\n",
      "Epoch: 5/20... Training loss: 0.1059\n",
      "Epoch: 5/20... Training loss: 0.1069\n",
      "Epoch: 5/20... Training loss: 0.1088\n",
      "Epoch: 5/20... Training loss: 0.1036\n",
      "Epoch: 5/20... Training loss: 0.1102\n",
      "Epoch: 5/20... Training loss: 0.1056\n",
      "Epoch: 5/20... Training loss: 0.1098\n",
      "Epoch: 5/20... Training loss: 0.1128\n",
      "Epoch: 5/20... Training loss: 0.1064\n",
      "Epoch: 5/20... Training loss: 0.1090\n",
      "Epoch: 5/20... Training loss: 0.1082\n",
      "Epoch: 5/20... Training loss: 0.1125\n",
      "Epoch: 5/20... Training loss: 0.1044\n",
      "Epoch: 5/20... Training loss: 0.1080\n",
      "Epoch: 5/20... Training loss: 0.1097\n",
      "Epoch: 5/20... Training loss: 0.1099\n",
      "Epoch: 5/20... Training loss: 0.1109\n",
      "Epoch: 5/20... Training loss: 0.1040\n",
      "Epoch: 5/20... Training loss: 0.1093\n",
      "Epoch: 5/20... Training loss: 0.1071\n",
      "Epoch: 5/20... Training loss: 0.1080\n",
      "Epoch: 5/20... Training loss: 0.1083\n",
      "Epoch: 5/20... Training loss: 0.1073\n",
      "Epoch: 5/20... Training loss: 0.1107\n",
      "Epoch: 6/20... Training loss: 0.1072\n",
      "Epoch: 6/20... Training loss: 0.1104\n",
      "Epoch: 6/20... Training loss: 0.1084\n",
      "Epoch: 6/20... Training loss: 0.1120\n",
      "Epoch: 6/20... Training loss: 0.1094\n",
      "Epoch: 6/20... Training loss: 0.1054\n",
      "Epoch: 6/20... Training loss: 0.1088\n",
      "Epoch: 6/20... Training loss: 0.1091\n",
      "Epoch: 6/20... Training loss: 0.1042\n",
      "Epoch: 6/20... Training loss: 0.1032\n",
      "Epoch: 6/20... Training loss: 0.1091\n",
      "Epoch: 6/20... Training loss: 0.1140\n",
      "Epoch: 6/20... Training loss: 0.1065\n",
      "Epoch: 6/20... Training loss: 0.1121\n",
      "Epoch: 6/20... Training loss: 0.1051\n",
      "Epoch: 6/20... Training loss: 0.1078\n",
      "Epoch: 6/20... Training loss: 0.1073\n",
      "Epoch: 6/20... Training loss: 0.1077\n",
      "Epoch: 6/20... Training loss: 0.1058\n",
      "Epoch: 6/20... Training loss: 0.1041\n",
      "Epoch: 6/20... Training loss: 0.1107\n",
      "Epoch: 6/20... Training loss: 0.1097\n",
      "Epoch: 6/20... Training loss: 0.1086\n",
      "Epoch: 6/20... Training loss: 0.1078\n",
      "Epoch: 6/20... Training loss: 0.1078\n",
      "Epoch: 6/20... Training loss: 0.1054\n",
      "Epoch: 6/20... Training loss: 0.1117\n",
      "Epoch: 6/20... Training loss: 0.1071\n",
      "Epoch: 6/20... Training loss: 0.1084\n",
      "Epoch: 6/20... Training loss: 0.1107\n",
      "Epoch: 6/20... Training loss: 0.1088\n",
      "Epoch: 6/20... Training loss: 0.1078\n",
      "Epoch: 6/20... Training loss: 0.1049\n",
      "Epoch: 6/20... Training loss: 0.1066\n",
      "Epoch: 6/20... Training loss: 0.1068\n",
      "Epoch: 6/20... Training loss: 0.1068\n",
      "Epoch: 6/20... Training loss: 0.1063\n",
      "Epoch: 6/20... Training loss: 0.1086\n",
      "Epoch: 6/20... Training loss: 0.1092\n",
      "Epoch: 6/20... Training loss: 0.1103\n",
      "Epoch: 6/20... Training loss: 0.1106\n",
      "Epoch: 6/20... Training loss: 0.1076\n",
      "Epoch: 6/20... Training loss: 0.1078\n",
      "Epoch: 6/20... Training loss: 0.1034\n",
      "Epoch: 6/20... Training loss: 0.1122\n",
      "Epoch: 6/20... Training loss: 0.1086\n",
      "Epoch: 6/20... Training loss: 0.1099\n",
      "Epoch: 6/20... Training loss: 0.1060\n",
      "Epoch: 6/20... Training loss: 0.1066\n",
      "Epoch: 6/20... Training loss: 0.1064\n",
      "Epoch: 6/20... Training loss: 0.1090\n",
      "Epoch: 6/20... Training loss: 0.1083\n",
      "Epoch: 6/20... Training loss: 0.1093\n",
      "Epoch: 6/20... Training loss: 0.1043\n",
      "Epoch: 6/20... Training loss: 0.1086\n",
      "Epoch: 6/20... Training loss: 0.1088\n",
      "Epoch: 6/20... Training loss: 0.1076\n",
      "Epoch: 6/20... Training loss: 0.1106\n",
      "Epoch: 6/20... Training loss: 0.1032\n",
      "Epoch: 6/20... Training loss: 0.1079\n",
      "Epoch: 6/20... Training loss: 0.1067\n",
      "Epoch: 6/20... Training loss: 0.1113\n",
      "Epoch: 6/20... Training loss: 0.1093\n",
      "Epoch: 6/20... Training loss: 0.1054\n",
      "Epoch: 6/20... Training loss: 0.1091\n",
      "Epoch: 6/20... Training loss: 0.1054\n",
      "Epoch: 6/20... Training loss: 0.1082\n",
      "Epoch: 6/20... Training loss: 0.1068\n",
      "Epoch: 6/20... Training loss: 0.1081\n",
      "Epoch: 6/20... Training loss: 0.1066\n",
      "Epoch: 6/20... Training loss: 0.1072\n",
      "Epoch: 6/20... Training loss: 0.1055\n",
      "Epoch: 6/20... Training loss: 0.1072\n",
      "Epoch: 6/20... Training loss: 0.1076\n",
      "Epoch: 6/20... Training loss: 0.1123\n",
      "Epoch: 6/20... Training loss: 0.1087\n",
      "Epoch: 6/20... Training loss: 0.1051\n",
      "Epoch: 6/20... Training loss: 0.1055\n",
      "Epoch: 6/20... Training loss: 0.1086\n",
      "Epoch: 6/20... Training loss: 0.1073\n",
      "Epoch: 6/20... Training loss: 0.1080\n",
      "Epoch: 6/20... Training loss: 0.1065\n",
      "Epoch: 6/20... Training loss: 0.1092\n",
      "Epoch: 6/20... Training loss: 0.1067\n",
      "Epoch: 6/20... Training loss: 0.1118\n",
      "Epoch: 6/20... Training loss: 0.1098\n",
      "Epoch: 6/20... Training loss: 0.1132\n",
      "Epoch: 6/20... Training loss: 0.1042\n",
      "Epoch: 6/20... Training loss: 0.1036\n",
      "Epoch: 6/20... Training loss: 0.1093\n",
      "Epoch: 6/20... Training loss: 0.1067\n",
      "Epoch: 6/20... Training loss: 0.1045\n",
      "Epoch: 6/20... Training loss: 0.1064\n",
      "Epoch: 6/20... Training loss: 0.1067\n",
      "Epoch: 6/20... Training loss: 0.1083\n",
      "Epoch: 6/20... Training loss: 0.1087\n",
      "Epoch: 6/20... Training loss: 0.1050\n",
      "Epoch: 6/20... Training loss: 0.1086\n",
      "Epoch: 6/20... Training loss: 0.1120\n",
      "Epoch: 6/20... Training loss: 0.1077\n",
      "Epoch: 6/20... Training loss: 0.1029\n",
      "Epoch: 6/20... Training loss: 0.1014\n",
      "Epoch: 6/20... Training loss: 0.1092\n",
      "Epoch: 6/20... Training loss: 0.1095\n",
      "Epoch: 6/20... Training loss: 0.1053\n",
      "Epoch: 6/20... Training loss: 0.1113\n",
      "Epoch: 6/20... Training loss: 0.1083\n",
      "Epoch: 6/20... Training loss: 0.1098\n",
      "Epoch: 6/20... Training loss: 0.1106\n",
      "Epoch: 6/20... Training loss: 0.1072\n",
      "Epoch: 6/20... Training loss: 0.1092\n",
      "Epoch: 6/20... Training loss: 0.1102\n",
      "Epoch: 6/20... Training loss: 0.1058\n",
      "Epoch: 6/20... Training loss: 0.1028\n",
      "Epoch: 6/20... Training loss: 0.1049\n",
      "Epoch: 6/20... Training loss: 0.1041\n",
      "Epoch: 6/20... Training loss: 0.1078\n",
      "Epoch: 6/20... Training loss: 0.1112\n",
      "Epoch: 6/20... Training loss: 0.1100\n",
      "Epoch: 6/20... Training loss: 0.1074\n",
      "Epoch: 6/20... Training loss: 0.1027\n",
      "Epoch: 6/20... Training loss: 0.1067\n",
      "Epoch: 6/20... Training loss: 0.1059\n",
      "Epoch: 6/20... Training loss: 0.1063\n",
      "Epoch: 6/20... Training loss: 0.1060\n",
      "Epoch: 6/20... Training loss: 0.1061\n",
      "Epoch: 6/20... Training loss: 0.1058\n",
      "Epoch: 6/20... Training loss: 0.1057\n",
      "Epoch: 6/20... Training loss: 0.1045\n",
      "Epoch: 6/20... Training loss: 0.1028\n",
      "Epoch: 6/20... Training loss: 0.1059\n",
      "Epoch: 6/20... Training loss: 0.1077\n",
      "Epoch: 6/20... Training loss: 0.1060\n",
      "Epoch: 6/20... Training loss: 0.1044\n",
      "Epoch: 6/20... Training loss: 0.1057\n",
      "Epoch: 6/20... Training loss: 0.1041\n",
      "Epoch: 6/20... Training loss: 0.1066\n",
      "Epoch: 6/20... Training loss: 0.1086\n",
      "Epoch: 6/20... Training loss: 0.1046\n",
      "Epoch: 6/20... Training loss: 0.1066\n",
      "Epoch: 6/20... Training loss: 0.1059\n",
      "Epoch: 6/20... Training loss: 0.1039\n",
      "Epoch: 6/20... Training loss: 0.1083\n",
      "Epoch: 6/20... Training loss: 0.1056\n",
      "Epoch: 6/20... Training loss: 0.1108\n",
      "Epoch: 6/20... Training loss: 0.1038\n",
      "Epoch: 6/20... Training loss: 0.1046\n",
      "Epoch: 6/20... Training loss: 0.1047\n",
      "Epoch: 6/20... Training loss: 0.1093\n",
      "Epoch: 6/20... Training loss: 0.1064\n",
      "Epoch: 6/20... Training loss: 0.1079\n",
      "Epoch: 6/20... Training loss: 0.1031\n",
      "Epoch: 6/20... Training loss: 0.1071\n",
      "Epoch: 6/20... Training loss: 0.1089\n",
      "Epoch: 6/20... Training loss: 0.1042\n",
      "Epoch: 6/20... Training loss: 0.1067\n",
      "Epoch: 6/20... Training loss: 0.1022\n",
      "Epoch: 6/20... Training loss: 0.1073\n",
      "Epoch: 6/20... Training loss: 0.1049\n",
      "Epoch: 6/20... Training loss: 0.1048\n",
      "Epoch: 6/20... Training loss: 0.1093\n",
      "Epoch: 6/20... Training loss: 0.1028\n",
      "Epoch: 6/20... Training loss: 0.0998\n",
      "Epoch: 6/20... Training loss: 0.1101\n",
      "Epoch: 6/20... Training loss: 0.1029\n",
      "Epoch: 6/20... Training loss: 0.1025\n",
      "Epoch: 6/20... Training loss: 0.1041\n",
      "Epoch: 6/20... Training loss: 0.1058\n",
      "Epoch: 6/20... Training loss: 0.1077\n",
      "Epoch: 6/20... Training loss: 0.1022\n",
      "Epoch: 6/20... Training loss: 0.1061\n",
      "Epoch: 6/20... Training loss: 0.1061\n",
      "Epoch: 6/20... Training loss: 0.1012\n",
      "Epoch: 6/20... Training loss: 0.1049\n",
      "Epoch: 6/20... Training loss: 0.1063\n",
      "Epoch: 6/20... Training loss: 0.1028\n",
      "Epoch: 6/20... Training loss: 0.1035\n",
      "Epoch: 6/20... Training loss: 0.1082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/20... Training loss: 0.1058\n",
      "Epoch: 6/20... Training loss: 0.1025\n",
      "Epoch: 6/20... Training loss: 0.1033\n",
      "Epoch: 6/20... Training loss: 0.1044\n",
      "Epoch: 6/20... Training loss: 0.1050\n",
      "Epoch: 6/20... Training loss: 0.1062\n",
      "Epoch: 6/20... Training loss: 0.1077\n",
      "Epoch: 6/20... Training loss: 0.1075\n",
      "Epoch: 6/20... Training loss: 0.1086\n",
      "Epoch: 6/20... Training loss: 0.1078\n",
      "Epoch: 6/20... Training loss: 0.1059\n",
      "Epoch: 6/20... Training loss: 0.1051\n",
      "Epoch: 6/20... Training loss: 0.1047\n",
      "Epoch: 6/20... Training loss: 0.1035\n",
      "Epoch: 6/20... Training loss: 0.1050\n",
      "Epoch: 6/20... Training loss: 0.1049\n",
      "Epoch: 6/20... Training loss: 0.1045\n",
      "Epoch: 6/20... Training loss: 0.1039\n",
      "Epoch: 6/20... Training loss: 0.1027\n",
      "Epoch: 6/20... Training loss: 0.1029\n",
      "Epoch: 6/20... Training loss: 0.1099\n",
      "Epoch: 6/20... Training loss: 0.1063\n",
      "Epoch: 6/20... Training loss: 0.1053\n",
      "Epoch: 6/20... Training loss: 0.1046\n",
      "Epoch: 6/20... Training loss: 0.1064\n",
      "Epoch: 6/20... Training loss: 0.1049\n",
      "Epoch: 6/20... Training loss: 0.1012\n",
      "Epoch: 6/20... Training loss: 0.1044\n",
      "Epoch: 6/20... Training loss: 0.1072\n",
      "Epoch: 6/20... Training loss: 0.1023\n",
      "Epoch: 6/20... Training loss: 0.1068\n",
      "Epoch: 6/20... Training loss: 0.1057\n",
      "Epoch: 6/20... Training loss: 0.1053\n",
      "Epoch: 6/20... Training loss: 0.1043\n",
      "Epoch: 6/20... Training loss: 0.1057\n",
      "Epoch: 6/20... Training loss: 0.1063\n",
      "Epoch: 6/20... Training loss: 0.1024\n",
      "Epoch: 6/20... Training loss: 0.1080\n",
      "Epoch: 6/20... Training loss: 0.1079\n",
      "Epoch: 6/20... Training loss: 0.1052\n",
      "Epoch: 6/20... Training loss: 0.1039\n",
      "Epoch: 6/20... Training loss: 0.1066\n",
      "Epoch: 6/20... Training loss: 0.1044\n",
      "Epoch: 6/20... Training loss: 0.0997\n",
      "Epoch: 6/20... Training loss: 0.1033\n",
      "Epoch: 6/20... Training loss: 0.1092\n",
      "Epoch: 6/20... Training loss: 0.1062\n",
      "Epoch: 6/20... Training loss: 0.1051\n",
      "Epoch: 6/20... Training loss: 0.1027\n",
      "Epoch: 6/20... Training loss: 0.1053\n",
      "Epoch: 6/20... Training loss: 0.1039\n",
      "Epoch: 6/20... Training loss: 0.1060\n",
      "Epoch: 6/20... Training loss: 0.1009\n",
      "Epoch: 6/20... Training loss: 0.1059\n",
      "Epoch: 6/20... Training loss: 0.1096\n",
      "Epoch: 6/20... Training loss: 0.1060\n",
      "Epoch: 6/20... Training loss: 0.1009\n",
      "Epoch: 6/20... Training loss: 0.1094\n",
      "Epoch: 6/20... Training loss: 0.1040\n",
      "Epoch: 6/20... Training loss: 0.1046\n",
      "Epoch: 6/20... Training loss: 0.1067\n",
      "Epoch: 6/20... Training loss: 0.1037\n",
      "Epoch: 6/20... Training loss: 0.1063\n",
      "Epoch: 6/20... Training loss: 0.1061\n",
      "Epoch: 6/20... Training loss: 0.1031\n",
      "Epoch: 6/20... Training loss: 0.1062\n",
      "Epoch: 6/20... Training loss: 0.1059\n",
      "Epoch: 6/20... Training loss: 0.1032\n",
      "Epoch: 6/20... Training loss: 0.1079\n",
      "Epoch: 6/20... Training loss: 0.1023\n",
      "Epoch: 6/20... Training loss: 0.1058\n",
      "Epoch: 6/20... Training loss: 0.1059\n",
      "Epoch: 6/20... Training loss: 0.1037\n",
      "Epoch: 6/20... Training loss: 0.1042\n",
      "Epoch: 6/20... Training loss: 0.1030\n",
      "Epoch: 6/20... Training loss: 0.1069\n",
      "Epoch: 6/20... Training loss: 0.1021\n",
      "Epoch: 6/20... Training loss: 0.1020\n",
      "Epoch: 6/20... Training loss: 0.1044\n",
      "Epoch: 6/20... Training loss: 0.1030\n",
      "Epoch: 6/20... Training loss: 0.1057\n",
      "Epoch: 6/20... Training loss: 0.1055\n",
      "Epoch: 6/20... Training loss: 0.1033\n",
      "Epoch: 6/20... Training loss: 0.1021\n",
      "Epoch: 6/20... Training loss: 0.1065\n",
      "Epoch: 6/20... Training loss: 0.1028\n",
      "Epoch: 6/20... Training loss: 0.1028\n",
      "Epoch: 6/20... Training loss: 0.1056\n",
      "Epoch: 6/20... Training loss: 0.1017\n",
      "Epoch: 6/20... Training loss: 0.1006\n",
      "Epoch: 6/20... Training loss: 0.1077\n",
      "Epoch: 6/20... Training loss: 0.1023\n",
      "Epoch: 6/20... Training loss: 0.1017\n",
      "Epoch: 6/20... Training loss: 0.1017\n",
      "Epoch: 6/20... Training loss: 0.1069\n",
      "Epoch: 6/20... Training loss: 0.1084\n",
      "Epoch: 6/20... Training loss: 0.1055\n",
      "Epoch: 6/20... Training loss: 0.1051\n",
      "Epoch: 6/20... Training loss: 0.1013\n",
      "Epoch: 6/20... Training loss: 0.1050\n",
      "Epoch: 6/20... Training loss: 0.1114\n",
      "Epoch: 6/20... Training loss: 0.1024\n",
      "Epoch: 6/20... Training loss: 0.1056\n",
      "Epoch: 6/20... Training loss: 0.1025\n",
      "Epoch: 6/20... Training loss: 0.1046\n",
      "Epoch: 6/20... Training loss: 0.1053\n",
      "Epoch: 6/20... Training loss: 0.1043\n",
      "Epoch: 6/20... Training loss: 0.1001\n",
      "Epoch: 6/20... Training loss: 0.0999\n",
      "Epoch: 6/20... Training loss: 0.1029\n",
      "Epoch: 6/20... Training loss: 0.1040\n",
      "Epoch: 6/20... Training loss: 0.1025\n",
      "Epoch: 6/20... Training loss: 0.1038\n",
      "Epoch: 6/20... Training loss: 0.1036\n",
      "Epoch: 6/20... Training loss: 0.1051\n",
      "Epoch: 6/20... Training loss: 0.1019\n",
      "Epoch: 6/20... Training loss: 0.1042\n",
      "Epoch: 6/20... Training loss: 0.1054\n",
      "Epoch: 6/20... Training loss: 0.1068\n",
      "Epoch: 6/20... Training loss: 0.1045\n",
      "Epoch: 6/20... Training loss: 0.1035\n",
      "Epoch: 6/20... Training loss: 0.1042\n",
      "Epoch: 7/20... Training loss: 0.0992\n",
      "Epoch: 7/20... Training loss: 0.1062\n",
      "Epoch: 7/20... Training loss: 0.1019\n",
      "Epoch: 7/20... Training loss: 0.1031\n",
      "Epoch: 7/20... Training loss: 0.1044\n",
      "Epoch: 7/20... Training loss: 0.1031\n",
      "Epoch: 7/20... Training loss: 0.1035\n",
      "Epoch: 7/20... Training loss: 0.1026\n",
      "Epoch: 7/20... Training loss: 0.1017\n",
      "Epoch: 7/20... Training loss: 0.1116\n",
      "Epoch: 7/20... Training loss: 0.1038\n",
      "Epoch: 7/20... Training loss: 0.1038\n",
      "Epoch: 7/20... Training loss: 0.1076\n",
      "Epoch: 7/20... Training loss: 0.1039\n",
      "Epoch: 7/20... Training loss: 0.1014\n",
      "Epoch: 7/20... Training loss: 0.1053\n",
      "Epoch: 7/20... Training loss: 0.1025\n",
      "Epoch: 7/20... Training loss: 0.1015\n",
      "Epoch: 7/20... Training loss: 0.1039\n",
      "Epoch: 7/20... Training loss: 0.0989\n",
      "Epoch: 7/20... Training loss: 0.1025\n",
      "Epoch: 7/20... Training loss: 0.1047\n",
      "Epoch: 7/20... Training loss: 0.1022\n",
      "Epoch: 7/20... Training loss: 0.1028\n",
      "Epoch: 7/20... Training loss: 0.1035\n",
      "Epoch: 7/20... Training loss: 0.1033\n",
      "Epoch: 7/20... Training loss: 0.1019\n",
      "Epoch: 7/20... Training loss: 0.1029\n",
      "Epoch: 7/20... Training loss: 0.1041\n",
      "Epoch: 7/20... Training loss: 0.1001\n",
      "Epoch: 7/20... Training loss: 0.1027\n",
      "Epoch: 7/20... Training loss: 0.1019\n",
      "Epoch: 7/20... Training loss: 0.1064\n",
      "Epoch: 7/20... Training loss: 0.1041\n",
      "Epoch: 7/20... Training loss: 0.1045\n",
      "Epoch: 7/20... Training loss: 0.1077\n",
      "Epoch: 7/20... Training loss: 0.1000\n",
      "Epoch: 7/20... Training loss: 0.1012\n",
      "Epoch: 7/20... Training loss: 0.1034\n",
      "Epoch: 7/20... Training loss: 0.1059\n",
      "Epoch: 7/20... Training loss: 0.1014\n",
      "Epoch: 7/20... Training loss: 0.1062\n",
      "Epoch: 7/20... Training loss: 0.1058\n",
      "Epoch: 7/20... Training loss: 0.1033\n",
      "Epoch: 7/20... Training loss: 0.1052\n",
      "Epoch: 7/20... Training loss: 0.1001\n",
      "Epoch: 7/20... Training loss: 0.1043\n",
      "Epoch: 7/20... Training loss: 0.1049\n",
      "Epoch: 7/20... Training loss: 0.1047\n",
      "Epoch: 7/20... Training loss: 0.1026\n",
      "Epoch: 7/20... Training loss: 0.1014\n",
      "Epoch: 7/20... Training loss: 0.1012\n",
      "Epoch: 7/20... Training loss: 0.1038\n",
      "Epoch: 7/20... Training loss: 0.1028\n",
      "Epoch: 7/20... Training loss: 0.1016\n",
      "Epoch: 7/20... Training loss: 0.1056\n",
      "Epoch: 7/20... Training loss: 0.1022\n",
      "Epoch: 7/20... Training loss: 0.1033\n",
      "Epoch: 7/20... Training loss: 0.1006\n",
      "Epoch: 7/20... Training loss: 0.1018\n",
      "Epoch: 7/20... Training loss: 0.1045\n",
      "Epoch: 7/20... Training loss: 0.1044\n",
      "Epoch: 7/20... Training loss: 0.1039\n",
      "Epoch: 7/20... Training loss: 0.1047\n",
      "Epoch: 7/20... Training loss: 0.1003\n",
      "Epoch: 7/20... Training loss: 0.0993\n",
      "Epoch: 7/20... Training loss: 0.1028\n",
      "Epoch: 7/20... Training loss: 0.1014\n",
      "Epoch: 7/20... Training loss: 0.1059\n",
      "Epoch: 7/20... Training loss: 0.1001\n",
      "Epoch: 7/20... Training loss: 0.1061\n",
      "Epoch: 7/20... Training loss: 0.1013\n",
      "Epoch: 7/20... Training loss: 0.1055\n",
      "Epoch: 7/20... Training loss: 0.1023\n",
      "Epoch: 7/20... Training loss: 0.1034\n",
      "Epoch: 7/20... Training loss: 0.1013\n",
      "Epoch: 7/20... Training loss: 0.1012\n",
      "Epoch: 7/20... Training loss: 0.1002\n",
      "Epoch: 7/20... Training loss: 0.0981\n",
      "Epoch: 7/20... Training loss: 0.1016\n",
      "Epoch: 7/20... Training loss: 0.1003\n",
      "Epoch: 7/20... Training loss: 0.1013\n",
      "Epoch: 7/20... Training loss: 0.1005\n",
      "Epoch: 7/20... Training loss: 0.1002\n",
      "Epoch: 7/20... Training loss: 0.1027\n",
      "Epoch: 7/20... Training loss: 0.1012\n",
      "Epoch: 7/20... Training loss: 0.1043\n",
      "Epoch: 7/20... Training loss: 0.1030\n",
      "Epoch: 7/20... Training loss: 0.1011\n",
      "Epoch: 7/20... Training loss: 0.1026\n",
      "Epoch: 7/20... Training loss: 0.1063\n",
      "Epoch: 7/20... Training loss: 0.1049\n",
      "Epoch: 7/20... Training loss: 0.1044\n",
      "Epoch: 7/20... Training loss: 0.1056\n",
      "Epoch: 7/20... Training loss: 0.1045\n",
      "Epoch: 7/20... Training loss: 0.1026\n",
      "Epoch: 7/20... Training loss: 0.1018\n",
      "Epoch: 7/20... Training loss: 0.1019\n",
      "Epoch: 7/20... Training loss: 0.1006\n",
      "Epoch: 7/20... Training loss: 0.1009\n",
      "Epoch: 7/20... Training loss: 0.1024\n",
      "Epoch: 7/20... Training loss: 0.0988\n",
      "Epoch: 7/20... Training loss: 0.1008\n",
      "Epoch: 7/20... Training loss: 0.1034\n",
      "Epoch: 7/20... Training loss: 0.1042\n",
      "Epoch: 7/20... Training loss: 0.0988\n",
      "Epoch: 7/20... Training loss: 0.1049\n",
      "Epoch: 7/20... Training loss: 0.1059\n",
      "Epoch: 7/20... Training loss: 0.0999\n",
      "Epoch: 7/20... Training loss: 0.1058\n",
      "Epoch: 7/20... Training loss: 0.1077\n",
      "Epoch: 7/20... Training loss: 0.1048\n",
      "Epoch: 7/20... Training loss: 0.0987\n",
      "Epoch: 7/20... Training loss: 0.1031\n",
      "Epoch: 7/20... Training loss: 0.1034\n",
      "Epoch: 7/20... Training loss: 0.1007\n",
      "Epoch: 7/20... Training loss: 0.1007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/20... Training loss: 0.1028\n",
      "Epoch: 7/20... Training loss: 0.1037\n",
      "Epoch: 7/20... Training loss: 0.1022\n",
      "Epoch: 7/20... Training loss: 0.0994\n",
      "Epoch: 7/20... Training loss: 0.1061\n",
      "Epoch: 7/20... Training loss: 0.1016\n",
      "Epoch: 7/20... Training loss: 0.1045\n",
      "Epoch: 7/20... Training loss: 0.1016\n",
      "Epoch: 7/20... Training loss: 0.1022\n",
      "Epoch: 7/20... Training loss: 0.1015\n",
      "Epoch: 7/20... Training loss: 0.1027\n",
      "Epoch: 7/20... Training loss: 0.0980\n",
      "Epoch: 7/20... Training loss: 0.1055\n",
      "Epoch: 7/20... Training loss: 0.1041\n",
      "Epoch: 7/20... Training loss: 0.0999\n",
      "Epoch: 7/20... Training loss: 0.1019\n",
      "Epoch: 7/20... Training loss: 0.1013\n",
      "Epoch: 7/20... Training loss: 0.1046\n",
      "Epoch: 7/20... Training loss: 0.1034\n",
      "Epoch: 7/20... Training loss: 0.0986\n",
      "Epoch: 7/20... Training loss: 0.1018\n",
      "Epoch: 7/20... Training loss: 0.1083\n",
      "Epoch: 7/20... Training loss: 0.1031\n",
      "Epoch: 7/20... Training loss: 0.1029\n",
      "Epoch: 7/20... Training loss: 0.1032\n",
      "Epoch: 7/20... Training loss: 0.1007\n",
      "Epoch: 7/20... Training loss: 0.1012\n",
      "Epoch: 7/20... Training loss: 0.1012\n",
      "Epoch: 7/20... Training loss: 0.0987\n",
      "Epoch: 7/20... Training loss: 0.1001\n",
      "Epoch: 7/20... Training loss: 0.1016\n",
      "Epoch: 7/20... Training loss: 0.1026\n",
      "Epoch: 7/20... Training loss: 0.1015\n",
      "Epoch: 7/20... Training loss: 0.1019\n",
      "Epoch: 7/20... Training loss: 0.1043\n",
      "Epoch: 7/20... Training loss: 0.1028\n",
      "Epoch: 7/20... Training loss: 0.1023\n",
      "Epoch: 7/20... Training loss: 0.1036\n",
      "Epoch: 7/20... Training loss: 0.1025\n",
      "Epoch: 7/20... Training loss: 0.1026\n",
      "Epoch: 7/20... Training loss: 0.1048\n",
      "Epoch: 7/20... Training loss: 0.1006\n",
      "Epoch: 7/20... Training loss: 0.1027\n",
      "Epoch: 7/20... Training loss: 0.0994\n",
      "Epoch: 7/20... Training loss: 0.0998\n",
      "Epoch: 7/20... Training loss: 0.1009\n",
      "Epoch: 7/20... Training loss: 0.1044\n",
      "Epoch: 7/20... Training loss: 0.1012\n",
      "Epoch: 7/20... Training loss: 0.0991\n",
      "Epoch: 7/20... Training loss: 0.1008\n",
      "Epoch: 7/20... Training loss: 0.1011\n",
      "Epoch: 7/20... Training loss: 0.1009\n",
      "Epoch: 7/20... Training loss: 0.0996\n",
      "Epoch: 7/20... Training loss: 0.0999\n",
      "Epoch: 7/20... Training loss: 0.1039\n",
      "Epoch: 7/20... Training loss: 0.1011\n",
      "Epoch: 7/20... Training loss: 0.0991\n",
      "Epoch: 7/20... Training loss: 0.1016\n",
      "Epoch: 7/20... Training loss: 0.1029\n",
      "Epoch: 7/20... Training loss: 0.1046\n",
      "Epoch: 7/20... Training loss: 0.1059\n",
      "Epoch: 7/20... Training loss: 0.0996\n",
      "Epoch: 7/20... Training loss: 0.0961\n",
      "Epoch: 7/20... Training loss: 0.1005\n",
      "Epoch: 7/20... Training loss: 0.1000\n",
      "Epoch: 7/20... Training loss: 0.1051\n",
      "Epoch: 7/20... Training loss: 0.0994\n",
      "Epoch: 7/20... Training loss: 0.0996\n",
      "Epoch: 7/20... Training loss: 0.1034\n",
      "Epoch: 7/20... Training loss: 0.1012\n",
      "Epoch: 7/20... Training loss: 0.0992\n",
      "Epoch: 7/20... Training loss: 0.1010\n",
      "Epoch: 7/20... Training loss: 0.1033\n",
      "Epoch: 7/20... Training loss: 0.1015\n",
      "Epoch: 7/20... Training loss: 0.1006\n",
      "Epoch: 7/20... Training loss: 0.1041\n",
      "Epoch: 7/20... Training loss: 0.1017\n",
      "Epoch: 7/20... Training loss: 0.1009\n",
      "Epoch: 7/20... Training loss: 0.1019\n",
      "Epoch: 7/20... Training loss: 0.1026\n",
      "Epoch: 7/20... Training loss: 0.1047\n",
      "Epoch: 7/20... Training loss: 0.1012\n",
      "Epoch: 7/20... Training loss: 0.1006\n",
      "Epoch: 7/20... Training loss: 0.1023\n",
      "Epoch: 7/20... Training loss: 0.1010\n",
      "Epoch: 7/20... Training loss: 0.1011\n",
      "Epoch: 7/20... Training loss: 0.1041\n",
      "Epoch: 7/20... Training loss: 0.1016\n",
      "Epoch: 7/20... Training loss: 0.1004\n",
      "Epoch: 7/20... Training loss: 0.1043\n",
      "Epoch: 7/20... Training loss: 0.1030\n",
      "Epoch: 7/20... Training loss: 0.1009\n",
      "Epoch: 7/20... Training loss: 0.1044\n",
      "Epoch: 7/20... Training loss: 0.1005\n",
      "Epoch: 7/20... Training loss: 0.1038\n",
      "Epoch: 7/20... Training loss: 0.0987\n",
      "Epoch: 7/20... Training loss: 0.0996\n",
      "Epoch: 7/20... Training loss: 0.1007\n",
      "Epoch: 7/20... Training loss: 0.0985\n",
      "Epoch: 7/20... Training loss: 0.1039\n",
      "Epoch: 7/20... Training loss: 0.1003\n",
      "Epoch: 7/20... Training loss: 0.0997\n",
      "Epoch: 7/20... Training loss: 0.0999\n",
      "Epoch: 7/20... Training loss: 0.1029\n",
      "Epoch: 7/20... Training loss: 0.0994\n",
      "Epoch: 7/20... Training loss: 0.1004\n",
      "Epoch: 7/20... Training loss: 0.0986\n",
      "Epoch: 7/20... Training loss: 0.0995\n",
      "Epoch: 7/20... Training loss: 0.1016\n",
      "Epoch: 7/20... Training loss: 0.0996\n",
      "Epoch: 7/20... Training loss: 0.1012\n",
      "Epoch: 7/20... Training loss: 0.1000\n",
      "Epoch: 7/20... Training loss: 0.1026\n",
      "Epoch: 7/20... Training loss: 0.0984\n",
      "Epoch: 7/20... Training loss: 0.1013\n",
      "Epoch: 7/20... Training loss: 0.0985\n",
      "Epoch: 7/20... Training loss: 0.1025\n",
      "Epoch: 7/20... Training loss: 0.1020\n",
      "Epoch: 7/20... Training loss: 0.1045\n",
      "Epoch: 7/20... Training loss: 0.0957\n",
      "Epoch: 7/20... Training loss: 0.1004\n",
      "Epoch: 7/20... Training loss: 0.0998\n",
      "Epoch: 7/20... Training loss: 0.0997\n",
      "Epoch: 7/20... Training loss: 0.1011\n",
      "Epoch: 7/20... Training loss: 0.1037\n",
      "Epoch: 7/20... Training loss: 0.0956\n",
      "Epoch: 7/20... Training loss: 0.1028\n",
      "Epoch: 7/20... Training loss: 0.1016\n",
      "Epoch: 7/20... Training loss: 0.1051\n",
      "Epoch: 7/20... Training loss: 0.1030\n",
      "Epoch: 7/20... Training loss: 0.0982\n",
      "Epoch: 7/20... Training loss: 0.1017\n",
      "Epoch: 7/20... Training loss: 0.0972\n",
      "Epoch: 7/20... Training loss: 0.1000\n",
      "Epoch: 7/20... Training loss: 0.1015\n",
      "Epoch: 7/20... Training loss: 0.1015\n",
      "Epoch: 7/20... Training loss: 0.1035\n",
      "Epoch: 7/20... Training loss: 0.0984\n",
      "Epoch: 7/20... Training loss: 0.0993\n",
      "Epoch: 7/20... Training loss: 0.1010\n",
      "Epoch: 7/20... Training loss: 0.1047\n",
      "Epoch: 7/20... Training loss: 0.0996\n",
      "Epoch: 7/20... Training loss: 0.1008\n",
      "Epoch: 7/20... Training loss: 0.1003\n",
      "Epoch: 7/20... Training loss: 0.0994\n",
      "Epoch: 7/20... Training loss: 0.0983\n",
      "Epoch: 7/20... Training loss: 0.0995\n",
      "Epoch: 7/20... Training loss: 0.0968\n",
      "Epoch: 7/20... Training loss: 0.0986\n",
      "Epoch: 7/20... Training loss: 0.0989\n",
      "Epoch: 7/20... Training loss: 0.0994\n",
      "Epoch: 7/20... Training loss: 0.1003\n",
      "Epoch: 7/20... Training loss: 0.0977\n",
      "Epoch: 7/20... Training loss: 0.1036\n",
      "Epoch: 7/20... Training loss: 0.1016\n",
      "Epoch: 7/20... Training loss: 0.0985\n",
      "Epoch: 7/20... Training loss: 0.0974\n",
      "Epoch: 7/20... Training loss: 0.1000\n",
      "Epoch: 7/20... Training loss: 0.0963\n",
      "Epoch: 7/20... Training loss: 0.0984\n",
      "Epoch: 7/20... Training loss: 0.0989\n",
      "Epoch: 7/20... Training loss: 0.0982\n",
      "Epoch: 7/20... Training loss: 0.1028\n",
      "Epoch: 7/20... Training loss: 0.1015\n",
      "Epoch: 7/20... Training loss: 0.1013\n",
      "Epoch: 7/20... Training loss: 0.1007\n",
      "Epoch: 7/20... Training loss: 0.1000\n",
      "Epoch: 7/20... Training loss: 0.0975\n",
      "Epoch: 7/20... Training loss: 0.0984\n",
      "Epoch: 7/20... Training loss: 0.1037\n",
      "Epoch: 7/20... Training loss: 0.0989\n",
      "Epoch: 7/20... Training loss: 0.1021\n",
      "Epoch: 7/20... Training loss: 0.0998\n",
      "Epoch: 7/20... Training loss: 0.0966\n",
      "Epoch: 7/20... Training loss: 0.0985\n",
      "Epoch: 7/20... Training loss: 0.0983\n",
      "Epoch: 7/20... Training loss: 0.1016\n",
      "Epoch: 7/20... Training loss: 0.1040\n",
      "Epoch: 7/20... Training loss: 0.1011\n",
      "Epoch: 7/20... Training loss: 0.0975\n",
      "Epoch: 7/20... Training loss: 0.0995\n",
      "Epoch: 7/20... Training loss: 0.1014\n",
      "Epoch: 7/20... Training loss: 0.0986\n",
      "Epoch: 8/20... Training loss: 0.0993\n",
      "Epoch: 8/20... Training loss: 0.1000\n",
      "Epoch: 8/20... Training loss: 0.0986\n",
      "Epoch: 8/20... Training loss: 0.0999\n",
      "Epoch: 8/20... Training loss: 0.1001\n",
      "Epoch: 8/20... Training loss: 0.0965\n",
      "Epoch: 8/20... Training loss: 0.0972\n",
      "Epoch: 8/20... Training loss: 0.0995\n",
      "Epoch: 8/20... Training loss: 0.0999\n",
      "Epoch: 8/20... Training loss: 0.1017\n",
      "Epoch: 8/20... Training loss: 0.0986\n",
      "Epoch: 8/20... Training loss: 0.1007\n",
      "Epoch: 8/20... Training loss: 0.1022\n",
      "Epoch: 8/20... Training loss: 0.1001\n",
      "Epoch: 8/20... Training loss: 0.1013\n",
      "Epoch: 8/20... Training loss: 0.0985\n",
      "Epoch: 8/20... Training loss: 0.1041\n",
      "Epoch: 8/20... Training loss: 0.1017\n",
      "Epoch: 8/20... Training loss: 0.1025\n",
      "Epoch: 8/20... Training loss: 0.0995\n",
      "Epoch: 8/20... Training loss: 0.1008\n",
      "Epoch: 8/20... Training loss: 0.1001\n",
      "Epoch: 8/20... Training loss: 0.0976\n",
      "Epoch: 8/20... Training loss: 0.0978\n",
      "Epoch: 8/20... Training loss: 0.1051\n",
      "Epoch: 8/20... Training loss: 0.1022\n",
      "Epoch: 8/20... Training loss: 0.1008\n",
      "Epoch: 8/20... Training loss: 0.0967\n",
      "Epoch: 8/20... Training loss: 0.0994\n",
      "Epoch: 8/20... Training loss: 0.1003\n",
      "Epoch: 8/20... Training loss: 0.1045\n",
      "Epoch: 8/20... Training loss: 0.0998\n",
      "Epoch: 8/20... Training loss: 0.1001\n",
      "Epoch: 8/20... Training loss: 0.0969\n",
      "Epoch: 8/20... Training loss: 0.0997\n",
      "Epoch: 8/20... Training loss: 0.0992\n",
      "Epoch: 8/20... Training loss: 0.0986\n",
      "Epoch: 8/20... Training loss: 0.1019\n",
      "Epoch: 8/20... Training loss: 0.0985\n",
      "Epoch: 8/20... Training loss: 0.1030\n",
      "Epoch: 8/20... Training loss: 0.1005\n",
      "Epoch: 8/20... Training loss: 0.1019\n",
      "Epoch: 8/20... Training loss: 0.0992\n",
      "Epoch: 8/20... Training loss: 0.1005\n",
      "Epoch: 8/20... Training loss: 0.0981\n",
      "Epoch: 8/20... Training loss: 0.1010\n",
      "Epoch: 8/20... Training loss: 0.1011\n",
      "Epoch: 8/20... Training loss: 0.0968\n",
      "Epoch: 8/20... Training loss: 0.0997\n",
      "Epoch: 8/20... Training loss: 0.0960\n",
      "Epoch: 8/20... Training loss: 0.1017\n",
      "Epoch: 8/20... Training loss: 0.1008\n",
      "Epoch: 8/20... Training loss: 0.0977\n",
      "Epoch: 8/20... Training loss: 0.0988\n",
      "Epoch: 8/20... Training loss: 0.1018\n",
      "Epoch: 8/20... Training loss: 0.0988\n",
      "Epoch: 8/20... Training loss: 0.1019\n",
      "Epoch: 8/20... Training loss: 0.0994\n",
      "Epoch: 8/20... Training loss: 0.1014\n",
      "Epoch: 8/20... Training loss: 0.0988\n",
      "Epoch: 8/20... Training loss: 0.1000\n",
      "Epoch: 8/20... Training loss: 0.0993\n",
      "Epoch: 8/20... Training loss: 0.0969\n",
      "Epoch: 8/20... Training loss: 0.0979\n",
      "Epoch: 8/20... Training loss: 0.0996\n",
      "Epoch: 8/20... Training loss: 0.1008\n",
      "Epoch: 8/20... Training loss: 0.0991\n",
      "Epoch: 8/20... Training loss: 0.1003\n",
      "Epoch: 8/20... Training loss: 0.0987\n",
      "Epoch: 8/20... Training loss: 0.0976\n",
      "Epoch: 8/20... Training loss: 0.1012\n",
      "Epoch: 8/20... Training loss: 0.0944\n",
      "Epoch: 8/20... Training loss: 0.0971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/20... Training loss: 0.0986\n",
      "Epoch: 8/20... Training loss: 0.1018\n",
      "Epoch: 8/20... Training loss: 0.1015\n",
      "Epoch: 8/20... Training loss: 0.0958\n",
      "Epoch: 8/20... Training loss: 0.1006\n",
      "Epoch: 8/20... Training loss: 0.0986\n",
      "Epoch: 8/20... Training loss: 0.1005\n",
      "Epoch: 8/20... Training loss: 0.1018\n",
      "Epoch: 8/20... Training loss: 0.1007\n",
      "Epoch: 8/20... Training loss: 0.0980\n",
      "Epoch: 8/20... Training loss: 0.0985\n",
      "Epoch: 8/20... Training loss: 0.0987\n",
      "Epoch: 8/20... Training loss: 0.1006\n",
      "Epoch: 8/20... Training loss: 0.0967\n",
      "Epoch: 8/20... Training loss: 0.0985\n",
      "Epoch: 8/20... Training loss: 0.0990\n",
      "Epoch: 8/20... Training loss: 0.0994\n",
      "Epoch: 8/20... Training loss: 0.1015\n",
      "Epoch: 8/20... Training loss: 0.1002\n",
      "Epoch: 8/20... Training loss: 0.0964\n",
      "Epoch: 8/20... Training loss: 0.1005\n",
      "Epoch: 8/20... Training loss: 0.0983\n",
      "Epoch: 8/20... Training loss: 0.0974\n",
      "Epoch: 8/20... Training loss: 0.0993\n",
      "Epoch: 8/20... Training loss: 0.0989\n",
      "Epoch: 8/20... Training loss: 0.0987\n",
      "Epoch: 8/20... Training loss: 0.0969\n",
      "Epoch: 8/20... Training loss: 0.1010\n",
      "Epoch: 8/20... Training loss: 0.0969\n",
      "Epoch: 8/20... Training loss: 0.0985\n",
      "Epoch: 8/20... Training loss: 0.0986\n",
      "Epoch: 8/20... Training loss: 0.1007\n",
      "Epoch: 8/20... Training loss: 0.0993\n",
      "Epoch: 8/20... Training loss: 0.0984\n",
      "Epoch: 8/20... Training loss: 0.0971\n",
      "Epoch: 8/20... Training loss: 0.1010\n",
      "Epoch: 8/20... Training loss: 0.0981\n",
      "Epoch: 8/20... Training loss: 0.0995\n",
      "Epoch: 8/20... Training loss: 0.1032\n",
      "Epoch: 8/20... Training loss: 0.0976\n",
      "Epoch: 8/20... Training loss: 0.0988\n",
      "Epoch: 8/20... Training loss: 0.0991\n",
      "Epoch: 8/20... Training loss: 0.1016\n",
      "Epoch: 8/20... Training loss: 0.0989\n",
      "Epoch: 8/20... Training loss: 0.1013\n",
      "Epoch: 8/20... Training loss: 0.0971\n",
      "Epoch: 8/20... Training loss: 0.1017\n",
      "Epoch: 8/20... Training loss: 0.0989\n",
      "Epoch: 8/20... Training loss: 0.0967\n",
      "Epoch: 8/20... Training loss: 0.0962\n",
      "Epoch: 8/20... Training loss: 0.1037\n",
      "Epoch: 8/20... Training loss: 0.0986\n",
      "Epoch: 8/20... Training loss: 0.0999\n",
      "Epoch: 8/20... Training loss: 0.0980\n",
      "Epoch: 8/20... Training loss: 0.1040\n",
      "Epoch: 8/20... Training loss: 0.0964\n",
      "Epoch: 8/20... Training loss: 0.1049\n",
      "Epoch: 8/20... Training loss: 0.1011\n",
      "Epoch: 8/20... Training loss: 0.0961\n",
      "Epoch: 8/20... Training loss: 0.0986\n",
      "Epoch: 8/20... Training loss: 0.1013\n",
      "Epoch: 8/20... Training loss: 0.0981\n",
      "Epoch: 8/20... Training loss: 0.1024\n",
      "Epoch: 8/20... Training loss: 0.0983\n",
      "Epoch: 8/20... Training loss: 0.0974\n",
      "Epoch: 8/20... Training loss: 0.0977\n",
      "Epoch: 8/20... Training loss: 0.0936\n",
      "Epoch: 8/20... Training loss: 0.0993\n",
      "Epoch: 8/20... Training loss: 0.0998\n",
      "Epoch: 8/20... Training loss: 0.0994\n",
      "Epoch: 8/20... Training loss: 0.0988\n",
      "Epoch: 8/20... Training loss: 0.1002\n",
      "Epoch: 8/20... Training loss: 0.0975\n",
      "Epoch: 8/20... Training loss: 0.0988\n",
      "Epoch: 8/20... Training loss: 0.0982\n",
      "Epoch: 8/20... Training loss: 0.0995\n",
      "Epoch: 8/20... Training loss: 0.0961\n",
      "Epoch: 8/20... Training loss: 0.0975\n",
      "Epoch: 8/20... Training loss: 0.0970\n",
      "Epoch: 8/20... Training loss: 0.0996\n",
      "Epoch: 8/20... Training loss: 0.0967\n",
      "Epoch: 8/20... Training loss: 0.0958\n",
      "Epoch: 8/20... Training loss: 0.0998\n",
      "Epoch: 8/20... Training loss: 0.0967\n",
      "Epoch: 8/20... Training loss: 0.0981\n",
      "Epoch: 8/20... Training loss: 0.0993\n",
      "Epoch: 8/20... Training loss: 0.1018\n",
      "Epoch: 8/20... Training loss: 0.0954\n",
      "Epoch: 8/20... Training loss: 0.0954\n",
      "Epoch: 8/20... Training loss: 0.0947\n",
      "Epoch: 8/20... Training loss: 0.0985\n",
      "Epoch: 8/20... Training loss: 0.0987\n",
      "Epoch: 8/20... Training loss: 0.0959\n",
      "Epoch: 8/20... Training loss: 0.0972\n",
      "Epoch: 8/20... Training loss: 0.1023\n",
      "Epoch: 8/20... Training loss: 0.0954\n",
      "Epoch: 8/20... Training loss: 0.0970\n",
      "Epoch: 8/20... Training loss: 0.0964\n",
      "Epoch: 8/20... Training loss: 0.0983\n",
      "Epoch: 8/20... Training loss: 0.0972\n",
      "Epoch: 8/20... Training loss: 0.1027\n",
      "Epoch: 8/20... Training loss: 0.0975\n",
      "Epoch: 8/20... Training loss: 0.0972\n",
      "Epoch: 8/20... Training loss: 0.0975\n",
      "Epoch: 8/20... Training loss: 0.0939\n",
      "Epoch: 8/20... Training loss: 0.0990\n",
      "Epoch: 8/20... Training loss: 0.0959\n",
      "Epoch: 8/20... Training loss: 0.0975\n",
      "Epoch: 8/20... Training loss: 0.0984\n",
      "Epoch: 8/20... Training loss: 0.0961\n",
      "Epoch: 8/20... Training loss: 0.1005\n",
      "Epoch: 8/20... Training loss: 0.0953\n",
      "Epoch: 8/20... Training loss: 0.1029\n",
      "Epoch: 8/20... Training loss: 0.0988\n",
      "Epoch: 8/20... Training loss: 0.0996\n",
      "Epoch: 8/20... Training loss: 0.0969\n",
      "Epoch: 8/20... Training loss: 0.0998\n",
      "Epoch: 8/20... Training loss: 0.0982\n",
      "Epoch: 8/20... Training loss: 0.0974\n",
      "Epoch: 8/20... Training loss: 0.0980\n",
      "Epoch: 8/20... Training loss: 0.0997\n",
      "Epoch: 8/20... Training loss: 0.0967\n",
      "Epoch: 8/20... Training loss: 0.0997\n",
      "Epoch: 8/20... Training loss: 0.0972\n",
      "Epoch: 8/20... Training loss: 0.0998\n",
      "Epoch: 8/20... Training loss: 0.0973\n",
      "Epoch: 8/20... Training loss: 0.0975\n",
      "Epoch: 8/20... Training loss: 0.1007\n",
      "Epoch: 8/20... Training loss: 0.0988\n",
      "Epoch: 8/20... Training loss: 0.0991\n",
      "Epoch: 8/20... Training loss: 0.0986\n",
      "Epoch: 8/20... Training loss: 0.0976\n",
      "Epoch: 8/20... Training loss: 0.0994\n",
      "Epoch: 8/20... Training loss: 0.1023\n",
      "Epoch: 8/20... Training loss: 0.0990\n",
      "Epoch: 8/20... Training loss: 0.0969\n",
      "Epoch: 8/20... Training loss: 0.1006\n",
      "Epoch: 8/20... Training loss: 0.1016\n",
      "Epoch: 8/20... Training loss: 0.1002\n",
      "Epoch: 8/20... Training loss: 0.1030\n",
      "Epoch: 8/20... Training loss: 0.0965\n",
      "Epoch: 8/20... Training loss: 0.1005\n",
      "Epoch: 8/20... Training loss: 0.0982\n",
      "Epoch: 8/20... Training loss: 0.0974\n",
      "Epoch: 8/20... Training loss: 0.0985\n",
      "Epoch: 8/20... Training loss: 0.0962\n",
      "Epoch: 8/20... Training loss: 0.0983\n",
      "Epoch: 8/20... Training loss: 0.0978\n",
      "Epoch: 8/20... Training loss: 0.0966\n",
      "Epoch: 8/20... Training loss: 0.0949\n",
      "Epoch: 8/20... Training loss: 0.1006\n",
      "Epoch: 8/20... Training loss: 0.1005\n",
      "Epoch: 8/20... Training loss: 0.0993\n",
      "Epoch: 8/20... Training loss: 0.1037\n",
      "Epoch: 8/20... Training loss: 0.0943\n",
      "Epoch: 8/20... Training loss: 0.0942\n",
      "Epoch: 8/20... Training loss: 0.0997\n",
      "Epoch: 8/20... Training loss: 0.0979\n",
      "Epoch: 8/20... Training loss: 0.0994\n",
      "Epoch: 8/20... Training loss: 0.0935\n",
      "Epoch: 8/20... Training loss: 0.1012\n",
      "Epoch: 8/20... Training loss: 0.0998\n",
      "Epoch: 8/20... Training loss: 0.0981\n",
      "Epoch: 8/20... Training loss: 0.1022\n",
      "Epoch: 8/20... Training loss: 0.0939\n",
      "Epoch: 8/20... Training loss: 0.0969\n",
      "Epoch: 8/20... Training loss: 0.0998\n",
      "Epoch: 8/20... Training loss: 0.0993\n",
      "Epoch: 8/20... Training loss: 0.0950\n",
      "Epoch: 8/20... Training loss: 0.0975\n",
      "Epoch: 8/20... Training loss: 0.0971\n",
      "Epoch: 8/20... Training loss: 0.0965\n",
      "Epoch: 8/20... Training loss: 0.0963\n",
      "Epoch: 8/20... Training loss: 0.0975\n",
      "Epoch: 8/20... Training loss: 0.1001\n",
      "Epoch: 8/20... Training loss: 0.0981\n",
      "Epoch: 8/20... Training loss: 0.0976\n",
      "Epoch: 8/20... Training loss: 0.0965\n",
      "Epoch: 8/20... Training loss: 0.0998\n",
      "Epoch: 8/20... Training loss: 0.1004\n",
      "Epoch: 8/20... Training loss: 0.0982\n",
      "Epoch: 8/20... Training loss: 0.0963\n",
      "Epoch: 8/20... Training loss: 0.0967\n",
      "Epoch: 8/20... Training loss: 0.0980\n",
      "Epoch: 8/20... Training loss: 0.0981\n",
      "Epoch: 8/20... Training loss: 0.0986\n",
      "Epoch: 8/20... Training loss: 0.1017\n",
      "Epoch: 8/20... Training loss: 0.0974\n",
      "Epoch: 8/20... Training loss: 0.0993\n",
      "Epoch: 8/20... Training loss: 0.0999\n",
      "Epoch: 8/20... Training loss: 0.0929\n",
      "Epoch: 8/20... Training loss: 0.0954\n",
      "Epoch: 8/20... Training loss: 0.0968\n",
      "Epoch: 8/20... Training loss: 0.1003\n",
      "Epoch: 8/20... Training loss: 0.0945\n",
      "Epoch: 8/20... Training loss: 0.0995\n",
      "Epoch: 8/20... Training loss: 0.1019\n",
      "Epoch: 8/20... Training loss: 0.0991\n",
      "Epoch: 8/20... Training loss: 0.0969\n",
      "Epoch: 8/20... Training loss: 0.0973\n",
      "Epoch: 8/20... Training loss: 0.1009\n",
      "Epoch: 8/20... Training loss: 0.0990\n",
      "Epoch: 8/20... Training loss: 0.0962\n",
      "Epoch: 8/20... Training loss: 0.0931\n",
      "Epoch: 8/20... Training loss: 0.0929\n",
      "Epoch: 8/20... Training loss: 0.0995\n",
      "Epoch: 8/20... Training loss: 0.1010\n",
      "Epoch: 8/20... Training loss: 0.1018\n",
      "Epoch: 8/20... Training loss: 0.0957\n",
      "Epoch: 8/20... Training loss: 0.1010\n",
      "Epoch: 8/20... Training loss: 0.0944\n",
      "Epoch: 8/20... Training loss: 0.0985\n",
      "Epoch: 8/20... Training loss: 0.0988\n",
      "Epoch: 8/20... Training loss: 0.0980\n",
      "Epoch: 8/20... Training loss: 0.1023\n",
      "Epoch: 8/20... Training loss: 0.0978\n",
      "Epoch: 8/20... Training loss: 0.0982\n",
      "Epoch: 8/20... Training loss: 0.0982\n",
      "Epoch: 8/20... Training loss: 0.0954\n",
      "Epoch: 8/20... Training loss: 0.0937\n",
      "Epoch: 8/20... Training loss: 0.0990\n",
      "Epoch: 8/20... Training loss: 0.0988\n",
      "Epoch: 8/20... Training loss: 0.0968\n",
      "Epoch: 8/20... Training loss: 0.1009\n",
      "Epoch: 8/20... Training loss: 0.0967\n",
      "Epoch: 8/20... Training loss: 0.1001\n",
      "Epoch: 8/20... Training loss: 0.0937\n",
      "Epoch: 9/20... Training loss: 0.0969\n",
      "Epoch: 9/20... Training loss: 0.1008\n",
      "Epoch: 9/20... Training loss: 0.0971\n",
      "Epoch: 9/20... Training loss: 0.0978\n",
      "Epoch: 9/20... Training loss: 0.0957\n",
      "Epoch: 9/20... Training loss: 0.0984\n",
      "Epoch: 9/20... Training loss: 0.0992\n",
      "Epoch: 9/20... Training loss: 0.0951\n",
      "Epoch: 9/20... Training loss: 0.0974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/20... Training loss: 0.1009\n",
      "Epoch: 9/20... Training loss: 0.0956\n",
      "Epoch: 9/20... Training loss: 0.1007\n",
      "Epoch: 9/20... Training loss: 0.0944\n",
      "Epoch: 9/20... Training loss: 0.0960\n",
      "Epoch: 9/20... Training loss: 0.1002\n",
      "Epoch: 9/20... Training loss: 0.0954\n",
      "Epoch: 9/20... Training loss: 0.0981\n",
      "Epoch: 9/20... Training loss: 0.0990\n",
      "Epoch: 9/20... Training loss: 0.0932\n",
      "Epoch: 9/20... Training loss: 0.0935\n",
      "Epoch: 9/20... Training loss: 0.1014\n",
      "Epoch: 9/20... Training loss: 0.0960\n",
      "Epoch: 9/20... Training loss: 0.0983\n",
      "Epoch: 9/20... Training loss: 0.0999\n",
      "Epoch: 9/20... Training loss: 0.0994\n",
      "Epoch: 9/20... Training loss: 0.0982\n",
      "Epoch: 9/20... Training loss: 0.0977\n",
      "Epoch: 9/20... Training loss: 0.0962\n",
      "Epoch: 9/20... Training loss: 0.0970\n",
      "Epoch: 9/20... Training loss: 0.0984\n",
      "Epoch: 9/20... Training loss: 0.1004\n",
      "Epoch: 9/20... Training loss: 0.0980\n",
      "Epoch: 9/20... Training loss: 0.0983\n",
      "Epoch: 9/20... Training loss: 0.1006\n",
      "Epoch: 9/20... Training loss: 0.0965\n",
      "Epoch: 9/20... Training loss: 0.0963\n",
      "Epoch: 9/20... Training loss: 0.0991\n",
      "Epoch: 9/20... Training loss: 0.0995\n",
      "Epoch: 9/20... Training loss: 0.0989\n",
      "Epoch: 9/20... Training loss: 0.0983\n",
      "Epoch: 9/20... Training loss: 0.0955\n",
      "Epoch: 9/20... Training loss: 0.0962\n",
      "Epoch: 9/20... Training loss: 0.0966\n",
      "Epoch: 9/20... Training loss: 0.0991\n",
      "Epoch: 9/20... Training loss: 0.0963\n",
      "Epoch: 9/20... Training loss: 0.0996\n",
      "Epoch: 9/20... Training loss: 0.0943\n",
      "Epoch: 9/20... Training loss: 0.0962\n",
      "Epoch: 9/20... Training loss: 0.0952\n",
      "Epoch: 9/20... Training loss: 0.0955\n",
      "Epoch: 9/20... Training loss: 0.0968\n",
      "Epoch: 9/20... Training loss: 0.0991\n",
      "Epoch: 9/20... Training loss: 0.0975\n",
      "Epoch: 9/20... Training loss: 0.0977\n",
      "Epoch: 9/20... Training loss: 0.1001\n",
      "Epoch: 9/20... Training loss: 0.0955\n",
      "Epoch: 9/20... Training loss: 0.1010\n",
      "Epoch: 9/20... Training loss: 0.0943\n",
      "Epoch: 9/20... Training loss: 0.0977\n",
      "Epoch: 9/20... Training loss: 0.0966\n",
      "Epoch: 9/20... Training loss: 0.0977\n",
      "Epoch: 9/20... Training loss: 0.0965\n",
      "Epoch: 9/20... Training loss: 0.0973\n",
      "Epoch: 9/20... Training loss: 0.0990\n",
      "Epoch: 9/20... Training loss: 0.1001\n",
      "Epoch: 9/20... Training loss: 0.0964\n",
      "Epoch: 9/20... Training loss: 0.0949\n",
      "Epoch: 9/20... Training loss: 0.0989\n",
      "Epoch: 9/20... Training loss: 0.0981\n",
      "Epoch: 9/20... Training loss: 0.0942\n",
      "Epoch: 9/20... Training loss: 0.0978\n",
      "Epoch: 9/20... Training loss: 0.0995\n",
      "Epoch: 9/20... Training loss: 0.1021\n",
      "Epoch: 9/20... Training loss: 0.0987\n",
      "Epoch: 9/20... Training loss: 0.0946\n",
      "Epoch: 9/20... Training loss: 0.0968\n",
      "Epoch: 9/20... Training loss: 0.0977\n",
      "Epoch: 9/20... Training loss: 0.0941\n",
      "Epoch: 9/20... Training loss: 0.0971\n",
      "Epoch: 9/20... Training loss: 0.0960\n",
      "Epoch: 9/20... Training loss: 0.0961\n",
      "Epoch: 9/20... Training loss: 0.0987\n",
      "Epoch: 9/20... Training loss: 0.0997\n",
      "Epoch: 9/20... Training loss: 0.0944\n",
      "Epoch: 9/20... Training loss: 0.0966\n",
      "Epoch: 9/20... Training loss: 0.0946\n",
      "Epoch: 9/20... Training loss: 0.0938\n",
      "Epoch: 9/20... Training loss: 0.0994\n",
      "Epoch: 9/20... Training loss: 0.0967\n",
      "Epoch: 9/20... Training loss: 0.0951\n",
      "Epoch: 9/20... Training loss: 0.0972\n",
      "Epoch: 9/20... Training loss: 0.0936\n",
      "Epoch: 9/20... Training loss: 0.0970\n",
      "Epoch: 9/20... Training loss: 0.1000\n",
      "Epoch: 9/20... Training loss: 0.0975\n",
      "Epoch: 9/20... Training loss: 0.0997\n",
      "Epoch: 9/20... Training loss: 0.1017\n",
      "Epoch: 9/20... Training loss: 0.0978\n",
      "Epoch: 9/20... Training loss: 0.0961\n",
      "Epoch: 9/20... Training loss: 0.0959\n",
      "Epoch: 9/20... Training loss: 0.0985\n",
      "Epoch: 9/20... Training loss: 0.0958\n",
      "Epoch: 9/20... Training loss: 0.0975\n",
      "Epoch: 9/20... Training loss: 0.0937\n",
      "Epoch: 9/20... Training loss: 0.0974\n",
      "Epoch: 9/20... Training loss: 0.0996\n",
      "Epoch: 9/20... Training loss: 0.0940\n",
      "Epoch: 9/20... Training loss: 0.0977\n",
      "Epoch: 9/20... Training loss: 0.0963\n",
      "Epoch: 9/20... Training loss: 0.0964\n",
      "Epoch: 9/20... Training loss: 0.0958\n",
      "Epoch: 9/20... Training loss: 0.0972\n",
      "Epoch: 9/20... Training loss: 0.0986\n",
      "Epoch: 9/20... Training loss: 0.0935\n",
      "Epoch: 9/20... Training loss: 0.0976\n",
      "Epoch: 9/20... Training loss: 0.0980\n",
      "Epoch: 9/20... Training loss: 0.0971\n",
      "Epoch: 9/20... Training loss: 0.0944\n",
      "Epoch: 9/20... Training loss: 0.0972\n",
      "Epoch: 9/20... Training loss: 0.0979\n",
      "Epoch: 9/20... Training loss: 0.0952\n",
      "Epoch: 9/20... Training loss: 0.0964\n",
      "Epoch: 9/20... Training loss: 0.0983\n",
      "Epoch: 9/20... Training loss: 0.0958\n",
      "Epoch: 9/20... Training loss: 0.0979\n",
      "Epoch: 9/20... Training loss: 0.0970\n",
      "Epoch: 9/20... Training loss: 0.0969\n",
      "Epoch: 9/20... Training loss: 0.0973\n",
      "Epoch: 9/20... Training loss: 0.0979\n",
      "Epoch: 9/20... Training loss: 0.0988\n",
      "Epoch: 9/20... Training loss: 0.0950\n",
      "Epoch: 9/20... Training loss: 0.0953\n",
      "Epoch: 9/20... Training loss: 0.0970\n",
      "Epoch: 9/20... Training loss: 0.0975\n",
      "Epoch: 9/20... Training loss: 0.0935\n",
      "Epoch: 9/20... Training loss: 0.0983\n",
      "Epoch: 9/20... Training loss: 0.0947\n",
      "Epoch: 9/20... Training loss: 0.1007\n",
      "Epoch: 9/20... Training loss: 0.0972\n",
      "Epoch: 9/20... Training loss: 0.0998\n",
      "Epoch: 9/20... Training loss: 0.0961\n",
      "Epoch: 9/20... Training loss: 0.0989\n",
      "Epoch: 9/20... Training loss: 0.0962\n",
      "Epoch: 9/20... Training loss: 0.1001\n",
      "Epoch: 9/20... Training loss: 0.1014\n",
      "Epoch: 9/20... Training loss: 0.0978\n",
      "Epoch: 9/20... Training loss: 0.0946\n",
      "Epoch: 9/20... Training loss: 0.0987\n",
      "Epoch: 9/20... Training loss: 0.0996\n",
      "Epoch: 9/20... Training loss: 0.0978\n",
      "Epoch: 9/20... Training loss: 0.0967\n",
      "Epoch: 9/20... Training loss: 0.0948\n",
      "Epoch: 9/20... Training loss: 0.0930\n",
      "Epoch: 9/20... Training loss: 0.0964\n",
      "Epoch: 9/20... Training loss: 0.0974\n",
      "Epoch: 9/20... Training loss: 0.0972\n",
      "Epoch: 9/20... Training loss: 0.0965\n",
      "Epoch: 9/20... Training loss: 0.0970\n",
      "Epoch: 9/20... Training loss: 0.0971\n",
      "Epoch: 9/20... Training loss: 0.0992\n",
      "Epoch: 9/20... Training loss: 0.0975\n",
      "Epoch: 9/20... Training loss: 0.0978\n",
      "Epoch: 9/20... Training loss: 0.0971\n",
      "Epoch: 9/20... Training loss: 0.0955\n",
      "Epoch: 9/20... Training loss: 0.0945\n",
      "Epoch: 9/20... Training loss: 0.0947\n",
      "Epoch: 9/20... Training loss: 0.0954\n",
      "Epoch: 9/20... Training loss: 0.0976\n",
      "Epoch: 9/20... Training loss: 0.0972\n",
      "Epoch: 9/20... Training loss: 0.0976\n",
      "Epoch: 9/20... Training loss: 0.0945\n",
      "Epoch: 9/20... Training loss: 0.0961\n",
      "Epoch: 9/20... Training loss: 0.0952\n",
      "Epoch: 9/20... Training loss: 0.0993\n",
      "Epoch: 9/20... Training loss: 0.0974\n",
      "Epoch: 9/20... Training loss: 0.0956\n",
      "Epoch: 9/20... Training loss: 0.0996\n",
      "Epoch: 9/20... Training loss: 0.0966\n",
      "Epoch: 9/20... Training loss: 0.0966\n",
      "Epoch: 9/20... Training loss: 0.0982\n",
      "Epoch: 9/20... Training loss: 0.0971\n",
      "Epoch: 9/20... Training loss: 0.0966\n",
      "Epoch: 9/20... Training loss: 0.0947\n",
      "Epoch: 9/20... Training loss: 0.1038\n",
      "Epoch: 9/20... Training loss: 0.0964\n",
      "Epoch: 9/20... Training loss: 0.1011\n",
      "Epoch: 9/20... Training loss: 0.0959\n",
      "Epoch: 9/20... Training loss: 0.0948\n",
      "Epoch: 9/20... Training loss: 0.0968\n",
      "Epoch: 9/20... Training loss: 0.0968\n",
      "Epoch: 9/20... Training loss: 0.0974\n",
      "Epoch: 9/20... Training loss: 0.0937\n",
      "Epoch: 9/20... Training loss: 0.0959\n",
      "Epoch: 9/20... Training loss: 0.0923\n",
      "Epoch: 9/20... Training loss: 0.0960\n",
      "Epoch: 9/20... Training loss: 0.0956\n",
      "Epoch: 9/20... Training loss: 0.0927\n",
      "Epoch: 9/20... Training loss: 0.0986\n",
      "Epoch: 9/20... Training loss: 0.0946\n",
      "Epoch: 9/20... Training loss: 0.0953\n",
      "Epoch: 9/20... Training loss: 0.0980\n",
      "Epoch: 9/20... Training loss: 0.0939\n",
      "Epoch: 9/20... Training loss: 0.0956\n",
      "Epoch: 9/20... Training loss: 0.0965\n",
      "Epoch: 9/20... Training loss: 0.0984\n",
      "Epoch: 9/20... Training loss: 0.0986\n",
      "Epoch: 9/20... Training loss: 0.0995\n",
      "Epoch: 9/20... Training loss: 0.0948\n",
      "Epoch: 9/20... Training loss: 0.0961\n",
      "Epoch: 9/20... Training loss: 0.0975\n",
      "Epoch: 9/20... Training loss: 0.0957\n",
      "Epoch: 9/20... Training loss: 0.0985\n",
      "Epoch: 9/20... Training loss: 0.0943\n",
      "Epoch: 9/20... Training loss: 0.0949\n",
      "Epoch: 9/20... Training loss: 0.0952\n",
      "Epoch: 9/20... Training loss: 0.0972\n",
      "Epoch: 9/20... Training loss: 0.0970\n",
      "Epoch: 9/20... Training loss: 0.0974\n",
      "Epoch: 9/20... Training loss: 0.0939\n",
      "Epoch: 9/20... Training loss: 0.0965\n",
      "Epoch: 9/20... Training loss: 0.0927\n",
      "Epoch: 9/20... Training loss: 0.0966\n",
      "Epoch: 9/20... Training loss: 0.0962\n",
      "Epoch: 9/20... Training loss: 0.1018\n",
      "Epoch: 9/20... Training loss: 0.0978\n",
      "Epoch: 9/20... Training loss: 0.0976\n",
      "Epoch: 9/20... Training loss: 0.0950\n",
      "Epoch: 9/20... Training loss: 0.0972\n",
      "Epoch: 9/20... Training loss: 0.0979\n",
      "Epoch: 9/20... Training loss: 0.0976\n",
      "Epoch: 9/20... Training loss: 0.0959\n",
      "Epoch: 9/20... Training loss: 0.0914\n",
      "Epoch: 9/20... Training loss: 0.0931\n",
      "Epoch: 9/20... Training loss: 0.0958\n",
      "Epoch: 9/20... Training loss: 0.0967\n",
      "Epoch: 9/20... Training loss: 0.0978\n",
      "Epoch: 9/20... Training loss: 0.0988\n",
      "Epoch: 9/20... Training loss: 0.0958\n",
      "Epoch: 9/20... Training loss: 0.0982\n",
      "Epoch: 9/20... Training loss: 0.0960\n",
      "Epoch: 9/20... Training loss: 0.0947\n",
      "Epoch: 9/20... Training loss: 0.0937\n",
      "Epoch: 9/20... Training loss: 0.0922\n",
      "Epoch: 9/20... Training loss: 0.0977\n",
      "Epoch: 9/20... Training loss: 0.0965\n",
      "Epoch: 9/20... Training loss: 0.1000\n",
      "Epoch: 9/20... Training loss: 0.0962\n",
      "Epoch: 9/20... Training loss: 0.0969\n",
      "Epoch: 9/20... Training loss: 0.0957\n",
      "Epoch: 9/20... Training loss: 0.0979\n",
      "Epoch: 9/20... Training loss: 0.0955\n",
      "Epoch: 9/20... Training loss: 0.0981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/20... Training loss: 0.0947\n",
      "Epoch: 9/20... Training loss: 0.1007\n",
      "Epoch: 9/20... Training loss: 0.0951\n",
      "Epoch: 9/20... Training loss: 0.0943\n",
      "Epoch: 9/20... Training loss: 0.0981\n",
      "Epoch: 9/20... Training loss: 0.0965\n",
      "Epoch: 9/20... Training loss: 0.0954\n",
      "Epoch: 9/20... Training loss: 0.0930\n",
      "Epoch: 9/20... Training loss: 0.0996\n",
      "Epoch: 9/20... Training loss: 0.0963\n",
      "Epoch: 9/20... Training loss: 0.0997\n",
      "Epoch: 9/20... Training loss: 0.0973\n",
      "Epoch: 9/20... Training loss: 0.0944\n",
      "Epoch: 9/20... Training loss: 0.0987\n",
      "Epoch: 9/20... Training loss: 0.0941\n",
      "Epoch: 9/20... Training loss: 0.0979\n",
      "Epoch: 9/20... Training loss: 0.0976\n",
      "Epoch: 9/20... Training loss: 0.0974\n",
      "Epoch: 9/20... Training loss: 0.0955\n",
      "Epoch: 9/20... Training loss: 0.0941\n",
      "Epoch: 9/20... Training loss: 0.0985\n",
      "Epoch: 9/20... Training loss: 0.0976\n",
      "Epoch: 9/20... Training loss: 0.0920\n",
      "Epoch: 9/20... Training loss: 0.0959\n",
      "Epoch: 9/20... Training loss: 0.0950\n",
      "Epoch: 9/20... Training loss: 0.0981\n",
      "Epoch: 9/20... Training loss: 0.0941\n",
      "Epoch: 9/20... Training loss: 0.0985\n",
      "Epoch: 9/20... Training loss: 0.0940\n",
      "Epoch: 9/20... Training loss: 0.0955\n",
      "Epoch: 9/20... Training loss: 0.0947\n",
      "Epoch: 9/20... Training loss: 0.0960\n",
      "Epoch: 9/20... Training loss: 0.0954\n",
      "Epoch: 9/20... Training loss: 0.0982\n",
      "Epoch: 9/20... Training loss: 0.0945\n",
      "Epoch: 9/20... Training loss: 0.0963\n",
      "Epoch: 9/20... Training loss: 0.0966\n",
      "Epoch: 9/20... Training loss: 0.0972\n",
      "Epoch: 9/20... Training loss: 0.0953\n",
      "Epoch: 9/20... Training loss: 0.0934\n",
      "Epoch: 9/20... Training loss: 0.0936\n",
      "Epoch: 9/20... Training loss: 0.1017\n",
      "Epoch: 9/20... Training loss: 0.0967\n",
      "Epoch: 9/20... Training loss: 0.0956\n",
      "Epoch: 9/20... Training loss: 0.0952\n",
      "Epoch: 9/20... Training loss: 0.0954\n",
      "Epoch: 9/20... Training loss: 0.0977\n",
      "Epoch: 9/20... Training loss: 0.0962\n",
      "Epoch: 10/20... Training loss: 0.0988\n",
      "Epoch: 10/20... Training loss: 0.0962\n",
      "Epoch: 10/20... Training loss: 0.0947\n",
      "Epoch: 10/20... Training loss: 0.0985\n",
      "Epoch: 10/20... Training loss: 0.0961\n",
      "Epoch: 10/20... Training loss: 0.0943\n",
      "Epoch: 10/20... Training loss: 0.0941\n",
      "Epoch: 10/20... Training loss: 0.0962\n",
      "Epoch: 10/20... Training loss: 0.0932\n",
      "Epoch: 10/20... Training loss: 0.0957\n",
      "Epoch: 10/20... Training loss: 0.0985\n",
      "Epoch: 10/20... Training loss: 0.0976\n",
      "Epoch: 10/20... Training loss: 0.0977\n",
      "Epoch: 10/20... Training loss: 0.0969\n",
      "Epoch: 10/20... Training loss: 0.0942\n",
      "Epoch: 10/20... Training loss: 0.0961\n",
      "Epoch: 10/20... Training loss: 0.0974\n",
      "Epoch: 10/20... Training loss: 0.0937\n",
      "Epoch: 10/20... Training loss: 0.0935\n",
      "Epoch: 10/20... Training loss: 0.0963\n",
      "Epoch: 10/20... Training loss: 0.0953\n",
      "Epoch: 10/20... Training loss: 0.0954\n",
      "Epoch: 10/20... Training loss: 0.0976\n",
      "Epoch: 10/20... Training loss: 0.0977\n",
      "Epoch: 10/20... Training loss: 0.0941\n",
      "Epoch: 10/20... Training loss: 0.0961\n",
      "Epoch: 10/20... Training loss: 0.0932\n",
      "Epoch: 10/20... Training loss: 0.0971\n",
      "Epoch: 10/20... Training loss: 0.0959\n",
      "Epoch: 10/20... Training loss: 0.0928\n",
      "Epoch: 10/20... Training loss: 0.0905\n",
      "Epoch: 10/20... Training loss: 0.0974\n",
      "Epoch: 10/20... Training loss: 0.0959\n",
      "Epoch: 10/20... Training loss: 0.0968\n",
      "Epoch: 10/20... Training loss: 0.0936\n",
      "Epoch: 10/20... Training loss: 0.0906\n",
      "Epoch: 10/20... Training loss: 0.0961\n",
      "Epoch: 10/20... Training loss: 0.0941\n",
      "Epoch: 10/20... Training loss: 0.0929\n",
      "Epoch: 10/20... Training loss: 0.0945\n",
      "Epoch: 10/20... Training loss: 0.0925\n",
      "Epoch: 10/20... Training loss: 0.0950\n",
      "Epoch: 10/20... Training loss: 0.0976\n",
      "Epoch: 10/20... Training loss: 0.0961\n",
      "Epoch: 10/20... Training loss: 0.0952\n",
      "Epoch: 10/20... Training loss: 0.0952\n",
      "Epoch: 10/20... Training loss: 0.0965\n",
      "Epoch: 10/20... Training loss: 0.0970\n",
      "Epoch: 10/20... Training loss: 0.0997\n",
      "Epoch: 10/20... Training loss: 0.0960\n",
      "Epoch: 10/20... Training loss: 0.0967\n",
      "Epoch: 10/20... Training loss: 0.0933\n",
      "Epoch: 10/20... Training loss: 0.0936\n",
      "Epoch: 10/20... Training loss: 0.0978\n",
      "Epoch: 10/20... Training loss: 0.0931\n",
      "Epoch: 10/20... Training loss: 0.0976\n",
      "Epoch: 10/20... Training loss: 0.0959\n",
      "Epoch: 10/20... Training loss: 0.0963\n",
      "Epoch: 10/20... Training loss: 0.0975\n",
      "Epoch: 10/20... Training loss: 0.0950\n",
      "Epoch: 10/20... Training loss: 0.0933\n",
      "Epoch: 10/20... Training loss: 0.0963\n",
      "Epoch: 10/20... Training loss: 0.0968\n",
      "Epoch: 10/20... Training loss: 0.0972\n",
      "Epoch: 10/20... Training loss: 0.0944\n",
      "Epoch: 10/20... Training loss: 0.0934\n",
      "Epoch: 10/20... Training loss: 0.0946\n",
      "Epoch: 10/20... Training loss: 0.0925\n",
      "Epoch: 10/20... Training loss: 0.0957\n",
      "Epoch: 10/20... Training loss: 0.0952\n",
      "Epoch: 10/20... Training loss: 0.0967\n",
      "Epoch: 10/20... Training loss: 0.0981\n",
      "Epoch: 10/20... Training loss: 0.0940\n",
      "Epoch: 10/20... Training loss: 0.0961\n",
      "Epoch: 10/20... Training loss: 0.0929\n",
      "Epoch: 10/20... Training loss: 0.0927\n",
      "Epoch: 10/20... Training loss: 0.0956\n",
      "Epoch: 10/20... Training loss: 0.0953\n",
      "Epoch: 10/20... Training loss: 0.0948\n",
      "Epoch: 10/20... Training loss: 0.0965\n",
      "Epoch: 10/20... Training loss: 0.0961\n",
      "Epoch: 10/20... Training loss: 0.0960\n",
      "Epoch: 10/20... Training loss: 0.0981\n",
      "Epoch: 10/20... Training loss: 0.0961\n",
      "Epoch: 10/20... Training loss: 0.0967\n",
      "Epoch: 10/20... Training loss: 0.0974\n",
      "Epoch: 10/20... Training loss: 0.0957\n",
      "Epoch: 10/20... Training loss: 0.0979\n",
      "Epoch: 10/20... Training loss: 0.0965\n",
      "Epoch: 10/20... Training loss: 0.0964\n",
      "Epoch: 10/20... Training loss: 0.0974\n",
      "Epoch: 10/20... Training loss: 0.0946\n",
      "Epoch: 10/20... Training loss: 0.0952\n",
      "Epoch: 10/20... Training loss: 0.0955\n",
      "Epoch: 10/20... Training loss: 0.0994\n",
      "Epoch: 10/20... Training loss: 0.0980\n",
      "Epoch: 10/20... Training loss: 0.0968\n",
      "Epoch: 10/20... Training loss: 0.0961\n",
      "Epoch: 10/20... Training loss: 0.0952\n",
      "Epoch: 10/20... Training loss: 0.0977\n",
      "Epoch: 10/20... Training loss: 0.0914\n",
      "Epoch: 10/20... Training loss: 0.0960\n",
      "Epoch: 10/20... Training loss: 0.0946\n",
      "Epoch: 10/20... Training loss: 0.0977\n",
      "Epoch: 10/20... Training loss: 0.0958\n",
      "Epoch: 10/20... Training loss: 0.0972\n",
      "Epoch: 10/20... Training loss: 0.0973\n",
      "Epoch: 10/20... Training loss: 0.0939\n",
      "Epoch: 10/20... Training loss: 0.0957\n",
      "Epoch: 10/20... Training loss: 0.0967\n",
      "Epoch: 10/20... Training loss: 0.0966\n",
      "Epoch: 10/20... Training loss: 0.0933\n",
      "Epoch: 10/20... Training loss: 0.0947\n",
      "Epoch: 10/20... Training loss: 0.0939\n",
      "Epoch: 10/20... Training loss: 0.0945\n",
      "Epoch: 10/20... Training loss: 0.0963\n",
      "Epoch: 10/20... Training loss: 0.0995\n",
      "Epoch: 10/20... Training loss: 0.0896\n",
      "Epoch: 10/20... Training loss: 0.0928\n",
      "Epoch: 10/20... Training loss: 0.0975\n",
      "Epoch: 10/20... Training loss: 0.0992\n",
      "Epoch: 10/20... Training loss: 0.0968\n",
      "Epoch: 10/20... Training loss: 0.0959\n",
      "Epoch: 10/20... Training loss: 0.0957\n",
      "Epoch: 10/20... Training loss: 0.0968\n",
      "Epoch: 10/20... Training loss: 0.0971\n",
      "Epoch: 10/20... Training loss: 0.0960\n",
      "Epoch: 10/20... Training loss: 0.0952\n",
      "Epoch: 10/20... Training loss: 0.0969\n",
      "Epoch: 10/20... Training loss: 0.0965\n",
      "Epoch: 10/20... Training loss: 0.0966\n",
      "Epoch: 10/20... Training loss: 0.0972\n",
      "Epoch: 10/20... Training loss: 0.0966\n",
      "Epoch: 10/20... Training loss: 0.0975\n",
      "Epoch: 10/20... Training loss: 0.0945\n",
      "Epoch: 10/20... Training loss: 0.0959\n",
      "Epoch: 10/20... Training loss: 0.0964\n",
      "Epoch: 10/20... Training loss: 0.0967\n",
      "Epoch: 10/20... Training loss: 0.0985\n",
      "Epoch: 10/20... Training loss: 0.0964\n",
      "Epoch: 10/20... Training loss: 0.0969\n",
      "Epoch: 10/20... Training loss: 0.0974\n",
      "Epoch: 10/20... Training loss: 0.0996\n",
      "Epoch: 10/20... Training loss: 0.0947\n",
      "Epoch: 10/20... Training loss: 0.0975\n",
      "Epoch: 10/20... Training loss: 0.0993\n",
      "Epoch: 10/20... Training loss: 0.0948\n",
      "Epoch: 10/20... Training loss: 0.0954\n",
      "Epoch: 10/20... Training loss: 0.0957\n",
      "Epoch: 10/20... Training loss: 0.0955\n",
      "Epoch: 10/20... Training loss: 0.0983\n",
      "Epoch: 10/20... Training loss: 0.0942\n",
      "Epoch: 10/20... Training loss: 0.0970\n",
      "Epoch: 10/20... Training loss: 0.0948\n",
      "Epoch: 10/20... Training loss: 0.0946\n",
      "Epoch: 10/20... Training loss: 0.0959\n",
      "Epoch: 10/20... Training loss: 0.0972\n",
      "Epoch: 10/20... Training loss: 0.0975\n",
      "Epoch: 10/20... Training loss: 0.0941\n",
      "Epoch: 10/20... Training loss: 0.0937\n",
      "Epoch: 10/20... Training loss: 0.0948\n",
      "Epoch: 10/20... Training loss: 0.0944\n",
      "Epoch: 10/20... Training loss: 0.0938\n",
      "Epoch: 10/20... Training loss: 0.0962\n",
      "Epoch: 10/20... Training loss: 0.0984\n",
      "Epoch: 10/20... Training loss: 0.0949\n",
      "Epoch: 10/20... Training loss: 0.0938\n",
      "Epoch: 10/20... Training loss: 0.0952\n",
      "Epoch: 10/20... Training loss: 0.0949\n",
      "Epoch: 10/20... Training loss: 0.0906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/20... Training loss: 0.0935\n",
      "Epoch: 10/20... Training loss: 0.0976\n",
      "Epoch: 10/20... Training loss: 0.0972\n",
      "Epoch: 10/20... Training loss: 0.0970\n",
      "Epoch: 10/20... Training loss: 0.0970\n",
      "Epoch: 10/20... Training loss: 0.0947\n",
      "Epoch: 10/20... Training loss: 0.0954\n",
      "Epoch: 10/20... Training loss: 0.0962\n",
      "Epoch: 10/20... Training loss: 0.0953\n",
      "Epoch: 10/20... Training loss: 0.0939\n",
      "Epoch: 10/20... Training loss: 0.0975\n",
      "Epoch: 10/20... Training loss: 0.0939\n",
      "Epoch: 10/20... Training loss: 0.0962\n",
      "Epoch: 10/20... Training loss: 0.0942\n",
      "Epoch: 10/20... Training loss: 0.0977\n",
      "Epoch: 10/20... Training loss: 0.0948\n",
      "Epoch: 10/20... Training loss: 0.0959\n",
      "Epoch: 10/20... Training loss: 0.0958\n",
      "Epoch: 10/20... Training loss: 0.0978\n",
      "Epoch: 10/20... Training loss: 0.0990\n",
      "Epoch: 10/20... Training loss: 0.0966\n",
      "Epoch: 10/20... Training loss: 0.0947\n",
      "Epoch: 10/20... Training loss: 0.0920\n",
      "Epoch: 10/20... Training loss: 0.0952\n",
      "Epoch: 10/20... Training loss: 0.0981\n",
      "Epoch: 10/20... Training loss: 0.0964\n",
      "Epoch: 10/20... Training loss: 0.0948\n",
      "Epoch: 10/20... Training loss: 0.0947\n",
      "Epoch: 10/20... Training loss: 0.0935\n",
      "Epoch: 10/20... Training loss: 0.0968\n",
      "Epoch: 10/20... Training loss: 0.0980\n",
      "Epoch: 10/20... Training loss: 0.0904\n",
      "Epoch: 10/20... Training loss: 0.0935\n",
      "Epoch: 10/20... Training loss: 0.0943\n",
      "Epoch: 10/20... Training loss: 0.0951\n",
      "Epoch: 10/20... Training loss: 0.0980\n",
      "Epoch: 10/20... Training loss: 0.0942\n",
      "Epoch: 10/20... Training loss: 0.0972\n",
      "Epoch: 10/20... Training loss: 0.0934\n",
      "Epoch: 10/20... Training loss: 0.0951\n",
      "Epoch: 10/20... Training loss: 0.0943\n",
      "Epoch: 10/20... Training loss: 0.0936\n",
      "Epoch: 10/20... Training loss: 0.0966\n",
      "Epoch: 10/20... Training loss: 0.0932\n",
      "Epoch: 10/20... Training loss: 0.0921\n",
      "Epoch: 10/20... Training loss: 0.0990\n",
      "Epoch: 10/20... Training loss: 0.0928\n",
      "Epoch: 10/20... Training loss: 0.0911\n",
      "Epoch: 10/20... Training loss: 0.1001\n",
      "Epoch: 10/20... Training loss: 0.0969\n",
      "Epoch: 10/20... Training loss: 0.0993\n",
      "Epoch: 10/20... Training loss: 0.0963\n",
      "Epoch: 10/20... Training loss: 0.0929\n",
      "Epoch: 10/20... Training loss: 0.0965\n",
      "Epoch: 10/20... Training loss: 0.0976\n",
      "Epoch: 10/20... Training loss: 0.0969\n",
      "Epoch: 10/20... Training loss: 0.0962\n",
      "Epoch: 10/20... Training loss: 0.0980\n",
      "Epoch: 10/20... Training loss: 0.0971\n",
      "Epoch: 10/20... Training loss: 0.0952\n",
      "Epoch: 10/20... Training loss: 0.0954\n",
      "Epoch: 10/20... Training loss: 0.0953\n",
      "Epoch: 10/20... Training loss: 0.0929\n",
      "Epoch: 10/20... Training loss: 0.0965\n",
      "Epoch: 10/20... Training loss: 0.0981\n",
      "Epoch: 10/20... Training loss: 0.0947\n",
      "Epoch: 10/20... Training loss: 0.0952\n",
      "Epoch: 10/20... Training loss: 0.0937\n",
      "Epoch: 10/20... Training loss: 0.0956\n",
      "Epoch: 10/20... Training loss: 0.0969\n",
      "Epoch: 10/20... Training loss: 0.0946\n",
      "Epoch: 10/20... Training loss: 0.0972\n",
      "Epoch: 10/20... Training loss: 0.0925\n",
      "Epoch: 10/20... Training loss: 0.0984\n",
      "Epoch: 10/20... Training loss: 0.0963\n",
      "Epoch: 10/20... Training loss: 0.0984\n",
      "Epoch: 10/20... Training loss: 0.0974\n",
      "Epoch: 10/20... Training loss: 0.0968\n",
      "Epoch: 10/20... Training loss: 0.0928\n",
      "Epoch: 10/20... Training loss: 0.0987\n",
      "Epoch: 10/20... Training loss: 0.0975\n",
      "Epoch: 10/20... Training loss: 0.0974\n",
      "Epoch: 10/20... Training loss: 0.0980\n",
      "Epoch: 10/20... Training loss: 0.0962\n",
      "Epoch: 10/20... Training loss: 0.0952\n",
      "Epoch: 10/20... Training loss: 0.0980\n",
      "Epoch: 10/20... Training loss: 0.0905\n",
      "Epoch: 10/20... Training loss: 0.0958\n",
      "Epoch: 10/20... Training loss: 0.0958\n",
      "Epoch: 10/20... Training loss: 0.0954\n",
      "Epoch: 10/20... Training loss: 0.0975\n",
      "Epoch: 10/20... Training loss: 0.0972\n",
      "Epoch: 10/20... Training loss: 0.0951\n",
      "Epoch: 10/20... Training loss: 0.0945\n",
      "Epoch: 10/20... Training loss: 0.0962\n",
      "Epoch: 10/20... Training loss: 0.0990\n",
      "Epoch: 10/20... Training loss: 0.0974\n",
      "Epoch: 10/20... Training loss: 0.0963\n",
      "Epoch: 10/20... Training loss: 0.0924\n",
      "Epoch: 10/20... Training loss: 0.0975\n",
      "Epoch: 10/20... Training loss: 0.0971\n",
      "Epoch: 10/20... Training loss: 0.0950\n",
      "Epoch: 10/20... Training loss: 0.0940\n",
      "Epoch: 10/20... Training loss: 0.0950\n",
      "Epoch: 10/20... Training loss: 0.0920\n",
      "Epoch: 10/20... Training loss: 0.0951\n",
      "Epoch: 10/20... Training loss: 0.0948\n",
      "Epoch: 10/20... Training loss: 0.1003\n",
      "Epoch: 10/20... Training loss: 0.0931\n",
      "Epoch: 10/20... Training loss: 0.0964\n",
      "Epoch: 10/20... Training loss: 0.0960\n",
      "Epoch: 10/20... Training loss: 0.0980\n",
      "Epoch: 10/20... Training loss: 0.0937\n",
      "Epoch: 10/20... Training loss: 0.0970\n",
      "Epoch: 10/20... Training loss: 0.0950\n",
      "Epoch: 10/20... Training loss: 0.0952\n",
      "Epoch: 10/20... Training loss: 0.0956\n",
      "Epoch: 10/20... Training loss: 0.0959\n",
      "Epoch: 10/20... Training loss: 0.0911\n",
      "Epoch: 10/20... Training loss: 0.0967\n",
      "Epoch: 10/20... Training loss: 0.0918\n",
      "Epoch: 10/20... Training loss: 0.0954\n",
      "Epoch: 10/20... Training loss: 0.0961\n",
      "Epoch: 10/20... Training loss: 0.0980\n",
      "Epoch: 10/20... Training loss: 0.0945\n",
      "Epoch: 10/20... Training loss: 0.0960\n",
      "Epoch: 10/20... Training loss: 0.0956\n",
      "Epoch: 10/20... Training loss: 0.0931\n",
      "Epoch: 10/20... Training loss: 0.0948\n",
      "Epoch: 10/20... Training loss: 0.0949\n",
      "Epoch: 11/20... Training loss: 0.0955\n",
      "Epoch: 11/20... Training loss: 0.0975\n",
      "Epoch: 11/20... Training loss: 0.0953\n",
      "Epoch: 11/20... Training loss: 0.0965\n",
      "Epoch: 11/20... Training loss: 0.0953\n",
      "Epoch: 11/20... Training loss: 0.0962\n",
      "Epoch: 11/20... Training loss: 0.0953\n",
      "Epoch: 11/20... Training loss: 0.0987\n",
      "Epoch: 11/20... Training loss: 0.0904\n",
      "Epoch: 11/20... Training loss: 0.0936\n",
      "Epoch: 11/20... Training loss: 0.0954\n",
      "Epoch: 11/20... Training loss: 0.0952\n",
      "Epoch: 11/20... Training loss: 0.0949\n",
      "Epoch: 11/20... Training loss: 0.0919\n",
      "Epoch: 11/20... Training loss: 0.0958\n",
      "Epoch: 11/20... Training loss: 0.0984\n",
      "Epoch: 11/20... Training loss: 0.0940\n",
      "Epoch: 11/20... Training loss: 0.0965\n",
      "Epoch: 11/20... Training loss: 0.0915\n",
      "Epoch: 11/20... Training loss: 0.0964\n",
      "Epoch: 11/20... Training loss: 0.0945\n",
      "Epoch: 11/20... Training loss: 0.0979\n",
      "Epoch: 11/20... Training loss: 0.0953\n",
      "Epoch: 11/20... Training loss: 0.0928\n",
      "Epoch: 11/20... Training loss: 0.0963\n",
      "Epoch: 11/20... Training loss: 0.0949\n",
      "Epoch: 11/20... Training loss: 0.0915\n",
      "Epoch: 11/20... Training loss: 0.0943\n",
      "Epoch: 11/20... Training loss: 0.0953\n",
      "Epoch: 11/20... Training loss: 0.0971\n",
      "Epoch: 11/20... Training loss: 0.0953\n",
      "Epoch: 11/20... Training loss: 0.0988\n",
      "Epoch: 11/20... Training loss: 0.0984\n",
      "Epoch: 11/20... Training loss: 0.0935\n",
      "Epoch: 11/20... Training loss: 0.0961\n",
      "Epoch: 11/20... Training loss: 0.0968\n",
      "Epoch: 11/20... Training loss: 0.0992\n",
      "Epoch: 11/20... Training loss: 0.0926\n",
      "Epoch: 11/20... Training loss: 0.0961\n",
      "Epoch: 11/20... Training loss: 0.0937\n",
      "Epoch: 11/20... Training loss: 0.0937\n",
      "Epoch: 11/20... Training loss: 0.0957\n",
      "Epoch: 11/20... Training loss: 0.0947\n",
      "Epoch: 11/20... Training loss: 0.0912\n",
      "Epoch: 11/20... Training loss: 0.0984\n",
      "Epoch: 11/20... Training loss: 0.0974\n",
      "Epoch: 11/20... Training loss: 0.0971\n",
      "Epoch: 11/20... Training loss: 0.0932\n",
      "Epoch: 11/20... Training loss: 0.0942\n",
      "Epoch: 11/20... Training loss: 0.0972\n",
      "Epoch: 11/20... Training loss: 0.0973\n",
      "Epoch: 11/20... Training loss: 0.0918\n",
      "Epoch: 11/20... Training loss: 0.0937\n",
      "Epoch: 11/20... Training loss: 0.0941\n",
      "Epoch: 11/20... Training loss: 0.0933\n",
      "Epoch: 11/20... Training loss: 0.0940\n",
      "Epoch: 11/20... Training loss: 0.0972\n",
      "Epoch: 11/20... Training loss: 0.0988\n",
      "Epoch: 11/20... Training loss: 0.0943\n",
      "Epoch: 11/20... Training loss: 0.0931\n",
      "Epoch: 11/20... Training loss: 0.0956\n",
      "Epoch: 11/20... Training loss: 0.0950\n",
      "Epoch: 11/20... Training loss: 0.0940\n",
      "Epoch: 11/20... Training loss: 0.0962\n",
      "Epoch: 11/20... Training loss: 0.0931\n",
      "Epoch: 11/20... Training loss: 0.0972\n",
      "Epoch: 11/20... Training loss: 0.0947\n",
      "Epoch: 11/20... Training loss: 0.0942\n",
      "Epoch: 11/20... Training loss: 0.0938\n",
      "Epoch: 11/20... Training loss: 0.0956\n",
      "Epoch: 11/20... Training loss: 0.0929\n",
      "Epoch: 11/20... Training loss: 0.0950\n",
      "Epoch: 11/20... Training loss: 0.0946\n",
      "Epoch: 11/20... Training loss: 0.0973\n",
      "Epoch: 11/20... Training loss: 0.0978\n",
      "Epoch: 11/20... Training loss: 0.0951\n",
      "Epoch: 11/20... Training loss: 0.0934\n",
      "Epoch: 11/20... Training loss: 0.0980\n",
      "Epoch: 11/20... Training loss: 0.0899\n",
      "Epoch: 11/20... Training loss: 0.0922\n",
      "Epoch: 11/20... Training loss: 0.0945\n",
      "Epoch: 11/20... Training loss: 0.0930\n",
      "Epoch: 11/20... Training loss: 0.0936\n",
      "Epoch: 11/20... Training loss: 0.0925\n",
      "Epoch: 11/20... Training loss: 0.0975\n",
      "Epoch: 11/20... Training loss: 0.0954\n",
      "Epoch: 11/20... Training loss: 0.0946\n",
      "Epoch: 11/20... Training loss: 0.0917\n",
      "Epoch: 11/20... Training loss: 0.0958\n",
      "Epoch: 11/20... Training loss: 0.0971\n",
      "Epoch: 11/20... Training loss: 0.0951\n",
      "Epoch: 11/20... Training loss: 0.0974\n",
      "Epoch: 11/20... Training loss: 0.0960\n",
      "Epoch: 11/20... Training loss: 0.0937\n",
      "Epoch: 11/20... Training loss: 0.0960\n",
      "Epoch: 11/20... Training loss: 0.0983\n",
      "Epoch: 11/20... Training loss: 0.0970\n",
      "Epoch: 11/20... Training loss: 0.0941\n",
      "Epoch: 11/20... Training loss: 0.0936\n",
      "Epoch: 11/20... Training loss: 0.0930\n",
      "Epoch: 11/20... Training loss: 0.0986\n",
      "Epoch: 11/20... Training loss: 0.0973\n",
      "Epoch: 11/20... Training loss: 0.0944\n",
      "Epoch: 11/20... Training loss: 0.0950\n",
      "Epoch: 11/20... Training loss: 0.0937\n",
      "Epoch: 11/20... Training loss: 0.0934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/20... Training loss: 0.0940\n",
      "Epoch: 11/20... Training loss: 0.0956\n",
      "Epoch: 11/20... Training loss: 0.0966\n",
      "Epoch: 11/20... Training loss: 0.0971\n",
      "Epoch: 11/20... Training loss: 0.0926\n",
      "Epoch: 11/20... Training loss: 0.0948\n",
      "Epoch: 11/20... Training loss: 0.0958\n",
      "Epoch: 11/20... Training loss: 0.0953\n",
      "Epoch: 11/20... Training loss: 0.0970\n",
      "Epoch: 11/20... Training loss: 0.0917\n",
      "Epoch: 11/20... Training loss: 0.0965\n",
      "Epoch: 11/20... Training loss: 0.0945\n",
      "Epoch: 11/20... Training loss: 0.0936\n",
      "Epoch: 11/20... Training loss: 0.0932\n",
      "Epoch: 11/20... Training loss: 0.0939\n",
      "Epoch: 11/20... Training loss: 0.0983\n",
      "Epoch: 11/20... Training loss: 0.0945\n",
      "Epoch: 11/20... Training loss: 0.0941\n",
      "Epoch: 11/20... Training loss: 0.0934\n",
      "Epoch: 11/20... Training loss: 0.0952\n",
      "Epoch: 11/20... Training loss: 0.0938\n",
      "Epoch: 11/20... Training loss: 0.0963\n",
      "Epoch: 11/20... Training loss: 0.0934\n",
      "Epoch: 11/20... Training loss: 0.0935\n",
      "Epoch: 11/20... Training loss: 0.0963\n",
      "Epoch: 11/20... Training loss: 0.0923\n",
      "Epoch: 11/20... Training loss: 0.0975\n",
      "Epoch: 11/20... Training loss: 0.0942\n",
      "Epoch: 11/20... Training loss: 0.0954\n",
      "Epoch: 11/20... Training loss: 0.0958\n",
      "Epoch: 11/20... Training loss: 0.0962\n",
      "Epoch: 11/20... Training loss: 0.0933\n",
      "Epoch: 11/20... Training loss: 0.0934\n",
      "Epoch: 11/20... Training loss: 0.0912\n",
      "Epoch: 11/20... Training loss: 0.0944\n",
      "Epoch: 11/20... Training loss: 0.0978\n",
      "Epoch: 11/20... Training loss: 0.0964\n",
      "Epoch: 11/20... Training loss: 0.0915\n",
      "Epoch: 11/20... Training loss: 0.0974\n",
      "Epoch: 11/20... Training loss: 0.0959\n",
      "Epoch: 11/20... Training loss: 0.0987\n",
      "Epoch: 11/20... Training loss: 0.0969\n",
      "Epoch: 11/20... Training loss: 0.0940\n",
      "Epoch: 11/20... Training loss: 0.0954\n",
      "Epoch: 11/20... Training loss: 0.0957\n",
      "Epoch: 11/20... Training loss: 0.0962\n",
      "Epoch: 11/20... Training loss: 0.0948\n",
      "Epoch: 11/20... Training loss: 0.0947\n",
      "Epoch: 11/20... Training loss: 0.0885\n",
      "Epoch: 11/20... Training loss: 0.0902\n",
      "Epoch: 11/20... Training loss: 0.0929\n",
      "Epoch: 11/20... Training loss: 0.0956\n",
      "Epoch: 11/20... Training loss: 0.0982\n",
      "Epoch: 11/20... Training loss: 0.0965\n",
      "Epoch: 11/20... Training loss: 0.0975\n",
      "Epoch: 11/20... Training loss: 0.0982\n",
      "Epoch: 11/20... Training loss: 0.0974\n",
      "Epoch: 11/20... Training loss: 0.0957\n",
      "Epoch: 11/20... Training loss: 0.0966\n",
      "Epoch: 11/20... Training loss: 0.0965\n",
      "Epoch: 11/20... Training loss: 0.0951\n",
      "Epoch: 11/20... Training loss: 0.0946\n",
      "Epoch: 11/20... Training loss: 0.0988\n",
      "Epoch: 11/20... Training loss: 0.0947\n",
      "Epoch: 11/20... Training loss: 0.0940\n",
      "Epoch: 11/20... Training loss: 0.0977\n",
      "Epoch: 11/20... Training loss: 0.0979\n",
      "Epoch: 11/20... Training loss: 0.0946\n",
      "Epoch: 11/20... Training loss: 0.0917\n",
      "Epoch: 11/20... Training loss: 0.0984\n",
      "Epoch: 11/20... Training loss: 0.0949\n",
      "Epoch: 11/20... Training loss: 0.0973\n",
      "Epoch: 11/20... Training loss: 0.0980\n",
      "Epoch: 11/20... Training loss: 0.0919\n",
      "Epoch: 11/20... Training loss: 0.0909\n",
      "Epoch: 11/20... Training loss: 0.0973\n",
      "Epoch: 11/20... Training loss: 0.0942\n",
      "Epoch: 11/20... Training loss: 0.0953\n",
      "Epoch: 11/20... Training loss: 0.0942\n",
      "Epoch: 11/20... Training loss: 0.0924\n",
      "Epoch: 11/20... Training loss: 0.0952\n",
      "Epoch: 11/20... Training loss: 0.0950\n",
      "Epoch: 11/20... Training loss: 0.0962\n",
      "Epoch: 11/20... Training loss: 0.0962\n",
      "Epoch: 11/20... Training loss: 0.0950\n",
      "Epoch: 11/20... Training loss: 0.0964\n",
      "Epoch: 11/20... Training loss: 0.0960\n",
      "Epoch: 11/20... Training loss: 0.0913\n",
      "Epoch: 11/20... Training loss: 0.0945\n",
      "Epoch: 11/20... Training loss: 0.0930\n",
      "Epoch: 11/20... Training loss: 0.0922\n",
      "Epoch: 11/20... Training loss: 0.0949\n",
      "Epoch: 11/20... Training loss: 0.0918\n",
      "Epoch: 11/20... Training loss: 0.0934\n",
      "Epoch: 11/20... Training loss: 0.0989\n",
      "Epoch: 11/20... Training loss: 0.0931\n",
      "Epoch: 11/20... Training loss: 0.0962\n",
      "Epoch: 11/20... Training loss: 0.0954\n",
      "Epoch: 11/20... Training loss: 0.0938\n",
      "Epoch: 11/20... Training loss: 0.0960\n",
      "Epoch: 11/20... Training loss: 0.0965\n",
      "Epoch: 11/20... Training loss: 0.0951\n",
      "Epoch: 11/20... Training loss: 0.0931\n",
      "Epoch: 11/20... Training loss: 0.0966\n",
      "Epoch: 11/20... Training loss: 0.0928\n",
      "Epoch: 11/20... Training loss: 0.0922\n",
      "Epoch: 11/20... Training loss: 0.0945\n",
      "Epoch: 11/20... Training loss: 0.0964\n",
      "Epoch: 11/20... Training loss: 0.0941\n",
      "Epoch: 11/20... Training loss: 0.0919\n",
      "Epoch: 11/20... Training loss: 0.0956\n",
      "Epoch: 11/20... Training loss: 0.0956\n",
      "Epoch: 11/20... Training loss: 0.0938\n",
      "Epoch: 11/20... Training loss: 0.0922\n",
      "Epoch: 11/20... Training loss: 0.0957\n",
      "Epoch: 11/20... Training loss: 0.0989\n",
      "Epoch: 11/20... Training loss: 0.0956\n",
      "Epoch: 11/20... Training loss: 0.0917\n",
      "Epoch: 11/20... Training loss: 0.0955\n",
      "Epoch: 11/20... Training loss: 0.0958\n",
      "Epoch: 11/20... Training loss: 0.0981\n",
      "Epoch: 11/20... Training loss: 0.0925\n",
      "Epoch: 11/20... Training loss: 0.0950\n",
      "Epoch: 11/20... Training loss: 0.0909\n",
      "Epoch: 11/20... Training loss: 0.0985\n",
      "Epoch: 11/20... Training loss: 0.0924\n",
      "Epoch: 11/20... Training loss: 0.0976\n",
      "Epoch: 11/20... Training loss: 0.0943\n",
      "Epoch: 11/20... Training loss: 0.0971\n",
      "Epoch: 11/20... Training loss: 0.0939\n",
      "Epoch: 11/20... Training loss: 0.0938\n",
      "Epoch: 11/20... Training loss: 0.0938\n",
      "Epoch: 11/20... Training loss: 0.0951\n",
      "Epoch: 11/20... Training loss: 0.0949\n",
      "Epoch: 11/20... Training loss: 0.0937\n",
      "Epoch: 11/20... Training loss: 0.0941\n",
      "Epoch: 11/20... Training loss: 0.0959\n",
      "Epoch: 11/20... Training loss: 0.0943\n",
      "Epoch: 11/20... Training loss: 0.0956\n",
      "Epoch: 11/20... Training loss: 0.0930\n",
      "Epoch: 11/20... Training loss: 0.0987\n",
      "Epoch: 11/20... Training loss: 0.0944\n",
      "Epoch: 11/20... Training loss: 0.0967\n",
      "Epoch: 11/20... Training loss: 0.0967\n",
      "Epoch: 11/20... Training loss: 0.0926\n",
      "Epoch: 11/20... Training loss: 0.0956\n",
      "Epoch: 11/20... Training loss: 0.0925\n",
      "Epoch: 11/20... Training loss: 0.0982\n",
      "Epoch: 11/20... Training loss: 0.0967\n",
      "Epoch: 11/20... Training loss: 0.0927\n",
      "Epoch: 11/20... Training loss: 0.0935\n",
      "Epoch: 11/20... Training loss: 0.0983\n",
      "Epoch: 11/20... Training loss: 0.0965\n",
      "Epoch: 11/20... Training loss: 0.0922\n",
      "Epoch: 11/20... Training loss: 0.0959\n",
      "Epoch: 11/20... Training loss: 0.0936\n",
      "Epoch: 11/20... Training loss: 0.0927\n",
      "Epoch: 11/20... Training loss: 0.0977\n",
      "Epoch: 11/20... Training loss: 0.0910\n",
      "Epoch: 11/20... Training loss: 0.0953\n",
      "Epoch: 11/20... Training loss: 0.0970\n",
      "Epoch: 11/20... Training loss: 0.0954\n",
      "Epoch: 11/20... Training loss: 0.0951\n",
      "Epoch: 11/20... Training loss: 0.0918\n",
      "Epoch: 11/20... Training loss: 0.0936\n",
      "Epoch: 11/20... Training loss: 0.0938\n",
      "Epoch: 11/20... Training loss: 0.0974\n",
      "Epoch: 11/20... Training loss: 0.0950\n",
      "Epoch: 11/20... Training loss: 0.0937\n",
      "Epoch: 11/20... Training loss: 0.0925\n",
      "Epoch: 11/20... Training loss: 0.0932\n",
      "Epoch: 11/20... Training loss: 0.0938\n",
      "Epoch: 11/20... Training loss: 0.0941\n",
      "Epoch: 11/20... Training loss: 0.0947\n",
      "Epoch: 11/20... Training loss: 0.0944\n",
      "Epoch: 11/20... Training loss: 0.0911\n",
      "Epoch: 11/20... Training loss: 0.0961\n",
      "Epoch: 11/20... Training loss: 0.0963\n",
      "Epoch: 11/20... Training loss: 0.0981\n",
      "Epoch: 11/20... Training loss: 0.0966\n",
      "Epoch: 11/20... Training loss: 0.0935\n",
      "Epoch: 11/20... Training loss: 0.0897\n",
      "Epoch: 11/20... Training loss: 0.0978\n",
      "Epoch: 11/20... Training loss: 0.1009\n",
      "Epoch: 11/20... Training loss: 0.0948\n",
      "Epoch: 11/20... Training loss: 0.0916\n",
      "Epoch: 11/20... Training loss: 0.0956\n",
      "Epoch: 11/20... Training loss: 0.0963\n",
      "Epoch: 11/20... Training loss: 0.0954\n",
      "Epoch: 11/20... Training loss: 0.0964\n",
      "Epoch: 11/20... Training loss: 0.0953\n",
      "Epoch: 11/20... Training loss: 0.0980\n",
      "Epoch: 11/20... Training loss: 0.0960\n",
      "Epoch: 11/20... Training loss: 0.0971\n",
      "Epoch: 12/20... Training loss: 0.0967\n",
      "Epoch: 12/20... Training loss: 0.0946\n",
      "Epoch: 12/20... Training loss: 0.0926\n",
      "Epoch: 12/20... Training loss: 0.0937\n",
      "Epoch: 12/20... Training loss: 0.0984\n",
      "Epoch: 12/20... Training loss: 0.0961\n",
      "Epoch: 12/20... Training loss: 0.0999\n",
      "Epoch: 12/20... Training loss: 0.0950\n",
      "Epoch: 12/20... Training loss: 0.0971\n",
      "Epoch: 12/20... Training loss: 0.0938\n",
      "Epoch: 12/20... Training loss: 0.0969\n",
      "Epoch: 12/20... Training loss: 0.0965\n",
      "Epoch: 12/20... Training loss: 0.0957\n",
      "Epoch: 12/20... Training loss: 0.0970\n",
      "Epoch: 12/20... Training loss: 0.0951\n",
      "Epoch: 12/20... Training loss: 0.0941\n",
      "Epoch: 12/20... Training loss: 0.0953\n",
      "Epoch: 12/20... Training loss: 0.0939\n",
      "Epoch: 12/20... Training loss: 0.0978\n",
      "Epoch: 12/20... Training loss: 0.0959\n",
      "Epoch: 12/20... Training loss: 0.0952\n",
      "Epoch: 12/20... Training loss: 0.0968\n",
      "Epoch: 12/20... Training loss: 0.0980\n",
      "Epoch: 12/20... Training loss: 0.0926\n",
      "Epoch: 12/20... Training loss: 0.0937\n",
      "Epoch: 12/20... Training loss: 0.0942\n",
      "Epoch: 12/20... Training loss: 0.0959\n",
      "Epoch: 12/20... Training loss: 0.0957\n",
      "Epoch: 12/20... Training loss: 0.0957\n",
      "Epoch: 12/20... Training loss: 0.0952\n",
      "Epoch: 12/20... Training loss: 0.0956\n",
      "Epoch: 12/20... Training loss: 0.0970\n",
      "Epoch: 12/20... Training loss: 0.0916\n",
      "Epoch: 12/20... Training loss: 0.0980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/20... Training loss: 0.0974\n",
      "Epoch: 12/20... Training loss: 0.0958\n",
      "Epoch: 12/20... Training loss: 0.0977\n",
      "Epoch: 12/20... Training loss: 0.0930\n",
      "Epoch: 12/20... Training loss: 0.0944\n",
      "Epoch: 12/20... Training loss: 0.0896\n",
      "Epoch: 12/20... Training loss: 0.0949\n",
      "Epoch: 12/20... Training loss: 0.0976\n",
      "Epoch: 12/20... Training loss: 0.0930\n",
      "Epoch: 12/20... Training loss: 0.0974\n",
      "Epoch: 12/20... Training loss: 0.0953\n",
      "Epoch: 12/20... Training loss: 0.0939\n",
      "Epoch: 12/20... Training loss: 0.0917\n",
      "Epoch: 12/20... Training loss: 0.0951\n",
      "Epoch: 12/20... Training loss: 0.0940\n",
      "Epoch: 12/20... Training loss: 0.0941\n",
      "Epoch: 12/20... Training loss: 0.0998\n",
      "Epoch: 12/20... Training loss: 0.0897\n",
      "Epoch: 12/20... Training loss: 0.0978\n",
      "Epoch: 12/20... Training loss: 0.0969\n",
      "Epoch: 12/20... Training loss: 0.0936\n",
      "Epoch: 12/20... Training loss: 0.0945\n",
      "Epoch: 12/20... Training loss: 0.0964\n",
      "Epoch: 12/20... Training loss: 0.0953\n",
      "Epoch: 12/20... Training loss: 0.0953\n",
      "Epoch: 12/20... Training loss: 0.0933\n",
      "Epoch: 12/20... Training loss: 0.0936\n",
      "Epoch: 12/20... Training loss: 0.0945\n",
      "Epoch: 12/20... Training loss: 0.0941\n",
      "Epoch: 12/20... Training loss: 0.0963\n",
      "Epoch: 12/20... Training loss: 0.0931\n",
      "Epoch: 12/20... Training loss: 0.0936\n",
      "Epoch: 12/20... Training loss: 0.0945\n",
      "Epoch: 12/20... Training loss: 0.0993\n",
      "Epoch: 12/20... Training loss: 0.0928\n",
      "Epoch: 12/20... Training loss: 0.0953\n",
      "Epoch: 12/20... Training loss: 0.0974\n",
      "Epoch: 12/20... Training loss: 0.0931\n",
      "Epoch: 12/20... Training loss: 0.0945\n",
      "Epoch: 12/20... Training loss: 0.0921\n",
      "Epoch: 12/20... Training loss: 0.0951\n",
      "Epoch: 12/20... Training loss: 0.0907\n",
      "Epoch: 12/20... Training loss: 0.0952\n",
      "Epoch: 12/20... Training loss: 0.0960\n",
      "Epoch: 12/20... Training loss: 0.0918\n",
      "Epoch: 12/20... Training loss: 0.0922\n",
      "Epoch: 12/20... Training loss: 0.0949\n",
      "Epoch: 12/20... Training loss: 0.0957\n",
      "Epoch: 12/20... Training loss: 0.0959\n",
      "Epoch: 12/20... Training loss: 0.0943\n",
      "Epoch: 12/20... Training loss: 0.0979\n",
      "Epoch: 12/20... Training loss: 0.0950\n",
      "Epoch: 12/20... Training loss: 0.0972\n",
      "Epoch: 12/20... Training loss: 0.0970\n",
      "Epoch: 12/20... Training loss: 0.0951\n",
      "Epoch: 12/20... Training loss: 0.0968\n",
      "Epoch: 12/20... Training loss: 0.0988\n",
      "Epoch: 12/20... Training loss: 0.0925\n",
      "Epoch: 12/20... Training loss: 0.0943\n",
      "Epoch: 12/20... Training loss: 0.0947\n",
      "Epoch: 12/20... Training loss: 0.0959\n",
      "Epoch: 12/20... Training loss: 0.0922\n",
      "Epoch: 12/20... Training loss: 0.0940\n",
      "Epoch: 12/20... Training loss: 0.0994\n",
      "Epoch: 12/20... Training loss: 0.0941\n",
      "Epoch: 12/20... Training loss: 0.0928\n",
      "Epoch: 12/20... Training loss: 0.0960\n",
      "Epoch: 12/20... Training loss: 0.0927\n",
      "Epoch: 12/20... Training loss: 0.0946\n",
      "Epoch: 12/20... Training loss: 0.0934\n",
      "Epoch: 12/20... Training loss: 0.0927\n",
      "Epoch: 12/20... Training loss: 0.0944\n",
      "Epoch: 12/20... Training loss: 0.0917\n",
      "Epoch: 12/20... Training loss: 0.0928\n",
      "Epoch: 12/20... Training loss: 0.0945\n",
      "Epoch: 12/20... Training loss: 0.0941\n",
      "Epoch: 12/20... Training loss: 0.0920\n",
      "Epoch: 12/20... Training loss: 0.0933\n",
      "Epoch: 12/20... Training loss: 0.0949\n",
      "Epoch: 12/20... Training loss: 0.0928\n",
      "Epoch: 12/20... Training loss: 0.0909\n",
      "Epoch: 12/20... Training loss: 0.0930\n",
      "Epoch: 12/20... Training loss: 0.0964\n",
      "Epoch: 12/20... Training loss: 0.0937\n",
      "Epoch: 12/20... Training loss: 0.0952\n",
      "Epoch: 12/20... Training loss: 0.0921\n",
      "Epoch: 12/20... Training loss: 0.0930\n",
      "Epoch: 12/20... Training loss: 0.0944\n",
      "Epoch: 12/20... Training loss: 0.0938\n",
      "Epoch: 12/20... Training loss: 0.0905\n",
      "Epoch: 12/20... Training loss: 0.0935\n",
      "Epoch: 12/20... Training loss: 0.0919\n",
      "Epoch: 12/20... Training loss: 0.0956\n",
      "Epoch: 12/20... Training loss: 0.0971\n",
      "Epoch: 12/20... Training loss: 0.0911\n",
      "Epoch: 12/20... Training loss: 0.0924\n",
      "Epoch: 12/20... Training loss: 0.0974\n",
      "Epoch: 12/20... Training loss: 0.0907\n",
      "Epoch: 12/20... Training loss: 0.0899\n",
      "Epoch: 12/20... Training loss: 0.0983\n",
      "Epoch: 12/20... Training loss: 0.0956\n",
      "Epoch: 12/20... Training loss: 0.0951\n",
      "Epoch: 12/20... Training loss: 0.0959\n",
      "Epoch: 12/20... Training loss: 0.0952\n",
      "Epoch: 12/20... Training loss: 0.0954\n",
      "Epoch: 12/20... Training loss: 0.0938\n",
      "Epoch: 12/20... Training loss: 0.0924\n",
      "Epoch: 12/20... Training loss: 0.0932\n",
      "Epoch: 12/20... Training loss: 0.0924\n",
      "Epoch: 12/20... Training loss: 0.0943\n",
      "Epoch: 12/20... Training loss: 0.0944\n",
      "Epoch: 12/20... Training loss: 0.0921\n",
      "Epoch: 12/20... Training loss: 0.0932\n",
      "Epoch: 12/20... Training loss: 0.0946\n",
      "Epoch: 12/20... Training loss: 0.0925\n",
      "Epoch: 12/20... Training loss: 0.0966\n",
      "Epoch: 12/20... Training loss: 0.0946\n",
      "Epoch: 12/20... Training loss: 0.1005\n",
      "Epoch: 12/20... Training loss: 0.0958\n",
      "Epoch: 12/20... Training loss: 0.0946\n",
      "Epoch: 12/20... Training loss: 0.0942\n",
      "Epoch: 12/20... Training loss: 0.0936\n",
      "Epoch: 12/20... Training loss: 0.0958\n",
      "Epoch: 12/20... Training loss: 0.0934\n",
      "Epoch: 12/20... Training loss: 0.0967\n",
      "Epoch: 12/20... Training loss: 0.0945\n",
      "Epoch: 12/20... Training loss: 0.0961\n",
      "Epoch: 12/20... Training loss: 0.0964\n",
      "Epoch: 12/20... Training loss: 0.0954\n",
      "Epoch: 12/20... Training loss: 0.0986\n",
      "Epoch: 12/20... Training loss: 0.0868\n",
      "Epoch: 12/20... Training loss: 0.0953\n",
      "Epoch: 12/20... Training loss: 0.0964\n",
      "Epoch: 12/20... Training loss: 0.0947\n",
      "Epoch: 12/20... Training loss: 0.0965\n",
      "Epoch: 12/20... Training loss: 0.0949\n",
      "Epoch: 12/20... Training loss: 0.0937\n",
      "Epoch: 12/20... Training loss: 0.0995\n",
      "Epoch: 12/20... Training loss: 0.0961\n",
      "Epoch: 12/20... Training loss: 0.0948\n",
      "Epoch: 12/20... Training loss: 0.0956\n",
      "Epoch: 12/20... Training loss: 0.0955\n",
      "Epoch: 12/20... Training loss: 0.0903\n",
      "Epoch: 12/20... Training loss: 0.0984\n",
      "Epoch: 12/20... Training loss: 0.0955\n",
      "Epoch: 12/20... Training loss: 0.0961\n",
      "Epoch: 12/20... Training loss: 0.0960\n",
      "Epoch: 12/20... Training loss: 0.0947\n",
      "Epoch: 12/20... Training loss: 0.0980\n",
      "Epoch: 12/20... Training loss: 0.0933\n",
      "Epoch: 12/20... Training loss: 0.0958\n",
      "Epoch: 12/20... Training loss: 0.0937\n",
      "Epoch: 12/20... Training loss: 0.0958\n",
      "Epoch: 12/20... Training loss: 0.0959\n",
      "Epoch: 12/20... Training loss: 0.0948\n",
      "Epoch: 12/20... Training loss: 0.0965\n",
      "Epoch: 12/20... Training loss: 0.0947\n",
      "Epoch: 12/20... Training loss: 0.0931\n",
      "Epoch: 12/20... Training loss: 0.0901\n",
      "Epoch: 12/20... Training loss: 0.0939\n",
      "Epoch: 12/20... Training loss: 0.0956\n",
      "Epoch: 12/20... Training loss: 0.0954\n",
      "Epoch: 12/20... Training loss: 0.0933\n",
      "Epoch: 12/20... Training loss: 0.0949\n",
      "Epoch: 12/20... Training loss: 0.0937\n",
      "Epoch: 12/20... Training loss: 0.0919\n",
      "Epoch: 12/20... Training loss: 0.0909\n",
      "Epoch: 12/20... Training loss: 0.0973\n",
      "Epoch: 12/20... Training loss: 0.0934\n",
      "Epoch: 12/20... Training loss: 0.0931\n",
      "Epoch: 12/20... Training loss: 0.0955\n",
      "Epoch: 12/20... Training loss: 0.0905\n",
      "Epoch: 12/20... Training loss: 0.0958\n",
      "Epoch: 12/20... Training loss: 0.0925\n",
      "Epoch: 12/20... Training loss: 0.0958\n",
      "Epoch: 12/20... Training loss: 0.0972\n",
      "Epoch: 12/20... Training loss: 0.0945\n",
      "Epoch: 12/20... Training loss: 0.0920\n",
      "Epoch: 12/20... Training loss: 0.0940\n",
      "Epoch: 12/20... Training loss: 0.0946\n",
      "Epoch: 12/20... Training loss: 0.0979\n",
      "Epoch: 12/20... Training loss: 0.0966\n",
      "Epoch: 12/20... Training loss: 0.0900\n",
      "Epoch: 12/20... Training loss: 0.0963\n",
      "Epoch: 12/20... Training loss: 0.0948\n",
      "Epoch: 12/20... Training loss: 0.0961\n",
      "Epoch: 12/20... Training loss: 0.0913\n",
      "Epoch: 12/20... Training loss: 0.0960\n",
      "Epoch: 12/20... Training loss: 0.0893\n",
      "Epoch: 12/20... Training loss: 0.0953\n",
      "Epoch: 12/20... Training loss: 0.0932\n",
      "Epoch: 12/20... Training loss: 0.0936\n",
      "Epoch: 12/20... Training loss: 0.0925\n",
      "Epoch: 12/20... Training loss: 0.0934\n",
      "Epoch: 12/20... Training loss: 0.0942\n",
      "Epoch: 12/20... Training loss: 0.0960\n",
      "Epoch: 12/20... Training loss: 0.0917\n",
      "Epoch: 12/20... Training loss: 0.0943\n",
      "Epoch: 12/20... Training loss: 0.0937\n",
      "Epoch: 12/20... Training loss: 0.0920\n",
      "Epoch: 12/20... Training loss: 0.0953\n",
      "Epoch: 12/20... Training loss: 0.0933\n",
      "Epoch: 12/20... Training loss: 0.0936\n",
      "Epoch: 12/20... Training loss: 0.0942\n",
      "Epoch: 12/20... Training loss: 0.0939\n",
      "Epoch: 12/20... Training loss: 0.0965\n",
      "Epoch: 12/20... Training loss: 0.0913\n",
      "Epoch: 12/20... Training loss: 0.0950\n",
      "Epoch: 12/20... Training loss: 0.0943\n",
      "Epoch: 12/20... Training loss: 0.0944\n",
      "Epoch: 12/20... Training loss: 0.0915\n",
      "Epoch: 12/20... Training loss: 0.0949\n",
      "Epoch: 12/20... Training loss: 0.0925\n",
      "Epoch: 12/20... Training loss: 0.0942\n",
      "Epoch: 12/20... Training loss: 0.0954\n",
      "Epoch: 12/20... Training loss: 0.0936\n",
      "Epoch: 12/20... Training loss: 0.0928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/20... Training loss: 0.0985\n",
      "Epoch: 12/20... Training loss: 0.0984\n",
      "Epoch: 12/20... Training loss: 0.0946\n",
      "Epoch: 12/20... Training loss: 0.0952\n",
      "Epoch: 12/20... Training loss: 0.0906\n",
      "Epoch: 12/20... Training loss: 0.0947\n",
      "Epoch: 12/20... Training loss: 0.0932\n",
      "Epoch: 12/20... Training loss: 0.0921\n",
      "Epoch: 12/20... Training loss: 0.0937\n",
      "Epoch: 12/20... Training loss: 0.0950\n",
      "Epoch: 12/20... Training loss: 0.0936\n",
      "Epoch: 12/20... Training loss: 0.0939\n",
      "Epoch: 12/20... Training loss: 0.0967\n",
      "Epoch: 12/20... Training loss: 0.0954\n",
      "Epoch: 12/20... Training loss: 0.0967\n",
      "Epoch: 12/20... Training loss: 0.0950\n",
      "Epoch: 12/20... Training loss: 0.0933\n",
      "Epoch: 12/20... Training loss: 0.0919\n",
      "Epoch: 12/20... Training loss: 0.0940\n",
      "Epoch: 12/20... Training loss: 0.0934\n",
      "Epoch: 12/20... Training loss: 0.0942\n",
      "Epoch: 12/20... Training loss: 0.0936\n",
      "Epoch: 12/20... Training loss: 0.0937\n",
      "Epoch: 12/20... Training loss: 0.0971\n",
      "Epoch: 12/20... Training loss: 0.0931\n",
      "Epoch: 12/20... Training loss: 0.0916\n",
      "Epoch: 12/20... Training loss: 0.0969\n",
      "Epoch: 12/20... Training loss: 0.0931\n",
      "Epoch: 12/20... Training loss: 0.0950\n",
      "Epoch: 12/20... Training loss: 0.0975\n",
      "Epoch: 12/20... Training loss: 0.0967\n",
      "Epoch: 12/20... Training loss: 0.0966\n",
      "Epoch: 12/20... Training loss: 0.0928\n",
      "Epoch: 12/20... Training loss: 0.0973\n",
      "Epoch: 12/20... Training loss: 0.0940\n",
      "Epoch: 12/20... Training loss: 0.0922\n",
      "Epoch: 12/20... Training loss: 0.0947\n",
      "Epoch: 12/20... Training loss: 0.0938\n",
      "Epoch: 12/20... Training loss: 0.0950\n",
      "Epoch: 12/20... Training loss: 0.0941\n",
      "Epoch: 12/20... Training loss: 0.0940\n",
      "Epoch: 12/20... Training loss: 0.0941\n",
      "Epoch: 12/20... Training loss: 0.0971\n",
      "Epoch: 12/20... Training loss: 0.0947\n",
      "Epoch: 12/20... Training loss: 0.0938\n",
      "Epoch: 12/20... Training loss: 0.0959\n",
      "Epoch: 12/20... Training loss: 0.0926\n",
      "Epoch: 12/20... Training loss: 0.0962\n",
      "Epoch: 12/20... Training loss: 0.0941\n",
      "Epoch: 13/20... Training loss: 0.0947\n",
      "Epoch: 13/20... Training loss: 0.0912\n",
      "Epoch: 13/20... Training loss: 0.0975\n",
      "Epoch: 13/20... Training loss: 0.0912\n",
      "Epoch: 13/20... Training loss: 0.0940\n",
      "Epoch: 13/20... Training loss: 0.0923\n",
      "Epoch: 13/20... Training loss: 0.0911\n",
      "Epoch: 13/20... Training loss: 0.0963\n",
      "Epoch: 13/20... Training loss: 0.0940\n",
      "Epoch: 13/20... Training loss: 0.0982\n",
      "Epoch: 13/20... Training loss: 0.0961\n",
      "Epoch: 13/20... Training loss: 0.0916\n",
      "Epoch: 13/20... Training loss: 0.0926\n",
      "Epoch: 13/20... Training loss: 0.0954\n",
      "Epoch: 13/20... Training loss: 0.0942\n",
      "Epoch: 13/20... Training loss: 0.0944\n",
      "Epoch: 13/20... Training loss: 0.0950\n",
      "Epoch: 13/20... Training loss: 0.0931\n",
      "Epoch: 13/20... Training loss: 0.0974\n",
      "Epoch: 13/20... Training loss: 0.0913\n",
      "Epoch: 13/20... Training loss: 0.0942\n",
      "Epoch: 13/20... Training loss: 0.0936\n",
      "Epoch: 13/20... Training loss: 0.0947\n",
      "Epoch: 13/20... Training loss: 0.0948\n",
      "Epoch: 13/20... Training loss: 0.0938\n",
      "Epoch: 13/20... Training loss: 0.0941\n",
      "Epoch: 13/20... Training loss: 0.0933\n",
      "Epoch: 13/20... Training loss: 0.0968\n",
      "Epoch: 13/20... Training loss: 0.0938\n",
      "Epoch: 13/20... Training loss: 0.0959\n",
      "Epoch: 13/20... Training loss: 0.0953\n",
      "Epoch: 13/20... Training loss: 0.0911\n",
      "Epoch: 13/20... Training loss: 0.0929\n",
      "Epoch: 13/20... Training loss: 0.0975\n",
      "Epoch: 13/20... Training loss: 0.0941\n",
      "Epoch: 13/20... Training loss: 0.0949\n",
      "Epoch: 13/20... Training loss: 0.0961\n",
      "Epoch: 13/20... Training loss: 0.0954\n",
      "Epoch: 13/20... Training loss: 0.0952\n",
      "Epoch: 13/20... Training loss: 0.0957\n",
      "Epoch: 13/20... Training loss: 0.0941\n",
      "Epoch: 13/20... Training loss: 0.0968\n",
      "Epoch: 13/20... Training loss: 0.0938\n",
      "Epoch: 13/20... Training loss: 0.0914\n",
      "Epoch: 13/20... Training loss: 0.0947\n",
      "Epoch: 13/20... Training loss: 0.0936\n",
      "Epoch: 13/20... Training loss: 0.0940\n",
      "Epoch: 13/20... Training loss: 0.0932\n",
      "Epoch: 13/20... Training loss: 0.0934\n",
      "Epoch: 13/20... Training loss: 0.0943\n",
      "Epoch: 13/20... Training loss: 0.0941\n",
      "Epoch: 13/20... Training loss: 0.0910\n",
      "Epoch: 13/20... Training loss: 0.0939\n",
      "Epoch: 13/20... Training loss: 0.0942\n",
      "Epoch: 13/20... Training loss: 0.0996\n",
      "Epoch: 13/20... Training loss: 0.0916\n",
      "Epoch: 13/20... Training loss: 0.0937\n",
      "Epoch: 13/20... Training loss: 0.0936\n",
      "Epoch: 13/20... Training loss: 0.0940\n",
      "Epoch: 13/20... Training loss: 0.0941\n",
      "Epoch: 13/20... Training loss: 0.0955\n",
      "Epoch: 13/20... Training loss: 0.0942\n",
      "Epoch: 13/20... Training loss: 0.0931\n",
      "Epoch: 13/20... Training loss: 0.0912\n",
      "Epoch: 13/20... Training loss: 0.0951\n",
      "Epoch: 13/20... Training loss: 0.0937\n",
      "Epoch: 13/20... Training loss: 0.0949\n",
      "Epoch: 13/20... Training loss: 0.0938\n",
      "Epoch: 13/20... Training loss: 0.0947\n",
      "Epoch: 13/20... Training loss: 0.0962\n",
      "Epoch: 13/20... Training loss: 0.0923\n",
      "Epoch: 13/20... Training loss: 0.0921\n",
      "Epoch: 13/20... Training loss: 0.0942\n",
      "Epoch: 13/20... Training loss: 0.0958\n",
      "Epoch: 13/20... Training loss: 0.0930\n",
      "Epoch: 13/20... Training loss: 0.0973\n",
      "Epoch: 13/20... Training loss: 0.0957\n",
      "Epoch: 13/20... Training loss: 0.0909\n",
      "Epoch: 13/20... Training loss: 0.0948\n",
      "Epoch: 13/20... Training loss: 0.0966\n",
      "Epoch: 13/20... Training loss: 0.0928\n",
      "Epoch: 13/20... Training loss: 0.0964\n",
      "Epoch: 13/20... Training loss: 0.0927\n",
      "Epoch: 13/20... Training loss: 0.0930\n",
      "Epoch: 13/20... Training loss: 0.0927\n",
      "Epoch: 13/20... Training loss: 0.0943\n",
      "Epoch: 13/20... Training loss: 0.0950\n",
      "Epoch: 13/20... Training loss: 0.0966\n",
      "Epoch: 13/20... Training loss: 0.0951\n",
      "Epoch: 13/20... Training loss: 0.0959\n",
      "Epoch: 13/20... Training loss: 0.0913\n",
      "Epoch: 13/20... Training loss: 0.0894\n",
      "Epoch: 13/20... Training loss: 0.0926\n",
      "Epoch: 13/20... Training loss: 0.0949\n",
      "Epoch: 13/20... Training loss: 0.0938\n",
      "Epoch: 13/20... Training loss: 0.0918\n",
      "Epoch: 13/20... Training loss: 0.0940\n",
      "Epoch: 13/20... Training loss: 0.0932\n",
      "Epoch: 13/20... Training loss: 0.0936\n",
      "Epoch: 13/20... Training loss: 0.0953\n",
      "Epoch: 13/20... Training loss: 0.0918\n",
      "Epoch: 13/20... Training loss: 0.0919\n",
      "Epoch: 13/20... Training loss: 0.0919\n",
      "Epoch: 13/20... Training loss: 0.0916\n",
      "Epoch: 13/20... Training loss: 0.0941\n",
      "Epoch: 13/20... Training loss: 0.0937\n",
      "Epoch: 13/20... Training loss: 0.0952\n",
      "Epoch: 13/20... Training loss: 0.0971\n",
      "Epoch: 13/20... Training loss: 0.0959\n",
      "Epoch: 13/20... Training loss: 0.0935\n",
      "Epoch: 13/20... Training loss: 0.0955\n",
      "Epoch: 13/20... Training loss: 0.0940\n",
      "Epoch: 13/20... Training loss: 0.0954\n",
      "Epoch: 13/20... Training loss: 0.0936\n",
      "Epoch: 13/20... Training loss: 0.0923\n",
      "Epoch: 13/20... Training loss: 0.0963\n",
      "Epoch: 13/20... Training loss: 0.0933\n",
      "Epoch: 13/20... Training loss: 0.0969\n",
      "Epoch: 13/20... Training loss: 0.0945\n",
      "Epoch: 13/20... Training loss: 0.0965\n",
      "Epoch: 13/20... Training loss: 0.0938\n",
      "Epoch: 13/20... Training loss: 0.0963\n",
      "Epoch: 13/20... Training loss: 0.0930\n",
      "Epoch: 13/20... Training loss: 0.0961\n",
      "Epoch: 13/20... Training loss: 0.0944\n",
      "Epoch: 13/20... Training loss: 0.0935\n",
      "Epoch: 13/20... Training loss: 0.0909\n",
      "Epoch: 13/20... Training loss: 0.0938\n",
      "Epoch: 13/20... Training loss: 0.0964\n",
      "Epoch: 13/20... Training loss: 0.0952\n",
      "Epoch: 13/20... Training loss: 0.0938\n",
      "Epoch: 13/20... Training loss: 0.0955\n",
      "Epoch: 13/20... Training loss: 0.0973\n",
      "Epoch: 13/20... Training loss: 0.0976\n",
      "Epoch: 13/20... Training loss: 0.0951\n",
      "Epoch: 13/20... Training loss: 0.0946\n",
      "Epoch: 13/20... Training loss: 0.0947\n",
      "Epoch: 13/20... Training loss: 0.0909\n",
      "Epoch: 13/20... Training loss: 0.0936\n",
      "Epoch: 13/20... Training loss: 0.0974\n",
      "Epoch: 13/20... Training loss: 0.0963\n",
      "Epoch: 13/20... Training loss: 0.0944\n",
      "Epoch: 13/20... Training loss: 0.0929\n",
      "Epoch: 13/20... Training loss: 0.0918\n",
      "Epoch: 13/20... Training loss: 0.0912\n",
      "Epoch: 13/20... Training loss: 0.0975\n",
      "Epoch: 13/20... Training loss: 0.0902\n",
      "Epoch: 13/20... Training loss: 0.0933\n",
      "Epoch: 13/20... Training loss: 0.0939\n",
      "Epoch: 13/20... Training loss: 0.0941\n",
      "Epoch: 13/20... Training loss: 0.0942\n",
      "Epoch: 13/20... Training loss: 0.0953\n",
      "Epoch: 13/20... Training loss: 0.0956\n",
      "Epoch: 13/20... Training loss: 0.0948\n",
      "Epoch: 13/20... Training loss: 0.0961\n",
      "Epoch: 13/20... Training loss: 0.0927\n",
      "Epoch: 13/20... Training loss: 0.0936\n",
      "Epoch: 13/20... Training loss: 0.0949\n",
      "Epoch: 13/20... Training loss: 0.0956\n",
      "Epoch: 13/20... Training loss: 0.0949\n",
      "Epoch: 13/20... Training loss: 0.0973\n",
      "Epoch: 13/20... Training loss: 0.0919\n",
      "Epoch: 13/20... Training loss: 0.0926\n",
      "Epoch: 13/20... Training loss: 0.0917\n",
      "Epoch: 13/20... Training loss: 0.0894\n",
      "Epoch: 13/20... Training loss: 0.0970\n",
      "Epoch: 13/20... Training loss: 0.0963\n",
      "Epoch: 13/20... Training loss: 0.0958\n",
      "Epoch: 13/20... Training loss: 0.0947\n",
      "Epoch: 13/20... Training loss: 0.0945\n",
      "Epoch: 13/20... Training loss: 0.0946\n",
      "Epoch: 13/20... Training loss: 0.0986\n",
      "Epoch: 13/20... Training loss: 0.0945\n",
      "Epoch: 13/20... Training loss: 0.0966\n",
      "Epoch: 13/20... Training loss: 0.0939\n",
      "Epoch: 13/20... Training loss: 0.0941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/20... Training loss: 0.0910\n",
      "Epoch: 13/20... Training loss: 0.0935\n",
      "Epoch: 13/20... Training loss: 0.0907\n",
      "Epoch: 13/20... Training loss: 0.0946\n",
      "Epoch: 13/20... Training loss: 0.0918\n",
      "Epoch: 13/20... Training loss: 0.0940\n",
      "Epoch: 13/20... Training loss: 0.0957\n",
      "Epoch: 13/20... Training loss: 0.0955\n",
      "Epoch: 13/20... Training loss: 0.0924\n",
      "Epoch: 13/20... Training loss: 0.0945\n",
      "Epoch: 13/20... Training loss: 0.0915\n",
      "Epoch: 13/20... Training loss: 0.0934\n",
      "Epoch: 13/20... Training loss: 0.0933\n",
      "Epoch: 13/20... Training loss: 0.0954\n",
      "Epoch: 13/20... Training loss: 0.0932\n",
      "Epoch: 13/20... Training loss: 0.0930\n",
      "Epoch: 13/20... Training loss: 0.0967\n",
      "Epoch: 13/20... Training loss: 0.0926\n",
      "Epoch: 13/20... Training loss: 0.0955\n",
      "Epoch: 13/20... Training loss: 0.0940\n",
      "Epoch: 13/20... Training loss: 0.0969\n",
      "Epoch: 13/20... Training loss: 0.0923\n",
      "Epoch: 13/20... Training loss: 0.0948\n",
      "Epoch: 13/20... Training loss: 0.0961\n",
      "Epoch: 13/20... Training loss: 0.0931\n",
      "Epoch: 13/20... Training loss: 0.0924\n",
      "Epoch: 13/20... Training loss: 0.0945\n",
      "Epoch: 13/20... Training loss: 0.0943\n",
      "Epoch: 13/20... Training loss: 0.0964\n",
      "Epoch: 13/20... Training loss: 0.0930\n",
      "Epoch: 13/20... Training loss: 0.0944\n",
      "Epoch: 13/20... Training loss: 0.0939\n",
      "Epoch: 13/20... Training loss: 0.0949\n",
      "Epoch: 13/20... Training loss: 0.0935\n",
      "Epoch: 13/20... Training loss: 0.0932\n",
      "Epoch: 13/20... Training loss: 0.0941\n",
      "Epoch: 13/20... Training loss: 0.0940\n",
      "Epoch: 13/20... Training loss: 0.0959\n",
      "Epoch: 13/20... Training loss: 0.0953\n",
      "Epoch: 13/20... Training loss: 0.0969\n",
      "Epoch: 13/20... Training loss: 0.0905\n",
      "Epoch: 13/20... Training loss: 0.0917\n",
      "Epoch: 13/20... Training loss: 0.0973\n",
      "Epoch: 13/20... Training loss: 0.0941\n",
      "Epoch: 13/20... Training loss: 0.0937\n",
      "Epoch: 13/20... Training loss: 0.0910\n",
      "Epoch: 13/20... Training loss: 0.0928\n",
      "Epoch: 13/20... Training loss: 0.0937\n",
      "Epoch: 13/20... Training loss: 0.0958\n",
      "Epoch: 13/20... Training loss: 0.0938\n",
      "Epoch: 13/20... Training loss: 0.0951\n",
      "Epoch: 13/20... Training loss: 0.0922\n",
      "Epoch: 13/20... Training loss: 0.0947\n",
      "Epoch: 13/20... Training loss: 0.0932\n",
      "Epoch: 13/20... Training loss: 0.0942\n",
      "Epoch: 13/20... Training loss: 0.0957\n",
      "Epoch: 13/20... Training loss: 0.0901\n",
      "Epoch: 13/20... Training loss: 0.0957\n",
      "Epoch: 13/20... Training loss: 0.0893\n",
      "Epoch: 13/20... Training loss: 0.0948\n",
      "Epoch: 13/20... Training loss: 0.0990\n",
      "Epoch: 13/20... Training loss: 0.0959\n",
      "Epoch: 13/20... Training loss: 0.0942\n",
      "Epoch: 13/20... Training loss: 0.0920\n",
      "Epoch: 13/20... Training loss: 0.0945\n",
      "Epoch: 13/20... Training loss: 0.0946\n",
      "Epoch: 13/20... Training loss: 0.0948\n",
      "Epoch: 13/20... Training loss: 0.0908\n",
      "Epoch: 13/20... Training loss: 0.0990\n",
      "Epoch: 13/20... Training loss: 0.0957\n",
      "Epoch: 13/20... Training loss: 0.0950\n",
      "Epoch: 13/20... Training loss: 0.0950\n",
      "Epoch: 13/20... Training loss: 0.0948\n",
      "Epoch: 13/20... Training loss: 0.0961\n",
      "Epoch: 13/20... Training loss: 0.0943\n",
      "Epoch: 13/20... Training loss: 0.0954\n",
      "Epoch: 13/20... Training loss: 0.0972\n",
      "Epoch: 13/20... Training loss: 0.0957\n",
      "Epoch: 13/20... Training loss: 0.0956\n",
      "Epoch: 13/20... Training loss: 0.0990\n",
      "Epoch: 13/20... Training loss: 0.0941\n",
      "Epoch: 13/20... Training loss: 0.0929\n",
      "Epoch: 13/20... Training loss: 0.0910\n",
      "Epoch: 13/20... Training loss: 0.0925\n",
      "Epoch: 13/20... Training loss: 0.0919\n",
      "Epoch: 13/20... Training loss: 0.0934\n",
      "Epoch: 13/20... Training loss: 0.0941\n",
      "Epoch: 13/20... Training loss: 0.0931\n",
      "Epoch: 13/20... Training loss: 0.0935\n",
      "Epoch: 13/20... Training loss: 0.0951\n",
      "Epoch: 13/20... Training loss: 0.0966\n",
      "Epoch: 13/20... Training loss: 0.0949\n",
      "Epoch: 13/20... Training loss: 0.0968\n",
      "Epoch: 13/20... Training loss: 0.0944\n",
      "Epoch: 13/20... Training loss: 0.0962\n",
      "Epoch: 13/20... Training loss: 0.0977\n",
      "Epoch: 13/20... Training loss: 0.0894\n",
      "Epoch: 13/20... Training loss: 0.0966\n",
      "Epoch: 13/20... Training loss: 0.0951\n",
      "Epoch: 13/20... Training loss: 0.0935\n",
      "Epoch: 13/20... Training loss: 0.0951\n",
      "Epoch: 13/20... Training loss: 0.0957\n",
      "Epoch: 13/20... Training loss: 0.0946\n",
      "Epoch: 13/20... Training loss: 0.0947\n",
      "Epoch: 13/20... Training loss: 0.0937\n",
      "Epoch: 13/20... Training loss: 0.0922\n",
      "Epoch: 13/20... Training loss: 0.0977\n",
      "Epoch: 13/20... Training loss: 0.0938\n",
      "Epoch: 13/20... Training loss: 0.0950\n",
      "Epoch: 13/20... Training loss: 0.0983\n",
      "Epoch: 13/20... Training loss: 0.0959\n",
      "Epoch: 13/20... Training loss: 0.0933\n",
      "Epoch: 13/20... Training loss: 0.0951\n",
      "Epoch: 13/20... Training loss: 0.0938\n",
      "Epoch: 13/20... Training loss: 0.0924\n",
      "Epoch: 13/20... Training loss: 0.0954\n",
      "Epoch: 13/20... Training loss: 0.0910\n",
      "Epoch: 13/20... Training loss: 0.0962\n",
      "Epoch: 13/20... Training loss: 0.0932\n",
      "Epoch: 13/20... Training loss: 0.0971\n",
      "Epoch: 13/20... Training loss: 0.0948\n",
      "Epoch: 13/20... Training loss: 0.0931\n",
      "Epoch: 13/20... Training loss: 0.0929\n",
      "Epoch: 13/20... Training loss: 0.0954\n",
      "Epoch: 14/20... Training loss: 0.0943\n",
      "Epoch: 14/20... Training loss: 0.0920\n",
      "Epoch: 14/20... Training loss: 0.0929\n",
      "Epoch: 14/20... Training loss: 0.0969\n",
      "Epoch: 14/20... Training loss: 0.0997\n",
      "Epoch: 14/20... Training loss: 0.0935\n",
      "Epoch: 14/20... Training loss: 0.0957\n",
      "Epoch: 14/20... Training loss: 0.0949\n",
      "Epoch: 14/20... Training loss: 0.0873\n",
      "Epoch: 14/20... Training loss: 0.0962\n",
      "Epoch: 14/20... Training loss: 0.0945\n",
      "Epoch: 14/20... Training loss: 0.0954\n",
      "Epoch: 14/20... Training loss: 0.0939\n",
      "Epoch: 14/20... Training loss: 0.0930\n",
      "Epoch: 14/20... Training loss: 0.0928\n",
      "Epoch: 14/20... Training loss: 0.0953\n",
      "Epoch: 14/20... Training loss: 0.0901\n",
      "Epoch: 14/20... Training loss: 0.0963\n",
      "Epoch: 14/20... Training loss: 0.0943\n",
      "Epoch: 14/20... Training loss: 0.0930\n",
      "Epoch: 14/20... Training loss: 0.0943\n",
      "Epoch: 14/20... Training loss: 0.0919\n",
      "Epoch: 14/20... Training loss: 0.0984\n",
      "Epoch: 14/20... Training loss: 0.0937\n",
      "Epoch: 14/20... Training loss: 0.0937\n",
      "Epoch: 14/20... Training loss: 0.0928\n",
      "Epoch: 14/20... Training loss: 0.0908\n",
      "Epoch: 14/20... Training loss: 0.0936\n",
      "Epoch: 14/20... Training loss: 0.0936\n",
      "Epoch: 14/20... Training loss: 0.0933\n",
      "Epoch: 14/20... Training loss: 0.0936\n",
      "Epoch: 14/20... Training loss: 0.0905\n",
      "Epoch: 14/20... Training loss: 0.0977\n",
      "Epoch: 14/20... Training loss: 0.0942\n",
      "Epoch: 14/20... Training loss: 0.0913\n",
      "Epoch: 14/20... Training loss: 0.0933\n",
      "Epoch: 14/20... Training loss: 0.0969\n",
      "Epoch: 14/20... Training loss: 0.0944\n",
      "Epoch: 14/20... Training loss: 0.0937\n",
      "Epoch: 14/20... Training loss: 0.0977\n",
      "Epoch: 14/20... Training loss: 0.0936\n",
      "Epoch: 14/20... Training loss: 0.0964\n",
      "Epoch: 14/20... Training loss: 0.0938\n",
      "Epoch: 14/20... Training loss: 0.0927\n",
      "Epoch: 14/20... Training loss: 0.0940\n",
      "Epoch: 14/20... Training loss: 0.0955\n",
      "Epoch: 14/20... Training loss: 0.0926\n",
      "Epoch: 14/20... Training loss: 0.0910\n",
      "Epoch: 14/20... Training loss: 0.0939\n",
      "Epoch: 14/20... Training loss: 0.0931\n",
      "Epoch: 14/20... Training loss: 0.0934\n",
      "Epoch: 14/20... Training loss: 0.0967\n",
      "Epoch: 14/20... Training loss: 0.1009\n",
      "Epoch: 14/20... Training loss: 0.0954\n",
      "Epoch: 14/20... Training loss: 0.0907\n",
      "Epoch: 14/20... Training loss: 0.0918\n",
      "Epoch: 14/20... Training loss: 0.0969\n",
      "Epoch: 14/20... Training loss: 0.0955\n",
      "Epoch: 14/20... Training loss: 0.0924\n",
      "Epoch: 14/20... Training loss: 0.0915\n",
      "Epoch: 14/20... Training loss: 0.0944\n",
      "Epoch: 14/20... Training loss: 0.0943\n",
      "Epoch: 14/20... Training loss: 0.0929\n",
      "Epoch: 14/20... Training loss: 0.0958\n",
      "Epoch: 14/20... Training loss: 0.0941\n",
      "Epoch: 14/20... Training loss: 0.0899\n",
      "Epoch: 14/20... Training loss: 0.0949\n",
      "Epoch: 14/20... Training loss: 0.0932\n",
      "Epoch: 14/20... Training loss: 0.0975\n",
      "Epoch: 14/20... Training loss: 0.0937\n",
      "Epoch: 14/20... Training loss: 0.0959\n",
      "Epoch: 14/20... Training loss: 0.0938\n",
      "Epoch: 14/20... Training loss: 0.0935\n",
      "Epoch: 14/20... Training loss: 0.0957\n",
      "Epoch: 14/20... Training loss: 0.0965\n",
      "Epoch: 14/20... Training loss: 0.0957\n",
      "Epoch: 14/20... Training loss: 0.0950\n",
      "Epoch: 14/20... Training loss: 0.0938\n",
      "Epoch: 14/20... Training loss: 0.0903\n",
      "Epoch: 14/20... Training loss: 0.0920\n",
      "Epoch: 14/20... Training loss: 0.0929\n",
      "Epoch: 14/20... Training loss: 0.0935\n",
      "Epoch: 14/20... Training loss: 0.0940\n",
      "Epoch: 14/20... Training loss: 0.0982\n",
      "Epoch: 14/20... Training loss: 0.0943\n",
      "Epoch: 14/20... Training loss: 0.0969\n",
      "Epoch: 14/20... Training loss: 0.0944\n",
      "Epoch: 14/20... Training loss: 0.0952\n",
      "Epoch: 14/20... Training loss: 0.0920\n",
      "Epoch: 14/20... Training loss: 0.0931\n",
      "Epoch: 14/20... Training loss: 0.0909\n",
      "Epoch: 14/20... Training loss: 0.0954\n",
      "Epoch: 14/20... Training loss: 0.0957\n",
      "Epoch: 14/20... Training loss: 0.0924\n",
      "Epoch: 14/20... Training loss: 0.0972\n",
      "Epoch: 14/20... Training loss: 0.0930\n",
      "Epoch: 14/20... Training loss: 0.0951\n",
      "Epoch: 14/20... Training loss: 0.0907\n",
      "Epoch: 14/20... Training loss: 0.0951\n",
      "Epoch: 14/20... Training loss: 0.0959\n",
      "Epoch: 14/20... Training loss: 0.0954\n",
      "Epoch: 14/20... Training loss: 0.0969\n",
      "Epoch: 14/20... Training loss: 0.0973\n",
      "Epoch: 14/20... Training loss: 0.0914\n",
      "Epoch: 14/20... Training loss: 0.0899\n",
      "Epoch: 14/20... Training loss: 0.0937\n",
      "Epoch: 14/20... Training loss: 0.0925\n",
      "Epoch: 14/20... Training loss: 0.0924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/20... Training loss: 0.0987\n",
      "Epoch: 14/20... Training loss: 0.0931\n",
      "Epoch: 14/20... Training loss: 0.0904\n",
      "Epoch: 14/20... Training loss: 0.0940\n",
      "Epoch: 14/20... Training loss: 0.0944\n",
      "Epoch: 14/20... Training loss: 0.0958\n",
      "Epoch: 14/20... Training loss: 0.0947\n",
      "Epoch: 14/20... Training loss: 0.0922\n",
      "Epoch: 14/20... Training loss: 0.0949\n",
      "Epoch: 14/20... Training loss: 0.0974\n",
      "Epoch: 14/20... Training loss: 0.0943\n",
      "Epoch: 14/20... Training loss: 0.0938\n",
      "Epoch: 14/20... Training loss: 0.0896\n",
      "Epoch: 14/20... Training loss: 0.0957\n",
      "Epoch: 14/20... Training loss: 0.0957\n",
      "Epoch: 14/20... Training loss: 0.0963\n",
      "Epoch: 14/20... Training loss: 0.0950\n",
      "Epoch: 14/20... Training loss: 0.0939\n",
      "Epoch: 14/20... Training loss: 0.0932\n",
      "Epoch: 14/20... Training loss: 0.0971\n",
      "Epoch: 14/20... Training loss: 0.0927\n",
      "Epoch: 14/20... Training loss: 0.0954\n",
      "Epoch: 14/20... Training loss: 0.0926\n",
      "Epoch: 14/20... Training loss: 0.0919\n",
      "Epoch: 14/20... Training loss: 0.0960\n",
      "Epoch: 14/20... Training loss: 0.0968\n",
      "Epoch: 14/20... Training loss: 0.1002\n",
      "Epoch: 14/20... Training loss: 0.0920\n",
      "Epoch: 14/20... Training loss: 0.0906\n",
      "Epoch: 14/20... Training loss: 0.0933\n",
      "Epoch: 14/20... Training loss: 0.1003\n",
      "Epoch: 14/20... Training loss: 0.0912\n",
      "Epoch: 14/20... Training loss: 0.0947\n",
      "Epoch: 14/20... Training loss: 0.0896\n",
      "Epoch: 14/20... Training loss: 0.0954\n",
      "Epoch: 14/20... Training loss: 0.0966\n",
      "Epoch: 14/20... Training loss: 0.0928\n",
      "Epoch: 14/20... Training loss: 0.0945\n",
      "Epoch: 14/20... Training loss: 0.0926\n",
      "Epoch: 14/20... Training loss: 0.0941\n",
      "Epoch: 14/20... Training loss: 0.0914\n",
      "Epoch: 14/20... Training loss: 0.0966\n",
      "Epoch: 14/20... Training loss: 0.0934\n",
      "Epoch: 14/20... Training loss: 0.0918\n",
      "Epoch: 14/20... Training loss: 0.0917\n",
      "Epoch: 14/20... Training loss: 0.0923\n",
      "Epoch: 14/20... Training loss: 0.0929\n",
      "Epoch: 14/20... Training loss: 0.0966\n",
      "Epoch: 14/20... Training loss: 0.0967\n",
      "Epoch: 14/20... Training loss: 0.0948\n",
      "Epoch: 14/20... Training loss: 0.0952\n",
      "Epoch: 14/20... Training loss: 0.0970\n",
      "Epoch: 14/20... Training loss: 0.0939\n",
      "Epoch: 14/20... Training loss: 0.0930\n",
      "Epoch: 14/20... Training loss: 0.0945\n",
      "Epoch: 14/20... Training loss: 0.0966\n",
      "Epoch: 14/20... Training loss: 0.0944\n",
      "Epoch: 14/20... Training loss: 0.0953\n",
      "Epoch: 14/20... Training loss: 0.0933\n",
      "Epoch: 14/20... Training loss: 0.0919\n",
      "Epoch: 14/20... Training loss: 0.0975\n",
      "Epoch: 14/20... Training loss: 0.0977\n",
      "Epoch: 14/20... Training loss: 0.0942\n",
      "Epoch: 14/20... Training loss: 0.0932\n",
      "Epoch: 14/20... Training loss: 0.0942\n",
      "Epoch: 14/20... Training loss: 0.0957\n",
      "Epoch: 14/20... Training loss: 0.0968\n",
      "Epoch: 14/20... Training loss: 0.0940\n",
      "Epoch: 14/20... Training loss: 0.0917\n",
      "Epoch: 14/20... Training loss: 0.0955\n",
      "Epoch: 14/20... Training loss: 0.0957\n",
      "Epoch: 14/20... Training loss: 0.0911\n",
      "Epoch: 14/20... Training loss: 0.0900\n",
      "Epoch: 14/20... Training loss: 0.0908\n",
      "Epoch: 14/20... Training loss: 0.0947\n",
      "Epoch: 14/20... Training loss: 0.0952\n",
      "Epoch: 14/20... Training loss: 0.0918\n",
      "Epoch: 14/20... Training loss: 0.0921\n",
      "Epoch: 14/20... Training loss: 0.0963\n",
      "Epoch: 14/20... Training loss: 0.0928\n",
      "Epoch: 14/20... Training loss: 0.0890\n",
      "Epoch: 14/20... Training loss: 0.0923\n",
      "Epoch: 14/20... Training loss: 0.0938\n",
      "Epoch: 14/20... Training loss: 0.0934\n",
      "Epoch: 14/20... Training loss: 0.0907\n",
      "Epoch: 14/20... Training loss: 0.0924\n",
      "Epoch: 14/20... Training loss: 0.0939\n",
      "Epoch: 14/20... Training loss: 0.0936\n",
      "Epoch: 14/20... Training loss: 0.0917\n",
      "Epoch: 14/20... Training loss: 0.0920\n",
      "Epoch: 14/20... Training loss: 0.0975\n",
      "Epoch: 14/20... Training loss: 0.0941\n",
      "Epoch: 14/20... Training loss: 0.0938\n",
      "Epoch: 14/20... Training loss: 0.0915\n",
      "Epoch: 14/20... Training loss: 0.0930\n",
      "Epoch: 14/20... Training loss: 0.0927\n",
      "Epoch: 14/20... Training loss: 0.0960\n",
      "Epoch: 14/20... Training loss: 0.0952\n",
      "Epoch: 14/20... Training loss: 0.0929\n",
      "Epoch: 14/20... Training loss: 0.0953\n",
      "Epoch: 14/20... Training loss: 0.0918\n",
      "Epoch: 14/20... Training loss: 0.0951\n",
      "Epoch: 14/20... Training loss: 0.0965\n",
      "Epoch: 14/20... Training loss: 0.0928\n",
      "Epoch: 14/20... Training loss: 0.0919\n",
      "Epoch: 14/20... Training loss: 0.0904\n",
      "Epoch: 14/20... Training loss: 0.0961\n",
      "Epoch: 14/20... Training loss: 0.0966\n",
      "Epoch: 14/20... Training loss: 0.0971\n",
      "Epoch: 14/20... Training loss: 0.0965\n",
      "Epoch: 14/20... Training loss: 0.0942\n",
      "Epoch: 14/20... Training loss: 0.0937\n",
      "Epoch: 14/20... Training loss: 0.0934\n",
      "Epoch: 14/20... Training loss: 0.0931\n",
      "Epoch: 14/20... Training loss: 0.0931\n",
      "Epoch: 14/20... Training loss: 0.0959\n",
      "Epoch: 14/20... Training loss: 0.0968\n",
      "Epoch: 14/20... Training loss: 0.0933\n",
      "Epoch: 14/20... Training loss: 0.0956\n",
      "Epoch: 14/20... Training loss: 0.0951\n",
      "Epoch: 14/20... Training loss: 0.0930\n",
      "Epoch: 14/20... Training loss: 0.0929\n",
      "Epoch: 14/20... Training loss: 0.0945\n",
      "Epoch: 14/20... Training loss: 0.0930\n",
      "Epoch: 14/20... Training loss: 0.0924\n",
      "Epoch: 14/20... Training loss: 0.0962\n",
      "Epoch: 14/20... Training loss: 0.0980\n",
      "Epoch: 14/20... Training loss: 0.0955\n",
      "Epoch: 14/20... Training loss: 0.0933\n",
      "Epoch: 14/20... Training loss: 0.0930\n",
      "Epoch: 14/20... Training loss: 0.0936\n",
      "Epoch: 14/20... Training loss: 0.0925\n",
      "Epoch: 14/20... Training loss: 0.0982\n",
      "Epoch: 14/20... Training loss: 0.0917\n",
      "Epoch: 14/20... Training loss: 0.0939\n",
      "Epoch: 14/20... Training loss: 0.0938\n",
      "Epoch: 14/20... Training loss: 0.0955\n",
      "Epoch: 14/20... Training loss: 0.0953\n",
      "Epoch: 14/20... Training loss: 0.0954\n",
      "Epoch: 14/20... Training loss: 0.0929\n",
      "Epoch: 14/20... Training loss: 0.0946\n",
      "Epoch: 14/20... Training loss: 0.0963\n",
      "Epoch: 14/20... Training loss: 0.0883\n",
      "Epoch: 14/20... Training loss: 0.0917\n",
      "Epoch: 14/20... Training loss: 0.0925\n",
      "Epoch: 14/20... Training loss: 0.0953\n",
      "Epoch: 14/20... Training loss: 0.0958\n",
      "Epoch: 14/20... Training loss: 0.0918\n",
      "Epoch: 14/20... Training loss: 0.0926\n",
      "Epoch: 14/20... Training loss: 0.0937\n",
      "Epoch: 14/20... Training loss: 0.0960\n",
      "Epoch: 14/20... Training loss: 0.0938\n",
      "Epoch: 14/20... Training loss: 0.0946\n",
      "Epoch: 14/20... Training loss: 0.0958\n",
      "Epoch: 14/20... Training loss: 0.0926\n",
      "Epoch: 14/20... Training loss: 0.0960\n",
      "Epoch: 14/20... Training loss: 0.0942\n",
      "Epoch: 14/20... Training loss: 0.0925\n",
      "Epoch: 14/20... Training loss: 0.0950\n",
      "Epoch: 14/20... Training loss: 0.0968\n",
      "Epoch: 14/20... Training loss: 0.0930\n",
      "Epoch: 14/20... Training loss: 0.0917\n",
      "Epoch: 14/20... Training loss: 0.0950\n",
      "Epoch: 14/20... Training loss: 0.0909\n",
      "Epoch: 14/20... Training loss: 0.0972\n",
      "Epoch: 14/20... Training loss: 0.0961\n",
      "Epoch: 14/20... Training loss: 0.0959\n",
      "Epoch: 14/20... Training loss: 0.0951\n",
      "Epoch: 14/20... Training loss: 0.0931\n",
      "Epoch: 14/20... Training loss: 0.0950\n",
      "Epoch: 14/20... Training loss: 0.0941\n",
      "Epoch: 14/20... Training loss: 0.0940\n",
      "Epoch: 14/20... Training loss: 0.0944\n",
      "Epoch: 14/20... Training loss: 0.0936\n",
      "Epoch: 14/20... Training loss: 0.0889\n",
      "Epoch: 14/20... Training loss: 0.0965\n",
      "Epoch: 14/20... Training loss: 0.0931\n",
      "Epoch: 14/20... Training loss: 0.0912\n",
      "Epoch: 14/20... Training loss: 0.0915\n",
      "Epoch: 14/20... Training loss: 0.0958\n",
      "Epoch: 14/20... Training loss: 0.0939\n",
      "Epoch: 14/20... Training loss: 0.0954\n",
      "Epoch: 14/20... Training loss: 0.0939\n",
      "Epoch: 14/20... Training loss: 0.0913\n",
      "Epoch: 14/20... Training loss: 0.0943\n",
      "Epoch: 14/20... Training loss: 0.0934\n",
      "Epoch: 14/20... Training loss: 0.0960\n",
      "Epoch: 14/20... Training loss: 0.0898\n",
      "Epoch: 14/20... Training loss: 0.0933\n",
      "Epoch: 14/20... Training loss: 0.0945\n",
      "Epoch: 14/20... Training loss: 0.0924\n",
      "Epoch: 14/20... Training loss: 0.0934\n",
      "Epoch: 15/20... Training loss: 0.0943\n",
      "Epoch: 15/20... Training loss: 0.0950\n",
      "Epoch: 15/20... Training loss: 0.0928\n",
      "Epoch: 15/20... Training loss: 0.0938\n",
      "Epoch: 15/20... Training loss: 0.0927\n",
      "Epoch: 15/20... Training loss: 0.0929\n",
      "Epoch: 15/20... Training loss: 0.0946\n",
      "Epoch: 15/20... Training loss: 0.0934\n",
      "Epoch: 15/20... Training loss: 0.0969\n",
      "Epoch: 15/20... Training loss: 0.0944\n",
      "Epoch: 15/20... Training loss: 0.0927\n",
      "Epoch: 15/20... Training loss: 0.0926\n",
      "Epoch: 15/20... Training loss: 0.0953\n",
      "Epoch: 15/20... Training loss: 0.0934\n",
      "Epoch: 15/20... Training loss: 0.0937\n",
      "Epoch: 15/20... Training loss: 0.0947\n",
      "Epoch: 15/20... Training loss: 0.0922\n",
      "Epoch: 15/20... Training loss: 0.0915\n",
      "Epoch: 15/20... Training loss: 0.0956\n",
      "Epoch: 15/20... Training loss: 0.0898\n",
      "Epoch: 15/20... Training loss: 0.0984\n",
      "Epoch: 15/20... Training loss: 0.0925\n",
      "Epoch: 15/20... Training loss: 0.0931\n",
      "Epoch: 15/20... Training loss: 0.0966\n",
      "Epoch: 15/20... Training loss: 0.0935\n",
      "Epoch: 15/20... Training loss: 0.0945\n",
      "Epoch: 15/20... Training loss: 0.0981\n",
      "Epoch: 15/20... Training loss: 0.0942\n",
      "Epoch: 15/20... Training loss: 0.0935\n",
      "Epoch: 15/20... Training loss: 0.0927\n",
      "Epoch: 15/20... Training loss: 0.0899\n",
      "Epoch: 15/20... Training loss: 0.0932\n",
      "Epoch: 15/20... Training loss: 0.0942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/20... Training loss: 0.0930\n",
      "Epoch: 15/20... Training loss: 0.0929\n",
      "Epoch: 15/20... Training loss: 0.0947\n",
      "Epoch: 15/20... Training loss: 0.0939\n",
      "Epoch: 15/20... Training loss: 0.0938\n",
      "Epoch: 15/20... Training loss: 0.0921\n",
      "Epoch: 15/20... Training loss: 0.0938\n",
      "Epoch: 15/20... Training loss: 0.0972\n",
      "Epoch: 15/20... Training loss: 0.0948\n",
      "Epoch: 15/20... Training loss: 0.0957\n",
      "Epoch: 15/20... Training loss: 0.0957\n",
      "Epoch: 15/20... Training loss: 0.0943\n",
      "Epoch: 15/20... Training loss: 0.0968\n",
      "Epoch: 15/20... Training loss: 0.0929\n",
      "Epoch: 15/20... Training loss: 0.0940\n",
      "Epoch: 15/20... Training loss: 0.0958\n",
      "Epoch: 15/20... Training loss: 0.0937\n",
      "Epoch: 15/20... Training loss: 0.0926\n",
      "Epoch: 15/20... Training loss: 0.0925\n",
      "Epoch: 15/20... Training loss: 0.0935\n",
      "Epoch: 15/20... Training loss: 0.0967\n",
      "Epoch: 15/20... Training loss: 0.0911\n",
      "Epoch: 15/20... Training loss: 0.0948\n",
      "Epoch: 15/20... Training loss: 0.0917\n",
      "Epoch: 15/20... Training loss: 0.0908\n",
      "Epoch: 15/20... Training loss: 0.0935\n",
      "Epoch: 15/20... Training loss: 0.0943\n",
      "Epoch: 15/20... Training loss: 0.0947\n",
      "Epoch: 15/20... Training loss: 0.0969\n",
      "Epoch: 15/20... Training loss: 0.0931\n",
      "Epoch: 15/20... Training loss: 0.0945\n",
      "Epoch: 15/20... Training loss: 0.0942\n",
      "Epoch: 15/20... Training loss: 0.0972\n",
      "Epoch: 15/20... Training loss: 0.0932\n",
      "Epoch: 15/20... Training loss: 0.0970\n",
      "Epoch: 15/20... Training loss: 0.0952\n",
      "Epoch: 15/20... Training loss: 0.0940\n",
      "Epoch: 15/20... Training loss: 0.0953\n",
      "Epoch: 15/20... Training loss: 0.0958\n",
      "Epoch: 15/20... Training loss: 0.0945\n",
      "Epoch: 15/20... Training loss: 0.0926\n",
      "Epoch: 15/20... Training loss: 0.0912\n",
      "Epoch: 15/20... Training loss: 0.0962\n",
      "Epoch: 15/20... Training loss: 0.0973\n",
      "Epoch: 15/20... Training loss: 0.0940\n",
      "Epoch: 15/20... Training loss: 0.0936\n",
      "Epoch: 15/20... Training loss: 0.0935\n",
      "Epoch: 15/20... Training loss: 0.0964\n",
      "Epoch: 15/20... Training loss: 0.0951\n",
      "Epoch: 15/20... Training loss: 0.0928\n",
      "Epoch: 15/20... Training loss: 0.0952\n",
      "Epoch: 15/20... Training loss: 0.0971\n",
      "Epoch: 15/20... Training loss: 0.0964\n",
      "Epoch: 15/20... Training loss: 0.0928\n",
      "Epoch: 15/20... Training loss: 0.0953\n",
      "Epoch: 15/20... Training loss: 0.0974\n",
      "Epoch: 15/20... Training loss: 0.0918\n",
      "Epoch: 15/20... Training loss: 0.0925\n",
      "Epoch: 15/20... Training loss: 0.0955\n",
      "Epoch: 15/20... Training loss: 0.0922\n",
      "Epoch: 15/20... Training loss: 0.0944\n",
      "Epoch: 15/20... Training loss: 0.0946\n",
      "Epoch: 15/20... Training loss: 0.0956\n",
      "Epoch: 15/20... Training loss: 0.0930\n",
      "Epoch: 15/20... Training loss: 0.0966\n",
      "Epoch: 15/20... Training loss: 0.0937\n",
      "Epoch: 15/20... Training loss: 0.0916\n",
      "Epoch: 15/20... Training loss: 0.0946\n",
      "Epoch: 15/20... Training loss: 0.0919\n",
      "Epoch: 15/20... Training loss: 0.0964\n",
      "Epoch: 15/20... Training loss: 0.0940\n",
      "Epoch: 15/20... Training loss: 0.0954\n",
      "Epoch: 15/20... Training loss: 0.0943\n",
      "Epoch: 15/20... Training loss: 0.0918\n",
      "Epoch: 15/20... Training loss: 0.0929\n",
      "Epoch: 15/20... Training loss: 0.0939\n",
      "Epoch: 15/20... Training loss: 0.0976\n",
      "Epoch: 15/20... Training loss: 0.0940\n",
      "Epoch: 15/20... Training loss: 0.0923\n",
      "Epoch: 15/20... Training loss: 0.0891\n",
      "Epoch: 15/20... Training loss: 0.0932\n",
      "Epoch: 15/20... Training loss: 0.0940\n",
      "Epoch: 15/20... Training loss: 0.0929\n",
      "Epoch: 15/20... Training loss: 0.0937\n",
      "Epoch: 15/20... Training loss: 0.0950\n",
      "Epoch: 15/20... Training loss: 0.0943\n",
      "Epoch: 15/20... Training loss: 0.0949\n",
      "Epoch: 15/20... Training loss: 0.0958\n",
      "Epoch: 15/20... Training loss: 0.0950\n",
      "Epoch: 15/20... Training loss: 0.0945\n",
      "Epoch: 15/20... Training loss: 0.0989\n",
      "Epoch: 15/20... Training loss: 0.0976\n",
      "Epoch: 15/20... Training loss: 0.0918\n",
      "Epoch: 15/20... Training loss: 0.0954\n",
      "Epoch: 15/20... Training loss: 0.0929\n",
      "Epoch: 15/20... Training loss: 0.0957\n",
      "Epoch: 15/20... Training loss: 0.0948\n",
      "Epoch: 15/20... Training loss: 0.0953\n",
      "Epoch: 15/20... Training loss: 0.0958\n",
      "Epoch: 15/20... Training loss: 0.0912\n",
      "Epoch: 15/20... Training loss: 0.0925\n",
      "Epoch: 15/20... Training loss: 0.0925\n",
      "Epoch: 15/20... Training loss: 0.0945\n",
      "Epoch: 15/20... Training loss: 0.0931\n",
      "Epoch: 15/20... Training loss: 0.0958\n",
      "Epoch: 15/20... Training loss: 0.0948\n",
      "Epoch: 15/20... Training loss: 0.0885\n",
      "Epoch: 15/20... Training loss: 0.0964\n",
      "Epoch: 15/20... Training loss: 0.0926\n",
      "Epoch: 15/20... Training loss: 0.0934\n",
      "Epoch: 15/20... Training loss: 0.0980\n",
      "Epoch: 15/20... Training loss: 0.0947\n",
      "Epoch: 15/20... Training loss: 0.0928\n",
      "Epoch: 15/20... Training loss: 0.0941\n",
      "Epoch: 15/20... Training loss: 0.0941\n",
      "Epoch: 15/20... Training loss: 0.0927\n",
      "Epoch: 15/20... Training loss: 0.0943\n",
      "Epoch: 15/20... Training loss: 0.0925\n",
      "Epoch: 15/20... Training loss: 0.0938\n",
      "Epoch: 15/20... Training loss: 0.0933\n",
      "Epoch: 15/20... Training loss: 0.0961\n",
      "Epoch: 15/20... Training loss: 0.0943\n",
      "Epoch: 15/20... Training loss: 0.0970\n",
      "Epoch: 15/20... Training loss: 0.0888\n",
      "Epoch: 15/20... Training loss: 0.0982\n",
      "Epoch: 15/20... Training loss: 0.0900\n",
      "Epoch: 15/20... Training loss: 0.0934\n",
      "Epoch: 15/20... Training loss: 0.0897\n",
      "Epoch: 15/20... Training loss: 0.0955\n",
      "Epoch: 15/20... Training loss: 0.0941\n",
      "Epoch: 15/20... Training loss: 0.0953\n",
      "Epoch: 15/20... Training loss: 0.0949\n",
      "Epoch: 15/20... Training loss: 0.0906\n",
      "Epoch: 15/20... Training loss: 0.0957\n",
      "Epoch: 15/20... Training loss: 0.0937\n",
      "Epoch: 15/20... Training loss: 0.0955\n",
      "Epoch: 15/20... Training loss: 0.0929\n",
      "Epoch: 15/20... Training loss: 0.0934\n",
      "Epoch: 15/20... Training loss: 0.0902\n",
      "Epoch: 15/20... Training loss: 0.0935\n",
      "Epoch: 15/20... Training loss: 0.0925\n",
      "Epoch: 15/20... Training loss: 0.0944\n",
      "Epoch: 15/20... Training loss: 0.0942\n",
      "Epoch: 15/20... Training loss: 0.0949\n",
      "Epoch: 15/20... Training loss: 0.0965\n",
      "Epoch: 15/20... Training loss: 0.0946\n",
      "Epoch: 15/20... Training loss: 0.0928\n",
      "Epoch: 15/20... Training loss: 0.0978\n",
      "Epoch: 15/20... Training loss: 0.0962\n",
      "Epoch: 15/20... Training loss: 0.0953\n",
      "Epoch: 15/20... Training loss: 0.0908\n",
      "Epoch: 15/20... Training loss: 0.0966\n",
      "Epoch: 15/20... Training loss: 0.0944\n",
      "Epoch: 15/20... Training loss: 0.0922\n",
      "Epoch: 15/20... Training loss: 0.0946\n",
      "Epoch: 15/20... Training loss: 0.0884\n",
      "Epoch: 15/20... Training loss: 0.0919\n",
      "Epoch: 15/20... Training loss: 0.0958\n",
      "Epoch: 15/20... Training loss: 0.0916\n",
      "Epoch: 15/20... Training loss: 0.0935\n",
      "Epoch: 15/20... Training loss: 0.0903\n",
      "Epoch: 15/20... Training loss: 0.0916\n",
      "Epoch: 15/20... Training loss: 0.0921\n",
      "Epoch: 15/20... Training loss: 0.0961\n",
      "Epoch: 15/20... Training loss: 0.0943\n",
      "Epoch: 15/20... Training loss: 0.0957\n",
      "Epoch: 15/20... Training loss: 0.0922\n",
      "Epoch: 15/20... Training loss: 0.0932\n",
      "Epoch: 15/20... Training loss: 0.0948\n",
      "Epoch: 15/20... Training loss: 0.0947\n",
      "Epoch: 15/20... Training loss: 0.0914\n",
      "Epoch: 15/20... Training loss: 0.0963\n",
      "Epoch: 15/20... Training loss: 0.0933\n",
      "Epoch: 15/20... Training loss: 0.0922\n",
      "Epoch: 15/20... Training loss: 0.0939\n",
      "Epoch: 15/20... Training loss: 0.0928\n",
      "Epoch: 15/20... Training loss: 0.0965\n",
      "Epoch: 15/20... Training loss: 0.0890\n",
      "Epoch: 15/20... Training loss: 0.0948\n",
      "Epoch: 15/20... Training loss: 0.0956\n",
      "Epoch: 15/20... Training loss: 0.0945\n",
      "Epoch: 15/20... Training loss: 0.0948\n",
      "Epoch: 15/20... Training loss: 0.0959\n",
      "Epoch: 15/20... Training loss: 0.0937\n",
      "Epoch: 15/20... Training loss: 0.0921\n",
      "Epoch: 15/20... Training loss: 0.0926\n",
      "Epoch: 15/20... Training loss: 0.0962\n",
      "Epoch: 15/20... Training loss: 0.0956\n",
      "Epoch: 15/20... Training loss: 0.0937\n",
      "Epoch: 15/20... Training loss: 0.0956\n",
      "Epoch: 15/20... Training loss: 0.0961\n",
      "Epoch: 15/20... Training loss: 0.0965\n",
      "Epoch: 15/20... Training loss: 0.0940\n",
      "Epoch: 15/20... Training loss: 0.0914\n",
      "Epoch: 15/20... Training loss: 0.0918\n",
      "Epoch: 15/20... Training loss: 0.0883\n",
      "Epoch: 15/20... Training loss: 0.0962\n",
      "Epoch: 15/20... Training loss: 0.0934\n",
      "Epoch: 15/20... Training loss: 0.0944\n",
      "Epoch: 15/20... Training loss: 0.0938\n",
      "Epoch: 15/20... Training loss: 0.0941\n",
      "Epoch: 15/20... Training loss: 0.0943\n",
      "Epoch: 15/20... Training loss: 0.0911\n",
      "Epoch: 15/20... Training loss: 0.0912\n",
      "Epoch: 15/20... Training loss: 0.0909\n",
      "Epoch: 15/20... Training loss: 0.0915\n",
      "Epoch: 15/20... Training loss: 0.0925\n",
      "Epoch: 15/20... Training loss: 0.0940\n",
      "Epoch: 15/20... Training loss: 0.0930\n",
      "Epoch: 15/20... Training loss: 0.0924\n",
      "Epoch: 15/20... Training loss: 0.0977\n",
      "Epoch: 15/20... Training loss: 0.0921\n",
      "Epoch: 15/20... Training loss: 0.0952\n",
      "Epoch: 15/20... Training loss: 0.0937\n",
      "Epoch: 15/20... Training loss: 0.0952\n",
      "Epoch: 15/20... Training loss: 0.0900\n",
      "Epoch: 15/20... Training loss: 0.0927\n",
      "Epoch: 15/20... Training loss: 0.0901\n",
      "Epoch: 15/20... Training loss: 0.0917\n",
      "Epoch: 15/20... Training loss: 0.0954\n",
      "Epoch: 15/20... Training loss: 0.0937\n",
      "Epoch: 15/20... Training loss: 0.0952\n",
      "Epoch: 15/20... Training loss: 0.0944\n",
      "Epoch: 15/20... Training loss: 0.0923\n",
      "Epoch: 15/20... Training loss: 0.0963\n",
      "Epoch: 15/20... Training loss: 0.0934\n",
      "Epoch: 15/20... Training loss: 0.0931\n",
      "Epoch: 15/20... Training loss: 0.0968\n",
      "Epoch: 15/20... Training loss: 0.0949\n",
      "Epoch: 15/20... Training loss: 0.0937\n",
      "Epoch: 15/20... Training loss: 0.0928\n",
      "Epoch: 15/20... Training loss: 0.0935\n",
      "Epoch: 15/20... Training loss: 0.0939\n",
      "Epoch: 15/20... Training loss: 0.0920\n",
      "Epoch: 15/20... Training loss: 0.0922\n",
      "Epoch: 15/20... Training loss: 0.0943\n",
      "Epoch: 15/20... Training loss: 0.0898\n",
      "Epoch: 15/20... Training loss: 0.0931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/20... Training loss: 0.0936\n",
      "Epoch: 15/20... Training loss: 0.0908\n",
      "Epoch: 15/20... Training loss: 0.0887\n",
      "Epoch: 15/20... Training loss: 0.0938\n",
      "Epoch: 15/20... Training loss: 0.0945\n",
      "Epoch: 15/20... Training loss: 0.0931\n",
      "Epoch: 15/20... Training loss: 0.0945\n",
      "Epoch: 15/20... Training loss: 0.0953\n",
      "Epoch: 15/20... Training loss: 0.0948\n",
      "Epoch: 15/20... Training loss: 0.0951\n",
      "Epoch: 15/20... Training loss: 0.0952\n",
      "Epoch: 15/20... Training loss: 0.0943\n",
      "Epoch: 15/20... Training loss: 0.0950\n",
      "Epoch: 15/20... Training loss: 0.0957\n",
      "Epoch: 15/20... Training loss: 0.0943\n",
      "Epoch: 15/20... Training loss: 0.0951\n",
      "Epoch: 15/20... Training loss: 0.0925\n",
      "Epoch: 15/20... Training loss: 0.0955\n",
      "Epoch: 15/20... Training loss: 0.0911\n",
      "Epoch: 15/20... Training loss: 0.0953\n",
      "Epoch: 15/20... Training loss: 0.0903\n",
      "Epoch: 15/20... Training loss: 0.0933\n",
      "Epoch: 15/20... Training loss: 0.0937\n",
      "Epoch: 15/20... Training loss: 0.0949\n",
      "Epoch: 15/20... Training loss: 0.0954\n",
      "Epoch: 15/20... Training loss: 0.0943\n",
      "Epoch: 15/20... Training loss: 0.0908\n",
      "Epoch: 15/20... Training loss: 0.0909\n",
      "Epoch: 15/20... Training loss: 0.0953\n",
      "Epoch: 16/20... Training loss: 0.0944\n",
      "Epoch: 16/20... Training loss: 0.0930\n",
      "Epoch: 16/20... Training loss: 0.0928\n",
      "Epoch: 16/20... Training loss: 0.0940\n",
      "Epoch: 16/20... Training loss: 0.0955\n",
      "Epoch: 16/20... Training loss: 0.0922\n",
      "Epoch: 16/20... Training loss: 0.0942\n",
      "Epoch: 16/20... Training loss: 0.0890\n",
      "Epoch: 16/20... Training loss: 0.0955\n",
      "Epoch: 16/20... Training loss: 0.0955\n",
      "Epoch: 16/20... Training loss: 0.0921\n",
      "Epoch: 16/20... Training loss: 0.0928\n",
      "Epoch: 16/20... Training loss: 0.0920\n",
      "Epoch: 16/20... Training loss: 0.0978\n",
      "Epoch: 16/20... Training loss: 0.0899\n",
      "Epoch: 16/20... Training loss: 0.0946\n",
      "Epoch: 16/20... Training loss: 0.0943\n",
      "Epoch: 16/20... Training loss: 0.0930\n",
      "Epoch: 16/20... Training loss: 0.0934\n",
      "Epoch: 16/20... Training loss: 0.0942\n",
      "Epoch: 16/20... Training loss: 0.0948\n",
      "Epoch: 16/20... Training loss: 0.0927\n",
      "Epoch: 16/20... Training loss: 0.0917\n",
      "Epoch: 16/20... Training loss: 0.0925\n",
      "Epoch: 16/20... Training loss: 0.0924\n",
      "Epoch: 16/20... Training loss: 0.0888\n",
      "Epoch: 16/20... Training loss: 0.0944\n",
      "Epoch: 16/20... Training loss: 0.0946\n",
      "Epoch: 16/20... Training loss: 0.0933\n",
      "Epoch: 16/20... Training loss: 0.0925\n",
      "Epoch: 16/20... Training loss: 0.0946\n",
      "Epoch: 16/20... Training loss: 0.0920\n",
      "Epoch: 16/20... Training loss: 0.0928\n",
      "Epoch: 16/20... Training loss: 0.0922\n",
      "Epoch: 16/20... Training loss: 0.0978\n",
      "Epoch: 16/20... Training loss: 0.0954\n",
      "Epoch: 16/20... Training loss: 0.0954\n",
      "Epoch: 16/20... Training loss: 0.0915\n",
      "Epoch: 16/20... Training loss: 0.0943\n",
      "Epoch: 16/20... Training loss: 0.0921\n",
      "Epoch: 16/20... Training loss: 0.0977\n",
      "Epoch: 16/20... Training loss: 0.0902\n",
      "Epoch: 16/20... Training loss: 0.0897\n",
      "Epoch: 16/20... Training loss: 0.0939\n",
      "Epoch: 16/20... Training loss: 0.0924\n",
      "Epoch: 16/20... Training loss: 0.0977\n",
      "Epoch: 16/20... Training loss: 0.0938\n",
      "Epoch: 16/20... Training loss: 0.0901\n",
      "Epoch: 16/20... Training loss: 0.0976\n",
      "Epoch: 16/20... Training loss: 0.0979\n",
      "Epoch: 16/20... Training loss: 0.0969\n",
      "Epoch: 16/20... Training loss: 0.0949\n",
      "Epoch: 16/20... Training loss: 0.0929\n",
      "Epoch: 16/20... Training loss: 0.0963\n",
      "Epoch: 16/20... Training loss: 0.0933\n",
      "Epoch: 16/20... Training loss: 0.0930\n",
      "Epoch: 16/20... Training loss: 0.0922\n",
      "Epoch: 16/20... Training loss: 0.0945\n",
      "Epoch: 16/20... Training loss: 0.0935\n",
      "Epoch: 16/20... Training loss: 0.0909\n",
      "Epoch: 16/20... Training loss: 0.0948\n",
      "Epoch: 16/20... Training loss: 0.0923\n",
      "Epoch: 16/20... Training loss: 0.0944\n",
      "Epoch: 16/20... Training loss: 0.0931\n",
      "Epoch: 16/20... Training loss: 0.0977\n",
      "Epoch: 16/20... Training loss: 0.0949\n",
      "Epoch: 16/20... Training loss: 0.0941\n",
      "Epoch: 16/20... Training loss: 0.0976\n",
      "Epoch: 16/20... Training loss: 0.0973\n",
      "Epoch: 16/20... Training loss: 0.0932\n",
      "Epoch: 16/20... Training loss: 0.0939\n",
      "Epoch: 16/20... Training loss: 0.0935\n",
      "Epoch: 16/20... Training loss: 0.0932\n",
      "Epoch: 16/20... Training loss: 0.0929\n",
      "Epoch: 16/20... Training loss: 0.0932\n",
      "Epoch: 16/20... Training loss: 0.0940\n",
      "Epoch: 16/20... Training loss: 0.0930\n",
      "Epoch: 16/20... Training loss: 0.0950\n",
      "Epoch: 16/20... Training loss: 0.0959\n",
      "Epoch: 16/20... Training loss: 0.0908\n",
      "Epoch: 16/20... Training loss: 0.0938\n",
      "Epoch: 16/20... Training loss: 0.0959\n",
      "Epoch: 16/20... Training loss: 0.0982\n",
      "Epoch: 16/20... Training loss: 0.0930\n",
      "Epoch: 16/20... Training loss: 0.0981\n",
      "Epoch: 16/20... Training loss: 0.0927\n",
      "Epoch: 16/20... Training loss: 0.0931\n",
      "Epoch: 16/20... Training loss: 0.0932\n",
      "Epoch: 16/20... Training loss: 0.0925\n",
      "Epoch: 16/20... Training loss: 0.0926\n",
      "Epoch: 16/20... Training loss: 0.0903\n",
      "Epoch: 16/20... Training loss: 0.0932\n",
      "Epoch: 16/20... Training loss: 0.0942\n",
      "Epoch: 16/20... Training loss: 0.0953\n",
      "Epoch: 16/20... Training loss: 0.0952\n",
      "Epoch: 16/20... Training loss: 0.0910\n",
      "Epoch: 16/20... Training loss: 0.0933\n",
      "Epoch: 16/20... Training loss: 0.0942\n",
      "Epoch: 16/20... Training loss: 0.0939\n",
      "Epoch: 16/20... Training loss: 0.0940\n",
      "Epoch: 16/20... Training loss: 0.0952\n",
      "Epoch: 16/20... Training loss: 0.0913\n",
      "Epoch: 16/20... Training loss: 0.0932\n",
      "Epoch: 16/20... Training loss: 0.0945\n",
      "Epoch: 16/20... Training loss: 0.0949\n",
      "Epoch: 16/20... Training loss: 0.0930\n",
      "Epoch: 16/20... Training loss: 0.0941\n",
      "Epoch: 16/20... Training loss: 0.0941\n",
      "Epoch: 16/20... Training loss: 0.0976\n",
      "Epoch: 16/20... Training loss: 0.0922\n",
      "Epoch: 16/20... Training loss: 0.0908\n",
      "Epoch: 16/20... Training loss: 0.0946\n",
      "Epoch: 16/20... Training loss: 0.0935\n",
      "Epoch: 16/20... Training loss: 0.0937\n",
      "Epoch: 16/20... Training loss: 0.0977\n",
      "Epoch: 16/20... Training loss: 0.0977\n",
      "Epoch: 16/20... Training loss: 0.0938\n",
      "Epoch: 16/20... Training loss: 0.0905\n",
      "Epoch: 16/20... Training loss: 0.0974\n",
      "Epoch: 16/20... Training loss: 0.0937\n",
      "Epoch: 16/20... Training loss: 0.0941\n",
      "Epoch: 16/20... Training loss: 0.0919\n",
      "Epoch: 16/20... Training loss: 0.0952\n",
      "Epoch: 16/20... Training loss: 0.0924\n",
      "Epoch: 16/20... Training loss: 0.0919\n",
      "Epoch: 16/20... Training loss: 0.0976\n",
      "Epoch: 16/20... Training loss: 0.0975\n",
      "Epoch: 16/20... Training loss: 0.0949\n",
      "Epoch: 16/20... Training loss: 0.0941\n",
      "Epoch: 16/20... Training loss: 0.0973\n",
      "Epoch: 16/20... Training loss: 0.0928\n",
      "Epoch: 16/20... Training loss: 0.0944\n",
      "Epoch: 16/20... Training loss: 0.0952\n",
      "Epoch: 16/20... Training loss: 0.0958\n",
      "Epoch: 16/20... Training loss: 0.0944\n",
      "Epoch: 16/20... Training loss: 0.0922\n",
      "Epoch: 16/20... Training loss: 0.0937\n",
      "Epoch: 16/20... Training loss: 0.0907\n",
      "Epoch: 16/20... Training loss: 0.0920\n",
      "Epoch: 16/20... Training loss: 0.0971\n",
      "Epoch: 16/20... Training loss: 0.0957\n",
      "Epoch: 16/20... Training loss: 0.0926\n",
      "Epoch: 16/20... Training loss: 0.0974\n",
      "Epoch: 16/20... Training loss: 0.0938\n",
      "Epoch: 16/20... Training loss: 0.0922\n",
      "Epoch: 16/20... Training loss: 0.0956\n",
      "Epoch: 16/20... Training loss: 0.0947\n",
      "Epoch: 16/20... Training loss: 0.0962\n",
      "Epoch: 16/20... Training loss: 0.0920\n",
      "Epoch: 16/20... Training loss: 0.0919\n",
      "Epoch: 16/20... Training loss: 0.0944\n",
      "Epoch: 16/20... Training loss: 0.0920\n",
      "Epoch: 16/20... Training loss: 0.0933\n",
      "Epoch: 16/20... Training loss: 0.0944\n",
      "Epoch: 16/20... Training loss: 0.0993\n",
      "Epoch: 16/20... Training loss: 0.0947\n",
      "Epoch: 16/20... Training loss: 0.0921\n",
      "Epoch: 16/20... Training loss: 0.0922\n",
      "Epoch: 16/20... Training loss: 0.0939\n",
      "Epoch: 16/20... Training loss: 0.0890\n",
      "Epoch: 16/20... Training loss: 0.0956\n",
      "Epoch: 16/20... Training loss: 0.0920\n",
      "Epoch: 16/20... Training loss: 0.0941\n",
      "Epoch: 16/20... Training loss: 0.0927\n",
      "Epoch: 16/20... Training loss: 0.0913\n",
      "Epoch: 16/20... Training loss: 0.0917\n",
      "Epoch: 16/20... Training loss: 0.0931\n",
      "Epoch: 16/20... Training loss: 0.0888\n",
      "Epoch: 16/20... Training loss: 0.0953\n",
      "Epoch: 16/20... Training loss: 0.0925\n",
      "Epoch: 16/20... Training loss: 0.0932\n",
      "Epoch: 16/20... Training loss: 0.0924\n",
      "Epoch: 16/20... Training loss: 0.0926\n",
      "Epoch: 16/20... Training loss: 0.0932\n",
      "Epoch: 16/20... Training loss: 0.0920\n",
      "Epoch: 16/20... Training loss: 0.0948\n",
      "Epoch: 16/20... Training loss: 0.0960\n",
      "Epoch: 16/20... Training loss: 0.0948\n",
      "Epoch: 16/20... Training loss: 0.0925\n",
      "Epoch: 16/20... Training loss: 0.0929\n",
      "Epoch: 16/20... Training loss: 0.0907\n",
      "Epoch: 16/20... Training loss: 0.0951\n",
      "Epoch: 16/20... Training loss: 0.0943\n",
      "Epoch: 16/20... Training loss: 0.0933\n",
      "Epoch: 16/20... Training loss: 0.0933\n",
      "Epoch: 16/20... Training loss: 0.0926\n",
      "Epoch: 16/20... Training loss: 0.0922\n",
      "Epoch: 16/20... Training loss: 0.0971\n",
      "Epoch: 16/20... Training loss: 0.0954\n",
      "Epoch: 16/20... Training loss: 0.0943\n",
      "Epoch: 16/20... Training loss: 0.0951\n",
      "Epoch: 16/20... Training loss: 0.0946\n",
      "Epoch: 16/20... Training loss: 0.0967\n",
      "Epoch: 16/20... Training loss: 0.0892\n",
      "Epoch: 16/20... Training loss: 0.0953\n",
      "Epoch: 16/20... Training loss: 0.0944\n",
      "Epoch: 16/20... Training loss: 0.0919\n",
      "Epoch: 16/20... Training loss: 0.0906\n",
      "Epoch: 16/20... Training loss: 0.0930\n",
      "Epoch: 16/20... Training loss: 0.0933\n",
      "Epoch: 16/20... Training loss: 0.0944\n",
      "Epoch: 16/20... Training loss: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/20... Training loss: 0.0916\n",
      "Epoch: 16/20... Training loss: 0.0932\n",
      "Epoch: 16/20... Training loss: 0.0973\n",
      "Epoch: 16/20... Training loss: 0.0932\n",
      "Epoch: 16/20... Training loss: 0.0936\n",
      "Epoch: 16/20... Training loss: 0.0948\n",
      "Epoch: 16/20... Training loss: 0.0944\n",
      "Epoch: 16/20... Training loss: 0.0931\n",
      "Epoch: 16/20... Training loss: 0.0922\n",
      "Epoch: 16/20... Training loss: 0.0965\n",
      "Epoch: 16/20... Training loss: 0.0951\n",
      "Epoch: 16/20... Training loss: 0.0974\n",
      "Epoch: 16/20... Training loss: 0.0911\n",
      "Epoch: 16/20... Training loss: 0.0906\n",
      "Epoch: 16/20... Training loss: 0.0945\n",
      "Epoch: 16/20... Training loss: 0.0952\n",
      "Epoch: 16/20... Training loss: 0.0941\n",
      "Epoch: 16/20... Training loss: 0.0986\n",
      "Epoch: 16/20... Training loss: 0.0921\n",
      "Epoch: 16/20... Training loss: 0.0928\n",
      "Epoch: 16/20... Training loss: 0.0933\n",
      "Epoch: 16/20... Training loss: 0.0926\n",
      "Epoch: 16/20... Training loss: 0.0937\n",
      "Epoch: 16/20... Training loss: 0.0944\n",
      "Epoch: 16/20... Training loss: 0.0943\n",
      "Epoch: 16/20... Training loss: 0.0926\n",
      "Epoch: 16/20... Training loss: 0.0945\n",
      "Epoch: 16/20... Training loss: 0.0933\n",
      "Epoch: 16/20... Training loss: 0.0951\n",
      "Epoch: 16/20... Training loss: 0.0938\n",
      "Epoch: 16/20... Training loss: 0.0927\n",
      "Epoch: 16/20... Training loss: 0.0923\n",
      "Epoch: 16/20... Training loss: 0.0927\n",
      "Epoch: 16/20... Training loss: 0.0953\n",
      "Epoch: 16/20... Training loss: 0.0943\n",
      "Epoch: 16/20... Training loss: 0.0951\n",
      "Epoch: 16/20... Training loss: 0.0928\n",
      "Epoch: 16/20... Training loss: 0.0947\n",
      "Epoch: 16/20... Training loss: 0.0929\n",
      "Epoch: 16/20... Training loss: 0.0936\n",
      "Epoch: 16/20... Training loss: 0.0947\n",
      "Epoch: 16/20... Training loss: 0.0904\n",
      "Epoch: 16/20... Training loss: 0.0957\n",
      "Epoch: 16/20... Training loss: 0.0941\n",
      "Epoch: 16/20... Training loss: 0.0935\n",
      "Epoch: 16/20... Training loss: 0.0930\n",
      "Epoch: 16/20... Training loss: 0.0974\n",
      "Epoch: 16/20... Training loss: 0.0963\n",
      "Epoch: 16/20... Training loss: 0.0906\n",
      "Epoch: 16/20... Training loss: 0.0908\n",
      "Epoch: 16/20... Training loss: 0.0942\n",
      "Epoch: 16/20... Training loss: 0.0944\n",
      "Epoch: 16/20... Training loss: 0.0908\n",
      "Epoch: 16/20... Training loss: 0.0945\n",
      "Epoch: 16/20... Training loss: 0.0940\n",
      "Epoch: 16/20... Training loss: 0.0958\n",
      "Epoch: 16/20... Training loss: 0.0927\n",
      "Epoch: 16/20... Training loss: 0.0895\n",
      "Epoch: 16/20... Training loss: 0.0939\n",
      "Epoch: 16/20... Training loss: 0.0953\n",
      "Epoch: 16/20... Training loss: 0.0953\n",
      "Epoch: 16/20... Training loss: 0.0934\n",
      "Epoch: 16/20... Training loss: 0.0968\n",
      "Epoch: 16/20... Training loss: 0.0924\n",
      "Epoch: 16/20... Training loss: 0.0922\n",
      "Epoch: 16/20... Training loss: 0.0955\n",
      "Epoch: 16/20... Training loss: 0.0959\n",
      "Epoch: 16/20... Training loss: 0.0923\n",
      "Epoch: 16/20... Training loss: 0.0905\n",
      "Epoch: 16/20... Training loss: 0.0930\n",
      "Epoch: 16/20... Training loss: 0.0960\n",
      "Epoch: 16/20... Training loss: 0.0915\n",
      "Epoch: 16/20... Training loss: 0.0937\n",
      "Epoch: 16/20... Training loss: 0.0934\n",
      "Epoch: 16/20... Training loss: 0.0916\n",
      "Epoch: 16/20... Training loss: 0.0901\n",
      "Epoch: 16/20... Training loss: 0.0944\n",
      "Epoch: 16/20... Training loss: 0.0915\n",
      "Epoch: 16/20... Training loss: 0.0917\n",
      "Epoch: 16/20... Training loss: 0.0951\n",
      "Epoch: 16/20... Training loss: 0.0925\n",
      "Epoch: 16/20... Training loss: 0.0953\n",
      "Epoch: 16/20... Training loss: 0.0908\n",
      "Epoch: 16/20... Training loss: 0.0954\n",
      "Epoch: 16/20... Training loss: 0.0935\n",
      "Epoch: 16/20... Training loss: 0.0964\n",
      "Epoch: 16/20... Training loss: 0.0961\n",
      "Epoch: 16/20... Training loss: 0.0915\n",
      "Epoch: 16/20... Training loss: 0.0917\n",
      "Epoch: 16/20... Training loss: 0.0928\n",
      "Epoch: 16/20... Training loss: 0.0902\n",
      "Epoch: 16/20... Training loss: 0.0947\n",
      "Epoch: 16/20... Training loss: 0.0921\n",
      "Epoch: 16/20... Training loss: 0.0939\n",
      "Epoch: 16/20... Training loss: 0.0940\n",
      "Epoch: 16/20... Training loss: 0.0956\n",
      "Epoch: 16/20... Training loss: 0.0926\n",
      "Epoch: 16/20... Training loss: 0.0906\n",
      "Epoch: 17/20... Training loss: 0.0954\n",
      "Epoch: 17/20... Training loss: 0.0932\n",
      "Epoch: 17/20... Training loss: 0.0929\n",
      "Epoch: 17/20... Training loss: 0.0948\n",
      "Epoch: 17/20... Training loss: 0.0913\n",
      "Epoch: 17/20... Training loss: 0.0894\n",
      "Epoch: 17/20... Training loss: 0.0943\n",
      "Epoch: 17/20... Training loss: 0.0938\n",
      "Epoch: 17/20... Training loss: 0.0948\n",
      "Epoch: 17/20... Training loss: 0.0942\n",
      "Epoch: 17/20... Training loss: 0.0930\n",
      "Epoch: 17/20... Training loss: 0.0951\n",
      "Epoch: 17/20... Training loss: 0.0926\n",
      "Epoch: 17/20... Training loss: 0.0913\n",
      "Epoch: 17/20... Training loss: 0.0913\n",
      "Epoch: 17/20... Training loss: 0.0945\n",
      "Epoch: 17/20... Training loss: 0.0942\n",
      "Epoch: 17/20... Training loss: 0.0917\n",
      "Epoch: 17/20... Training loss: 0.0964\n",
      "Epoch: 17/20... Training loss: 0.0938\n",
      "Epoch: 17/20... Training loss: 0.0935\n",
      "Epoch: 17/20... Training loss: 0.0937\n",
      "Epoch: 17/20... Training loss: 0.0926\n",
      "Epoch: 17/20... Training loss: 0.0927\n",
      "Epoch: 17/20... Training loss: 0.0929\n",
      "Epoch: 17/20... Training loss: 0.0889\n",
      "Epoch: 17/20... Training loss: 0.0929\n",
      "Epoch: 17/20... Training loss: 0.0972\n",
      "Epoch: 17/20... Training loss: 0.0942\n",
      "Epoch: 17/20... Training loss: 0.0926\n",
      "Epoch: 17/20... Training loss: 0.0923\n",
      "Epoch: 17/20... Training loss: 0.0942\n",
      "Epoch: 17/20... Training loss: 0.0939\n",
      "Epoch: 17/20... Training loss: 0.0893\n",
      "Epoch: 17/20... Training loss: 0.0955\n",
      "Epoch: 17/20... Training loss: 0.0956\n",
      "Epoch: 17/20... Training loss: 0.0915\n",
      "Epoch: 17/20... Training loss: 0.0931\n",
      "Epoch: 17/20... Training loss: 0.0953\n",
      "Epoch: 17/20... Training loss: 0.0926\n",
      "Epoch: 17/20... Training loss: 0.0888\n",
      "Epoch: 17/20... Training loss: 0.0934\n",
      "Epoch: 17/20... Training loss: 0.0971\n",
      "Epoch: 17/20... Training loss: 0.0942\n",
      "Epoch: 17/20... Training loss: 0.0924\n",
      "Epoch: 17/20... Training loss: 0.0942\n",
      "Epoch: 17/20... Training loss: 0.0907\n",
      "Epoch: 17/20... Training loss: 0.0934\n",
      "Epoch: 17/20... Training loss: 0.0939\n",
      "Epoch: 17/20... Training loss: 0.0920\n",
      "Epoch: 17/20... Training loss: 0.0913\n",
      "Epoch: 17/20... Training loss: 0.0965\n",
      "Epoch: 17/20... Training loss: 0.0920\n",
      "Epoch: 17/20... Training loss: 0.0972\n",
      "Epoch: 17/20... Training loss: 0.0936\n",
      "Epoch: 17/20... Training loss: 0.0953\n",
      "Epoch: 17/20... Training loss: 0.0940\n",
      "Epoch: 17/20... Training loss: 0.0929\n",
      "Epoch: 17/20... Training loss: 0.0942\n",
      "Epoch: 17/20... Training loss: 0.0931\n",
      "Epoch: 17/20... Training loss: 0.0933\n",
      "Epoch: 17/20... Training loss: 0.0961\n",
      "Epoch: 17/20... Training loss: 0.0929\n",
      "Epoch: 17/20... Training loss: 0.0987\n",
      "Epoch: 17/20... Training loss: 0.0961\n",
      "Epoch: 17/20... Training loss: 0.0910\n",
      "Epoch: 17/20... Training loss: 0.0959\n",
      "Epoch: 17/20... Training loss: 0.0958\n",
      "Epoch: 17/20... Training loss: 0.0942\n",
      "Epoch: 17/20... Training loss: 0.0927\n",
      "Epoch: 17/20... Training loss: 0.0927\n",
      "Epoch: 17/20... Training loss: 0.0963\n",
      "Epoch: 17/20... Training loss: 0.0936\n",
      "Epoch: 17/20... Training loss: 0.0921\n",
      "Epoch: 17/20... Training loss: 0.0941\n",
      "Epoch: 17/20... Training loss: 0.0940\n",
      "Epoch: 17/20... Training loss: 0.0924\n",
      "Epoch: 17/20... Training loss: 0.0922\n",
      "Epoch: 17/20... Training loss: 0.0954\n",
      "Epoch: 17/20... Training loss: 0.0979\n",
      "Epoch: 17/20... Training loss: 0.0926\n",
      "Epoch: 17/20... Training loss: 0.0905\n",
      "Epoch: 17/20... Training loss: 0.0946\n",
      "Epoch: 17/20... Training loss: 0.0947\n",
      "Epoch: 17/20... Training loss: 0.0951\n",
      "Epoch: 17/20... Training loss: 0.0893\n",
      "Epoch: 17/20... Training loss: 0.0927\n",
      "Epoch: 17/20... Training loss: 0.0945\n",
      "Epoch: 17/20... Training loss: 0.0947\n",
      "Epoch: 17/20... Training loss: 0.0933\n",
      "Epoch: 17/20... Training loss: 0.0944\n",
      "Epoch: 17/20... Training loss: 0.0946\n",
      "Epoch: 17/20... Training loss: 0.0926\n",
      "Epoch: 17/20... Training loss: 0.0908\n",
      "Epoch: 17/20... Training loss: 0.0962\n",
      "Epoch: 17/20... Training loss: 0.0971\n",
      "Epoch: 17/20... Training loss: 0.0974\n",
      "Epoch: 17/20... Training loss: 0.0930\n",
      "Epoch: 17/20... Training loss: 0.0972\n",
      "Epoch: 17/20... Training loss: 0.0897\n",
      "Epoch: 17/20... Training loss: 0.0901\n",
      "Epoch: 17/20... Training loss: 0.0908\n",
      "Epoch: 17/20... Training loss: 0.0943\n",
      "Epoch: 17/20... Training loss: 0.0903\n",
      "Epoch: 17/20... Training loss: 0.0920\n",
      "Epoch: 17/20... Training loss: 0.0888\n",
      "Epoch: 17/20... Training loss: 0.0930\n",
      "Epoch: 17/20... Training loss: 0.0935\n",
      "Epoch: 17/20... Training loss: 0.0921\n",
      "Epoch: 17/20... Training loss: 0.0916\n",
      "Epoch: 17/20... Training loss: 0.0963\n",
      "Epoch: 17/20... Training loss: 0.0977\n",
      "Epoch: 17/20... Training loss: 0.0939\n",
      "Epoch: 17/20... Training loss: 0.0954\n",
      "Epoch: 17/20... Training loss: 0.0928\n",
      "Epoch: 17/20... Training loss: 0.0930\n",
      "Epoch: 17/20... Training loss: 0.0946\n",
      "Epoch: 17/20... Training loss: 0.0933\n",
      "Epoch: 17/20... Training loss: 0.0976\n",
      "Epoch: 17/20... Training loss: 0.0970\n",
      "Epoch: 17/20... Training loss: 0.0915\n",
      "Epoch: 17/20... Training loss: 0.0962\n",
      "Epoch: 17/20... Training loss: 0.0927\n",
      "Epoch: 17/20... Training loss: 0.0936\n",
      "Epoch: 17/20... Training loss: 0.0919\n",
      "Epoch: 17/20... Training loss: 0.0929\n",
      "Epoch: 17/20... Training loss: 0.0935\n",
      "Epoch: 17/20... Training loss: 0.0902\n",
      "Epoch: 17/20... Training loss: 0.0975\n",
      "Epoch: 17/20... Training loss: 0.0934\n",
      "Epoch: 17/20... Training loss: 0.0971\n",
      "Epoch: 17/20... Training loss: 0.0934\n",
      "Epoch: 17/20... Training loss: 0.0953\n",
      "Epoch: 17/20... Training loss: 0.0930\n",
      "Epoch: 17/20... Training loss: 0.0926\n",
      "Epoch: 17/20... Training loss: 0.0960\n",
      "Epoch: 17/20... Training loss: 0.0923\n",
      "Epoch: 17/20... Training loss: 0.0927\n",
      "Epoch: 17/20... Training loss: 0.0926\n",
      "Epoch: 17/20... Training loss: 0.0933\n",
      "Epoch: 17/20... Training loss: 0.0952\n",
      "Epoch: 17/20... Training loss: 0.0932\n",
      "Epoch: 17/20... Training loss: 0.0948\n",
      "Epoch: 17/20... Training loss: 0.0935\n",
      "Epoch: 17/20... Training loss: 0.0947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/20... Training loss: 0.0956\n",
      "Epoch: 17/20... Training loss: 0.0953\n",
      "Epoch: 17/20... Training loss: 0.0927\n",
      "Epoch: 17/20... Training loss: 0.0935\n",
      "Epoch: 17/20... Training loss: 0.0900\n",
      "Epoch: 17/20... Training loss: 0.0942\n",
      "Epoch: 17/20... Training loss: 0.0939\n",
      "Epoch: 17/20... Training loss: 0.0944\n",
      "Epoch: 17/20... Training loss: 0.0946\n",
      "Epoch: 17/20... Training loss: 0.0923\n",
      "Epoch: 17/20... Training loss: 0.0916\n",
      "Epoch: 17/20... Training loss: 0.0922\n",
      "Epoch: 17/20... Training loss: 0.0962\n",
      "Epoch: 17/20... Training loss: 0.0927\n",
      "Epoch: 17/20... Training loss: 0.0946\n",
      "Epoch: 17/20... Training loss: 0.0964\n",
      "Epoch: 17/20... Training loss: 0.0940\n",
      "Epoch: 17/20... Training loss: 0.0942\n",
      "Epoch: 17/20... Training loss: 0.0970\n",
      "Epoch: 17/20... Training loss: 0.0929\n",
      "Epoch: 17/20... Training loss: 0.0916\n",
      "Epoch: 17/20... Training loss: 0.0961\n",
      "Epoch: 17/20... Training loss: 0.0948\n",
      "Epoch: 17/20... Training loss: 0.0971\n",
      "Epoch: 17/20... Training loss: 0.0988\n",
      "Epoch: 17/20... Training loss: 0.0935\n",
      "Epoch: 17/20... Training loss: 0.0969\n",
      "Epoch: 17/20... Training loss: 0.0911\n",
      "Epoch: 17/20... Training loss: 0.0911\n",
      "Epoch: 17/20... Training loss: 0.0945\n",
      "Epoch: 17/20... Training loss: 0.0962\n",
      "Epoch: 17/20... Training loss: 0.0914\n",
      "Epoch: 17/20... Training loss: 0.0951\n",
      "Epoch: 17/20... Training loss: 0.0952\n",
      "Epoch: 17/20... Training loss: 0.0932\n",
      "Epoch: 17/20... Training loss: 0.0955\n",
      "Epoch: 17/20... Training loss: 0.0904\n",
      "Epoch: 17/20... Training loss: 0.0925\n",
      "Epoch: 17/20... Training loss: 0.0964\n",
      "Epoch: 17/20... Training loss: 0.0974\n",
      "Epoch: 17/20... Training loss: 0.0965\n",
      "Epoch: 17/20... Training loss: 0.0967\n",
      "Epoch: 17/20... Training loss: 0.0911\n",
      "Epoch: 17/20... Training loss: 0.0912\n",
      "Epoch: 17/20... Training loss: 0.0912\n",
      "Epoch: 17/20... Training loss: 0.0955\n",
      "Epoch: 17/20... Training loss: 0.0902\n",
      "Epoch: 17/20... Training loss: 0.0940\n",
      "Epoch: 17/20... Training loss: 0.0937\n",
      "Epoch: 17/20... Training loss: 0.0924\n",
      "Epoch: 17/20... Training loss: 0.0944\n",
      "Epoch: 17/20... Training loss: 0.0930\n",
      "Epoch: 17/20... Training loss: 0.0931\n",
      "Epoch: 17/20... Training loss: 0.0956\n",
      "Epoch: 17/20... Training loss: 0.0954\n",
      "Epoch: 17/20... Training loss: 0.0916\n",
      "Epoch: 17/20... Training loss: 0.0948\n",
      "Epoch: 17/20... Training loss: 0.0961\n",
      "Epoch: 17/20... Training loss: 0.0938\n",
      "Epoch: 17/20... Training loss: 0.0949\n",
      "Epoch: 17/20... Training loss: 0.0893\n",
      "Epoch: 17/20... Training loss: 0.0956\n",
      "Epoch: 17/20... Training loss: 0.0926\n",
      "Epoch: 17/20... Training loss: 0.0928\n",
      "Epoch: 17/20... Training loss: 0.0936\n",
      "Epoch: 17/20... Training loss: 0.0932\n",
      "Epoch: 17/20... Training loss: 0.0921\n",
      "Epoch: 17/20... Training loss: 0.0924\n",
      "Epoch: 17/20... Training loss: 0.0944\n",
      "Epoch: 17/20... Training loss: 0.0943\n",
      "Epoch: 17/20... Training loss: 0.0913\n",
      "Epoch: 17/20... Training loss: 0.0951\n",
      "Epoch: 17/20... Training loss: 0.0942\n",
      "Epoch: 17/20... Training loss: 0.0927\n",
      "Epoch: 17/20... Training loss: 0.0956\n",
      "Epoch: 17/20... Training loss: 0.0962\n",
      "Epoch: 17/20... Training loss: 0.0956\n",
      "Epoch: 17/20... Training loss: 0.0899\n",
      "Epoch: 17/20... Training loss: 0.0924\n",
      "Epoch: 17/20... Training loss: 0.0930\n",
      "Epoch: 17/20... Training loss: 0.0923\n",
      "Epoch: 17/20... Training loss: 0.0960\n",
      "Epoch: 17/20... Training loss: 0.0932\n",
      "Epoch: 17/20... Training loss: 0.0944\n",
      "Epoch: 17/20... Training loss: 0.0914\n",
      "Epoch: 17/20... Training loss: 0.0945\n",
      "Epoch: 17/20... Training loss: 0.0913\n",
      "Epoch: 17/20... Training loss: 0.0940\n",
      "Epoch: 17/20... Training loss: 0.0924\n",
      "Epoch: 17/20... Training loss: 0.0959\n",
      "Epoch: 17/20... Training loss: 0.0918\n",
      "Epoch: 17/20... Training loss: 0.0961\n",
      "Epoch: 17/20... Training loss: 0.0903\n",
      "Epoch: 17/20... Training loss: 0.0906\n",
      "Epoch: 17/20... Training loss: 0.0976\n",
      "Epoch: 17/20... Training loss: 0.0935\n",
      "Epoch: 17/20... Training loss: 0.0974\n",
      "Epoch: 17/20... Training loss: 0.0973\n",
      "Epoch: 17/20... Training loss: 0.0915\n",
      "Epoch: 17/20... Training loss: 0.0921\n",
      "Epoch: 17/20... Training loss: 0.0935\n",
      "Epoch: 17/20... Training loss: 0.0906\n",
      "Epoch: 17/20... Training loss: 0.0953\n",
      "Epoch: 17/20... Training loss: 0.0927\n",
      "Epoch: 17/20... Training loss: 0.0936\n",
      "Epoch: 17/20... Training loss: 0.0938\n",
      "Epoch: 17/20... Training loss: 0.0929\n",
      "Epoch: 17/20... Training loss: 0.0942\n",
      "Epoch: 17/20... Training loss: 0.0917\n",
      "Epoch: 17/20... Training loss: 0.0942\n",
      "Epoch: 17/20... Training loss: 0.0956\n",
      "Epoch: 17/20... Training loss: 0.0902\n",
      "Epoch: 17/20... Training loss: 0.0945\n",
      "Epoch: 17/20... Training loss: 0.0959\n",
      "Epoch: 17/20... Training loss: 0.0936\n",
      "Epoch: 17/20... Training loss: 0.0957\n",
      "Epoch: 17/20... Training loss: 0.0946\n",
      "Epoch: 17/20... Training loss: 0.0949\n",
      "Epoch: 17/20... Training loss: 0.0929\n",
      "Epoch: 17/20... Training loss: 0.0939\n",
      "Epoch: 17/20... Training loss: 0.0937\n",
      "Epoch: 17/20... Training loss: 0.0922\n",
      "Epoch: 17/20... Training loss: 0.0919\n",
      "Epoch: 17/20... Training loss: 0.0912\n",
      "Epoch: 17/20... Training loss: 0.0945\n",
      "Epoch: 17/20... Training loss: 0.0945\n",
      "Epoch: 17/20... Training loss: 0.0899\n",
      "Epoch: 17/20... Training loss: 0.0969\n",
      "Epoch: 17/20... Training loss: 0.0943\n",
      "Epoch: 17/20... Training loss: 0.0947\n",
      "Epoch: 17/20... Training loss: 0.0939\n",
      "Epoch: 17/20... Training loss: 0.0949\n",
      "Epoch: 17/20... Training loss: 0.0963\n",
      "Epoch: 17/20... Training loss: 0.0950\n",
      "Epoch: 17/20... Training loss: 0.0926\n",
      "Epoch: 17/20... Training loss: 0.0975\n",
      "Epoch: 17/20... Training loss: 0.0901\n",
      "Epoch: 17/20... Training loss: 0.0889\n",
      "Epoch: 17/20... Training loss: 0.0923\n",
      "Epoch: 17/20... Training loss: 0.0917\n",
      "Epoch: 17/20... Training loss: 0.0932\n",
      "Epoch: 17/20... Training loss: 0.0913\n",
      "Epoch: 17/20... Training loss: 0.0893\n",
      "Epoch: 17/20... Training loss: 0.0929\n",
      "Epoch: 17/20... Training loss: 0.0938\n",
      "Epoch: 17/20... Training loss: 0.0944\n",
      "Epoch: 17/20... Training loss: 0.0910\n",
      "Epoch: 17/20... Training loss: 0.0921\n",
      "Epoch: 17/20... Training loss: 0.0912\n",
      "Epoch: 17/20... Training loss: 0.0934\n",
      "Epoch: 17/20... Training loss: 0.0925\n",
      "Epoch: 17/20... Training loss: 0.0965\n",
      "Epoch: 17/20... Training loss: 0.0938\n",
      "Epoch: 17/20... Training loss: 0.0921\n",
      "Epoch: 17/20... Training loss: 0.0934\n",
      "Epoch: 18/20... Training loss: 0.0946\n",
      "Epoch: 18/20... Training loss: 0.0929\n",
      "Epoch: 18/20... Training loss: 0.0928\n",
      "Epoch: 18/20... Training loss: 0.0956\n",
      "Epoch: 18/20... Training loss: 0.0939\n",
      "Epoch: 18/20... Training loss: 0.0948\n",
      "Epoch: 18/20... Training loss: 0.0940\n",
      "Epoch: 18/20... Training loss: 0.0928\n",
      "Epoch: 18/20... Training loss: 0.0890\n",
      "Epoch: 18/20... Training loss: 0.0920\n",
      "Epoch: 18/20... Training loss: 0.0897\n",
      "Epoch: 18/20... Training loss: 0.0941\n",
      "Epoch: 18/20... Training loss: 0.0917\n",
      "Epoch: 18/20... Training loss: 0.0950\n",
      "Epoch: 18/20... Training loss: 0.0933\n",
      "Epoch: 18/20... Training loss: 0.0943\n",
      "Epoch: 18/20... Training loss: 0.0936\n",
      "Epoch: 18/20... Training loss: 0.0940\n",
      "Epoch: 18/20... Training loss: 0.0935\n",
      "Epoch: 18/20... Training loss: 0.0950\n",
      "Epoch: 18/20... Training loss: 0.0960\n",
      "Epoch: 18/20... Training loss: 0.0958\n",
      "Epoch: 18/20... Training loss: 0.0941\n",
      "Epoch: 18/20... Training loss: 0.0933\n",
      "Epoch: 18/20... Training loss: 0.0952\n",
      "Epoch: 18/20... Training loss: 0.0937\n",
      "Epoch: 18/20... Training loss: 0.0964\n",
      "Epoch: 18/20... Training loss: 0.0937\n",
      "Epoch: 18/20... Training loss: 0.0939\n",
      "Epoch: 18/20... Training loss: 0.0950\n",
      "Epoch: 18/20... Training loss: 0.0924\n",
      "Epoch: 18/20... Training loss: 0.0913\n",
      "Epoch: 18/20... Training loss: 0.0948\n",
      "Epoch: 18/20... Training loss: 0.0908\n",
      "Epoch: 18/20... Training loss: 0.0935\n",
      "Epoch: 18/20... Training loss: 0.0919\n",
      "Epoch: 18/20... Training loss: 0.0940\n",
      "Epoch: 18/20... Training loss: 0.0949\n",
      "Epoch: 18/20... Training loss: 0.0909\n",
      "Epoch: 18/20... Training loss: 0.0894\n",
      "Epoch: 18/20... Training loss: 0.0947\n",
      "Epoch: 18/20... Training loss: 0.0937\n",
      "Epoch: 18/20... Training loss: 0.0941\n",
      "Epoch: 18/20... Training loss: 0.0933\n",
      "Epoch: 18/20... Training loss: 0.0906\n",
      "Epoch: 18/20... Training loss: 0.0932\n",
      "Epoch: 18/20... Training loss: 0.0961\n",
      "Epoch: 18/20... Training loss: 0.0929\n",
      "Epoch: 18/20... Training loss: 0.0935\n",
      "Epoch: 18/20... Training loss: 0.0922\n",
      "Epoch: 18/20... Training loss: 0.0921\n",
      "Epoch: 18/20... Training loss: 0.0955\n",
      "Epoch: 18/20... Training loss: 0.0955\n",
      "Epoch: 18/20... Training loss: 0.0903\n",
      "Epoch: 18/20... Training loss: 0.0945\n",
      "Epoch: 18/20... Training loss: 0.0920\n",
      "Epoch: 18/20... Training loss: 0.0934\n",
      "Epoch: 18/20... Training loss: 0.0889\n",
      "Epoch: 18/20... Training loss: 0.0938\n",
      "Epoch: 18/20... Training loss: 0.0931\n",
      "Epoch: 18/20... Training loss: 0.0909\n",
      "Epoch: 18/20... Training loss: 0.0952\n",
      "Epoch: 18/20... Training loss: 0.0902\n",
      "Epoch: 18/20... Training loss: 0.0955\n",
      "Epoch: 18/20... Training loss: 0.0940\n",
      "Epoch: 18/20... Training loss: 0.0911\n",
      "Epoch: 18/20... Training loss: 0.0945\n",
      "Epoch: 18/20... Training loss: 0.0957\n",
      "Epoch: 18/20... Training loss: 0.0940\n",
      "Epoch: 18/20... Training loss: 0.0968\n",
      "Epoch: 18/20... Training loss: 0.0935\n",
      "Epoch: 18/20... Training loss: 0.0949\n",
      "Epoch: 18/20... Training loss: 0.0916\n",
      "Epoch: 18/20... Training loss: 0.0937\n",
      "Epoch: 18/20... Training loss: 0.0938\n",
      "Epoch: 18/20... Training loss: 0.0964\n",
      "Epoch: 18/20... Training loss: 0.0915\n",
      "Epoch: 18/20... Training loss: 0.0917\n",
      "Epoch: 18/20... Training loss: 0.0934\n",
      "Epoch: 18/20... Training loss: 0.0950\n",
      "Epoch: 18/20... Training loss: 0.0920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/20... Training loss: 0.0925\n",
      "Epoch: 18/20... Training loss: 0.0906\n",
      "Epoch: 18/20... Training loss: 0.0918\n",
      "Epoch: 18/20... Training loss: 0.0931\n",
      "Epoch: 18/20... Training loss: 0.0929\n",
      "Epoch: 18/20... Training loss: 0.0913\n",
      "Epoch: 18/20... Training loss: 0.0939\n",
      "Epoch: 18/20... Training loss: 0.0914\n",
      "Epoch: 18/20... Training loss: 0.0945\n",
      "Epoch: 18/20... Training loss: 0.0946\n",
      "Epoch: 18/20... Training loss: 0.0925\n",
      "Epoch: 18/20... Training loss: 0.0924\n",
      "Epoch: 18/20... Training loss: 0.0949\n",
      "Epoch: 18/20... Training loss: 0.0948\n",
      "Epoch: 18/20... Training loss: 0.0952\n",
      "Epoch: 18/20... Training loss: 0.0920\n",
      "Epoch: 18/20... Training loss: 0.0949\n",
      "Epoch: 18/20... Training loss: 0.0924\n",
      "Epoch: 18/20... Training loss: 0.0919\n",
      "Epoch: 18/20... Training loss: 0.0961\n",
      "Epoch: 18/20... Training loss: 0.0932\n",
      "Epoch: 18/20... Training loss: 0.0924\n",
      "Epoch: 18/20... Training loss: 0.0933\n",
      "Epoch: 18/20... Training loss: 0.0943\n",
      "Epoch: 18/20... Training loss: 0.0958\n",
      "Epoch: 18/20... Training loss: 0.0931\n",
      "Epoch: 18/20... Training loss: 0.0913\n",
      "Epoch: 18/20... Training loss: 0.0977\n",
      "Epoch: 18/20... Training loss: 0.0957\n",
      "Epoch: 18/20... Training loss: 0.0948\n",
      "Epoch: 18/20... Training loss: 0.0925\n",
      "Epoch: 18/20... Training loss: 0.0912\n",
      "Epoch: 18/20... Training loss: 0.0937\n",
      "Epoch: 18/20... Training loss: 0.0950\n",
      "Epoch: 18/20... Training loss: 0.0928\n",
      "Epoch: 18/20... Training loss: 0.0935\n",
      "Epoch: 18/20... Training loss: 0.0927\n",
      "Epoch: 18/20... Training loss: 0.0913\n",
      "Epoch: 18/20... Training loss: 0.0956\n",
      "Epoch: 18/20... Training loss: 0.0952\n",
      "Epoch: 18/20... Training loss: 0.0948\n",
      "Epoch: 18/20... Training loss: 0.0933\n",
      "Epoch: 18/20... Training loss: 0.0958\n",
      "Epoch: 18/20... Training loss: 0.0903\n",
      "Epoch: 18/20... Training loss: 0.0945\n",
      "Epoch: 18/20... Training loss: 0.0931\n",
      "Epoch: 18/20... Training loss: 0.0906\n",
      "Epoch: 18/20... Training loss: 0.0939\n",
      "Epoch: 18/20... Training loss: 0.0918\n",
      "Epoch: 18/20... Training loss: 0.0927\n",
      "Epoch: 18/20... Training loss: 0.0938\n",
      "Epoch: 18/20... Training loss: 0.0937\n",
      "Epoch: 18/20... Training loss: 0.0953\n",
      "Epoch: 18/20... Training loss: 0.0963\n",
      "Epoch: 18/20... Training loss: 0.0926\n",
      "Epoch: 18/20... Training loss: 0.0966\n",
      "Epoch: 18/20... Training loss: 0.0922\n",
      "Epoch: 18/20... Training loss: 0.0941\n",
      "Epoch: 18/20... Training loss: 0.0923\n",
      "Epoch: 18/20... Training loss: 0.0920\n",
      "Epoch: 18/20... Training loss: 0.0925\n",
      "Epoch: 18/20... Training loss: 0.0925\n",
      "Epoch: 18/20... Training loss: 0.0949\n",
      "Epoch: 18/20... Training loss: 0.0904\n",
      "Epoch: 18/20... Training loss: 0.0989\n",
      "Epoch: 18/20... Training loss: 0.0919\n",
      "Epoch: 18/20... Training loss: 0.0955\n",
      "Epoch: 18/20... Training loss: 0.0940\n",
      "Epoch: 18/20... Training loss: 0.0925\n",
      "Epoch: 18/20... Training loss: 0.0958\n",
      "Epoch: 18/20... Training loss: 0.0951\n",
      "Epoch: 18/20... Training loss: 0.0926\n",
      "Epoch: 18/20... Training loss: 0.0912\n",
      "Epoch: 18/20... Training loss: 0.0920\n",
      "Epoch: 18/20... Training loss: 0.0934\n",
      "Epoch: 18/20... Training loss: 0.0954\n",
      "Epoch: 18/20... Training loss: 0.0919\n",
      "Epoch: 18/20... Training loss: 0.0945\n",
      "Epoch: 18/20... Training loss: 0.0995\n",
      "Epoch: 18/20... Training loss: 0.0927\n",
      "Epoch: 18/20... Training loss: 0.0938\n",
      "Epoch: 18/20... Training loss: 0.0948\n",
      "Epoch: 18/20... Training loss: 0.0921\n",
      "Epoch: 18/20... Training loss: 0.0941\n",
      "Epoch: 18/20... Training loss: 0.0921\n",
      "Epoch: 18/20... Training loss: 0.0947\n",
      "Epoch: 18/20... Training loss: 0.0934\n",
      "Epoch: 18/20... Training loss: 0.0932\n",
      "Epoch: 18/20... Training loss: 0.0926\n",
      "Epoch: 18/20... Training loss: 0.0923\n",
      "Epoch: 18/20... Training loss: 0.0925\n",
      "Epoch: 18/20... Training loss: 0.0917\n",
      "Epoch: 18/20... Training loss: 0.0922\n",
      "Epoch: 18/20... Training loss: 0.0946\n",
      "Epoch: 18/20... Training loss: 0.0922\n",
      "Epoch: 18/20... Training loss: 0.0927\n",
      "Epoch: 18/20... Training loss: 0.0944\n",
      "Epoch: 18/20... Training loss: 0.0936\n",
      "Epoch: 18/20... Training loss: 0.0923\n",
      "Epoch: 18/20... Training loss: 0.0924\n",
      "Epoch: 18/20... Training loss: 0.0960\n",
      "Epoch: 18/20... Training loss: 0.0918\n",
      "Epoch: 18/20... Training loss: 0.0951\n",
      "Epoch: 18/20... Training loss: 0.0917\n",
      "Epoch: 18/20... Training loss: 0.0912\n",
      "Epoch: 18/20... Training loss: 0.0915\n",
      "Epoch: 18/20... Training loss: 0.0956\n",
      "Epoch: 18/20... Training loss: 0.0934\n",
      "Epoch: 18/20... Training loss: 0.0925\n",
      "Epoch: 18/20... Training loss: 0.0950\n",
      "Epoch: 18/20... Training loss: 0.0934\n",
      "Epoch: 18/20... Training loss: 0.0929\n",
      "Epoch: 18/20... Training loss: 0.0928\n",
      "Epoch: 18/20... Training loss: 0.0940\n",
      "Epoch: 18/20... Training loss: 0.0914\n",
      "Epoch: 18/20... Training loss: 0.0952\n",
      "Epoch: 18/20... Training loss: 0.0905\n",
      "Epoch: 18/20... Training loss: 0.0941\n",
      "Epoch: 18/20... Training loss: 0.0946\n",
      "Epoch: 18/20... Training loss: 0.0962\n",
      "Epoch: 18/20... Training loss: 0.0951\n",
      "Epoch: 18/20... Training loss: 0.0955\n",
      "Epoch: 18/20... Training loss: 0.0969\n",
      "Epoch: 18/20... Training loss: 0.0939\n",
      "Epoch: 18/20... Training loss: 0.0921\n",
      "Epoch: 18/20... Training loss: 0.0942\n",
      "Epoch: 18/20... Training loss: 0.0968\n",
      "Epoch: 18/20... Training loss: 0.0911\n",
      "Epoch: 18/20... Training loss: 0.0938\n",
      "Epoch: 18/20... Training loss: 0.0922\n",
      "Epoch: 18/20... Training loss: 0.0910\n",
      "Epoch: 18/20... Training loss: 0.0912\n",
      "Epoch: 18/20... Training loss: 0.0934\n",
      "Epoch: 18/20... Training loss: 0.0935\n",
      "Epoch: 18/20... Training loss: 0.0957\n",
      "Epoch: 18/20... Training loss: 0.0920\n",
      "Epoch: 18/20... Training loss: 0.0925\n",
      "Epoch: 18/20... Training loss: 0.0940\n",
      "Epoch: 18/20... Training loss: 0.0958\n",
      "Epoch: 18/20... Training loss: 0.0940\n",
      "Epoch: 18/20... Training loss: 0.0931\n",
      "Epoch: 18/20... Training loss: 0.0939\n",
      "Epoch: 18/20... Training loss: 0.0922\n",
      "Epoch: 18/20... Training loss: 0.0919\n",
      "Epoch: 18/20... Training loss: 0.0927\n",
      "Epoch: 18/20... Training loss: 0.0910\n",
      "Epoch: 18/20... Training loss: 0.0935\n",
      "Epoch: 18/20... Training loss: 0.0939\n",
      "Epoch: 18/20... Training loss: 0.0934\n",
      "Epoch: 18/20... Training loss: 0.0936\n",
      "Epoch: 18/20... Training loss: 0.0927\n",
      "Epoch: 18/20... Training loss: 0.0927\n",
      "Epoch: 18/20... Training loss: 0.0941\n",
      "Epoch: 18/20... Training loss: 0.0948\n",
      "Epoch: 18/20... Training loss: 0.0925\n",
      "Epoch: 18/20... Training loss: 0.0946\n",
      "Epoch: 18/20... Training loss: 0.0923\n",
      "Epoch: 18/20... Training loss: 0.0944\n",
      "Epoch: 18/20... Training loss: 0.0945\n",
      "Epoch: 18/20... Training loss: 0.0925\n",
      "Epoch: 18/20... Training loss: 0.0952\n",
      "Epoch: 18/20... Training loss: 0.0895\n",
      "Epoch: 18/20... Training loss: 0.0893\n",
      "Epoch: 18/20... Training loss: 0.0946\n",
      "Epoch: 18/20... Training loss: 0.0938\n",
      "Epoch: 18/20... Training loss: 0.0956\n",
      "Epoch: 18/20... Training loss: 0.0937\n",
      "Epoch: 18/20... Training loss: 0.0932\n",
      "Epoch: 18/20... Training loss: 0.0926\n",
      "Epoch: 18/20... Training loss: 0.0919\n",
      "Epoch: 18/20... Training loss: 0.0952\n",
      "Epoch: 18/20... Training loss: 0.0900\n",
      "Epoch: 18/20... Training loss: 0.0890\n",
      "Epoch: 18/20... Training loss: 0.0942\n",
      "Epoch: 18/20... Training loss: 0.0972\n",
      "Epoch: 18/20... Training loss: 0.0958\n",
      "Epoch: 18/20... Training loss: 0.0933\n",
      "Epoch: 18/20... Training loss: 0.0901\n",
      "Epoch: 18/20... Training loss: 0.0941\n",
      "Epoch: 18/20... Training loss: 0.0937\n",
      "Epoch: 18/20... Training loss: 0.0986\n",
      "Epoch: 18/20... Training loss: 0.0902\n",
      "Epoch: 18/20... Training loss: 0.0893\n",
      "Epoch: 18/20... Training loss: 0.0967\n",
      "Epoch: 18/20... Training loss: 0.0955\n",
      "Epoch: 18/20... Training loss: 0.0972\n",
      "Epoch: 18/20... Training loss: 0.0940\n",
      "Epoch: 18/20... Training loss: 0.0941\n",
      "Epoch: 18/20... Training loss: 0.0948\n",
      "Epoch: 18/20... Training loss: 0.0911\n",
      "Epoch: 18/20... Training loss: 0.0938\n",
      "Epoch: 18/20... Training loss: 0.0942\n",
      "Epoch: 18/20... Training loss: 0.0950\n",
      "Epoch: 18/20... Training loss: 0.0938\n",
      "Epoch: 18/20... Training loss: 0.0979\n",
      "Epoch: 18/20... Training loss: 0.0954\n",
      "Epoch: 18/20... Training loss: 0.0951\n",
      "Epoch: 18/20... Training loss: 0.0950\n",
      "Epoch: 18/20... Training loss: 0.0952\n",
      "Epoch: 18/20... Training loss: 0.0924\n",
      "Epoch: 18/20... Training loss: 0.0934\n",
      "Epoch: 18/20... Training loss: 0.0956\n",
      "Epoch: 18/20... Training loss: 0.0925\n",
      "Epoch: 18/20... Training loss: 0.0965\n",
      "Epoch: 18/20... Training loss: 0.0965\n",
      "Epoch: 18/20... Training loss: 0.0952\n",
      "Epoch: 18/20... Training loss: 0.0928\n",
      "Epoch: 18/20... Training loss: 0.0920\n",
      "Epoch: 18/20... Training loss: 0.0953\n",
      "Epoch: 18/20... Training loss: 0.0932\n",
      "Epoch: 18/20... Training loss: 0.0927\n",
      "Epoch: 18/20... Training loss: 0.0952\n",
      "Epoch: 18/20... Training loss: 0.0949\n",
      "Epoch: 18/20... Training loss: 0.0940\n",
      "Epoch: 18/20... Training loss: 0.0939\n",
      "Epoch: 18/20... Training loss: 0.0960\n",
      "Epoch: 18/20... Training loss: 0.0963\n",
      "Epoch: 18/20... Training loss: 0.0943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/20... Training loss: 0.0917\n",
      "Epoch: 19/20... Training loss: 0.0930\n",
      "Epoch: 19/20... Training loss: 0.0929\n",
      "Epoch: 19/20... Training loss: 0.0940\n",
      "Epoch: 19/20... Training loss: 0.0955\n",
      "Epoch: 19/20... Training loss: 0.0963\n",
      "Epoch: 19/20... Training loss: 0.0924\n",
      "Epoch: 19/20... Training loss: 0.0953\n",
      "Epoch: 19/20... Training loss: 0.0904\n",
      "Epoch: 19/20... Training loss: 0.0969\n",
      "Epoch: 19/20... Training loss: 0.0928\n",
      "Epoch: 19/20... Training loss: 0.0941\n",
      "Epoch: 19/20... Training loss: 0.0933\n",
      "Epoch: 19/20... Training loss: 0.0937\n",
      "Epoch: 19/20... Training loss: 0.0921\n",
      "Epoch: 19/20... Training loss: 0.0909\n",
      "Epoch: 19/20... Training loss: 0.0913\n",
      "Epoch: 19/20... Training loss: 0.0953\n",
      "Epoch: 19/20... Training loss: 0.0915\n",
      "Epoch: 19/20... Training loss: 0.0914\n",
      "Epoch: 19/20... Training loss: 0.0933\n",
      "Epoch: 19/20... Training loss: 0.0944\n",
      "Epoch: 19/20... Training loss: 0.0939\n",
      "Epoch: 19/20... Training loss: 0.0933\n",
      "Epoch: 19/20... Training loss: 0.0916\n",
      "Epoch: 19/20... Training loss: 0.0958\n",
      "Epoch: 19/20... Training loss: 0.0944\n",
      "Epoch: 19/20... Training loss: 0.0944\n",
      "Epoch: 19/20... Training loss: 0.0894\n",
      "Epoch: 19/20... Training loss: 0.0907\n",
      "Epoch: 19/20... Training loss: 0.0930\n",
      "Epoch: 19/20... Training loss: 0.0942\n",
      "Epoch: 19/20... Training loss: 0.0948\n",
      "Epoch: 19/20... Training loss: 0.0973\n",
      "Epoch: 19/20... Training loss: 0.0926\n",
      "Epoch: 19/20... Training loss: 0.0922\n",
      "Epoch: 19/20... Training loss: 0.0945\n",
      "Epoch: 19/20... Training loss: 0.0926\n",
      "Epoch: 19/20... Training loss: 0.0903\n",
      "Epoch: 19/20... Training loss: 0.0916\n",
      "Epoch: 19/20... Training loss: 0.0980\n",
      "Epoch: 19/20... Training loss: 0.0910\n",
      "Epoch: 19/20... Training loss: 0.0938\n",
      "Epoch: 19/20... Training loss: 0.0937\n",
      "Epoch: 19/20... Training loss: 0.0922\n",
      "Epoch: 19/20... Training loss: 0.0932\n",
      "Epoch: 19/20... Training loss: 0.0936\n",
      "Epoch: 19/20... Training loss: 0.0931\n",
      "Epoch: 19/20... Training loss: 0.0956\n",
      "Epoch: 19/20... Training loss: 0.0955\n",
      "Epoch: 19/20... Training loss: 0.0925\n",
      "Epoch: 19/20... Training loss: 0.0929\n",
      "Epoch: 19/20... Training loss: 0.0968\n",
      "Epoch: 19/20... Training loss: 0.0905\n",
      "Epoch: 19/20... Training loss: 0.0930\n",
      "Epoch: 19/20... Training loss: 0.0951\n",
      "Epoch: 19/20... Training loss: 0.0931\n",
      "Epoch: 19/20... Training loss: 0.0954\n",
      "Epoch: 19/20... Training loss: 0.0912\n",
      "Epoch: 19/20... Training loss: 0.0924\n",
      "Epoch: 19/20... Training loss: 0.0910\n",
      "Epoch: 19/20... Training loss: 0.0960\n",
      "Epoch: 19/20... Training loss: 0.0936\n",
      "Epoch: 19/20... Training loss: 0.0919\n",
      "Epoch: 19/20... Training loss: 0.0946\n",
      "Epoch: 19/20... Training loss: 0.0954\n",
      "Epoch: 19/20... Training loss: 0.0937\n",
      "Epoch: 19/20... Training loss: 0.0953\n",
      "Epoch: 19/20... Training loss: 0.0936\n",
      "Epoch: 19/20... Training loss: 0.0949\n",
      "Epoch: 19/20... Training loss: 0.0945\n",
      "Epoch: 19/20... Training loss: 0.0933\n",
      "Epoch: 19/20... Training loss: 0.0937\n",
      "Epoch: 19/20... Training loss: 0.0950\n",
      "Epoch: 19/20... Training loss: 0.0909\n",
      "Epoch: 19/20... Training loss: 0.0949\n",
      "Epoch: 19/20... Training loss: 0.0914\n",
      "Epoch: 19/20... Training loss: 0.0946\n",
      "Epoch: 19/20... Training loss: 0.0898\n",
      "Epoch: 19/20... Training loss: 0.0917\n",
      "Epoch: 19/20... Training loss: 0.0898\n",
      "Epoch: 19/20... Training loss: 0.0960\n",
      "Epoch: 19/20... Training loss: 0.0908\n",
      "Epoch: 19/20... Training loss: 0.0926\n",
      "Epoch: 19/20... Training loss: 0.0955\n",
      "Epoch: 19/20... Training loss: 0.0920\n",
      "Epoch: 19/20... Training loss: 0.0958\n",
      "Epoch: 19/20... Training loss: 0.0955\n",
      "Epoch: 19/20... Training loss: 0.0944\n",
      "Epoch: 19/20... Training loss: 0.0912\n",
      "Epoch: 19/20... Training loss: 0.0917\n",
      "Epoch: 19/20... Training loss: 0.0932\n",
      "Epoch: 19/20... Training loss: 0.0927\n",
      "Epoch: 19/20... Training loss: 0.0969\n",
      "Epoch: 19/20... Training loss: 0.0957\n",
      "Epoch: 19/20... Training loss: 0.0913\n",
      "Epoch: 19/20... Training loss: 0.0924\n",
      "Epoch: 19/20... Training loss: 0.0913\n",
      "Epoch: 19/20... Training loss: 0.0947\n",
      "Epoch: 19/20... Training loss: 0.0923\n",
      "Epoch: 19/20... Training loss: 0.0935\n",
      "Epoch: 19/20... Training loss: 0.0939\n",
      "Epoch: 19/20... Training loss: 0.0951\n",
      "Epoch: 19/20... Training loss: 0.0937\n",
      "Epoch: 19/20... Training loss: 0.0952\n",
      "Epoch: 19/20... Training loss: 0.0947\n",
      "Epoch: 19/20... Training loss: 0.0909\n",
      "Epoch: 19/20... Training loss: 0.0930\n",
      "Epoch: 19/20... Training loss: 0.0976\n",
      "Epoch: 19/20... Training loss: 0.0922\n",
      "Epoch: 19/20... Training loss: 0.0955\n",
      "Epoch: 19/20... Training loss: 0.0936\n",
      "Epoch: 19/20... Training loss: 0.0953\n",
      "Epoch: 19/20... Training loss: 0.0965\n",
      "Epoch: 19/20... Training loss: 0.0937\n",
      "Epoch: 19/20... Training loss: 0.0933\n",
      "Epoch: 19/20... Training loss: 0.0904\n",
      "Epoch: 19/20... Training loss: 0.0965\n",
      "Epoch: 19/20... Training loss: 0.0925\n",
      "Epoch: 19/20... Training loss: 0.0946\n",
      "Epoch: 19/20... Training loss: 0.0930\n",
      "Epoch: 19/20... Training loss: 0.0928\n",
      "Epoch: 19/20... Training loss: 0.0934\n",
      "Epoch: 19/20... Training loss: 0.0913\n",
      "Epoch: 19/20... Training loss: 0.0945\n",
      "Epoch: 19/20... Training loss: 0.0893\n",
      "Epoch: 19/20... Training loss: 0.0952\n",
      "Epoch: 19/20... Training loss: 0.0943\n",
      "Epoch: 19/20... Training loss: 0.0946\n",
      "Epoch: 19/20... Training loss: 0.0918\n",
      "Epoch: 19/20... Training loss: 0.0934\n",
      "Epoch: 19/20... Training loss: 0.0932\n",
      "Epoch: 19/20... Training loss: 0.0927\n",
      "Epoch: 19/20... Training loss: 0.0920\n",
      "Epoch: 19/20... Training loss: 0.0964\n",
      "Epoch: 19/20... Training loss: 0.0941\n",
      "Epoch: 19/20... Training loss: 0.0923\n",
      "Epoch: 19/20... Training loss: 0.0930\n",
      "Epoch: 19/20... Training loss: 0.0943\n",
      "Epoch: 19/20... Training loss: 0.0929\n",
      "Epoch: 19/20... Training loss: 0.0945\n",
      "Epoch: 19/20... Training loss: 0.0923\n",
      "Epoch: 19/20... Training loss: 0.0942\n",
      "Epoch: 19/20... Training loss: 0.0960\n",
      "Epoch: 19/20... Training loss: 0.0971\n",
      "Epoch: 19/20... Training loss: 0.0910\n",
      "Epoch: 19/20... Training loss: 0.0938\n",
      "Epoch: 19/20... Training loss: 0.0940\n",
      "Epoch: 19/20... Training loss: 0.0975\n",
      "Epoch: 19/20... Training loss: 0.0973\n",
      "Epoch: 19/20... Training loss: 0.0928\n",
      "Epoch: 19/20... Training loss: 0.0922\n",
      "Epoch: 19/20... Training loss: 0.0958\n",
      "Epoch: 19/20... Training loss: 0.0942\n",
      "Epoch: 19/20... Training loss: 0.0931\n",
      "Epoch: 19/20... Training loss: 0.0965\n",
      "Epoch: 19/20... Training loss: 0.0938\n",
      "Epoch: 19/20... Training loss: 0.0933\n",
      "Epoch: 19/20... Training loss: 0.0958\n",
      "Epoch: 19/20... Training loss: 0.0930\n",
      "Epoch: 19/20... Training loss: 0.0942\n",
      "Epoch: 19/20... Training loss: 0.0913\n",
      "Epoch: 19/20... Training loss: 0.0921\n",
      "Epoch: 19/20... Training loss: 0.0956\n",
      "Epoch: 19/20... Training loss: 0.0897\n",
      "Epoch: 19/20... Training loss: 0.0941\n",
      "Epoch: 19/20... Training loss: 0.0917\n",
      "Epoch: 19/20... Training loss: 0.0920\n",
      "Epoch: 19/20... Training loss: 0.0919\n",
      "Epoch: 19/20... Training loss: 0.0912\n",
      "Epoch: 19/20... Training loss: 0.0924\n",
      "Epoch: 19/20... Training loss: 0.0970\n",
      "Epoch: 19/20... Training loss: 0.0925\n",
      "Epoch: 19/20... Training loss: 0.0926\n",
      "Epoch: 19/20... Training loss: 0.0911\n",
      "Epoch: 19/20... Training loss: 0.0960\n",
      "Epoch: 19/20... Training loss: 0.0987\n",
      "Epoch: 19/20... Training loss: 0.0928\n",
      "Epoch: 19/20... Training loss: 0.0968\n",
      "Epoch: 19/20... Training loss: 0.0909\n",
      "Epoch: 19/20... Training loss: 0.0931\n",
      "Epoch: 19/20... Training loss: 0.0946\n",
      "Epoch: 19/20... Training loss: 0.0929\n",
      "Epoch: 19/20... Training loss: 0.0954\n",
      "Epoch: 19/20... Training loss: 0.0911\n",
      "Epoch: 19/20... Training loss: 0.0940\n",
      "Epoch: 19/20... Training loss: 0.0929\n",
      "Epoch: 19/20... Training loss: 0.0923\n",
      "Epoch: 19/20... Training loss: 0.0937\n",
      "Epoch: 19/20... Training loss: 0.0941\n",
      "Epoch: 19/20... Training loss: 0.0941\n",
      "Epoch: 19/20... Training loss: 0.0931\n",
      "Epoch: 19/20... Training loss: 0.0937\n",
      "Epoch: 19/20... Training loss: 0.0934\n",
      "Epoch: 19/20... Training loss: 0.0965\n",
      "Epoch: 19/20... Training loss: 0.0911\n",
      "Epoch: 19/20... Training loss: 0.0924\n",
      "Epoch: 19/20... Training loss: 0.0925\n",
      "Epoch: 19/20... Training loss: 0.0931\n",
      "Epoch: 19/20... Training loss: 0.0936\n",
      "Epoch: 19/20... Training loss: 0.0900\n",
      "Epoch: 19/20... Training loss: 0.0925\n",
      "Epoch: 19/20... Training loss: 0.0932\n",
      "Epoch: 19/20... Training loss: 0.0954\n",
      "Epoch: 19/20... Training loss: 0.0949\n",
      "Epoch: 19/20... Training loss: 0.0968\n",
      "Epoch: 19/20... Training loss: 0.0910\n",
      "Epoch: 19/20... Training loss: 0.0936\n",
      "Epoch: 19/20... Training loss: 0.0927\n",
      "Epoch: 19/20... Training loss: 0.0915\n",
      "Epoch: 19/20... Training loss: 0.0912\n",
      "Epoch: 19/20... Training loss: 0.0988\n",
      "Epoch: 19/20... Training loss: 0.0946\n",
      "Epoch: 19/20... Training loss: 0.0942\n",
      "Epoch: 19/20... Training loss: 0.0959\n",
      "Epoch: 19/20... Training loss: 0.0911\n",
      "Epoch: 19/20... Training loss: 0.0949\n",
      "Epoch: 19/20... Training loss: 0.0924\n",
      "Epoch: 19/20... Training loss: 0.0903\n",
      "Epoch: 19/20... Training loss: 0.0935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/20... Training loss: 0.0981\n",
      "Epoch: 19/20... Training loss: 0.0938\n",
      "Epoch: 19/20... Training loss: 0.0946\n",
      "Epoch: 19/20... Training loss: 0.0964\n",
      "Epoch: 19/20... Training loss: 0.0897\n",
      "Epoch: 19/20... Training loss: 0.0917\n",
      "Epoch: 19/20... Training loss: 0.0933\n",
      "Epoch: 19/20... Training loss: 0.0942\n",
      "Epoch: 19/20... Training loss: 0.0981\n",
      "Epoch: 19/20... Training loss: 0.0929\n",
      "Epoch: 19/20... Training loss: 0.0871\n",
      "Epoch: 19/20... Training loss: 0.0957\n",
      "Epoch: 19/20... Training loss: 0.0948\n",
      "Epoch: 19/20... Training loss: 0.0908\n",
      "Epoch: 19/20... Training loss: 0.0944\n",
      "Epoch: 19/20... Training loss: 0.0949\n",
      "Epoch: 19/20... Training loss: 0.0933\n",
      "Epoch: 19/20... Training loss: 0.0947\n",
      "Epoch: 19/20... Training loss: 0.0888\n",
      "Epoch: 19/20... Training loss: 0.0990\n",
      "Epoch: 19/20... Training loss: 0.0930\n",
      "Epoch: 19/20... Training loss: 0.0953\n",
      "Epoch: 19/20... Training loss: 0.0984\n",
      "Epoch: 19/20... Training loss: 0.0921\n",
      "Epoch: 19/20... Training loss: 0.0937\n",
      "Epoch: 19/20... Training loss: 0.0945\n",
      "Epoch: 19/20... Training loss: 0.0912\n",
      "Epoch: 19/20... Training loss: 0.0969\n",
      "Epoch: 19/20... Training loss: 0.0951\n",
      "Epoch: 19/20... Training loss: 0.0936\n",
      "Epoch: 19/20... Training loss: 0.0947\n",
      "Epoch: 19/20... Training loss: 0.0915\n",
      "Epoch: 19/20... Training loss: 0.0945\n",
      "Epoch: 19/20... Training loss: 0.0941\n",
      "Epoch: 19/20... Training loss: 0.0929\n",
      "Epoch: 19/20... Training loss: 0.0898\n",
      "Epoch: 19/20... Training loss: 0.0922\n",
      "Epoch: 19/20... Training loss: 0.0904\n",
      "Epoch: 19/20... Training loss: 0.0941\n",
      "Epoch: 19/20... Training loss: 0.0947\n",
      "Epoch: 19/20... Training loss: 0.0939\n",
      "Epoch: 19/20... Training loss: 0.0901\n",
      "Epoch: 19/20... Training loss: 0.0973\n",
      "Epoch: 19/20... Training loss: 0.0931\n",
      "Epoch: 19/20... Training loss: 0.0930\n",
      "Epoch: 19/20... Training loss: 0.0903\n",
      "Epoch: 19/20... Training loss: 0.0948\n",
      "Epoch: 19/20... Training loss: 0.0946\n",
      "Epoch: 19/20... Training loss: 0.0917\n",
      "Epoch: 19/20... Training loss: 0.0948\n",
      "Epoch: 19/20... Training loss: 0.0936\n",
      "Epoch: 19/20... Training loss: 0.0943\n",
      "Epoch: 19/20... Training loss: 0.0896\n",
      "Epoch: 19/20... Training loss: 0.0904\n",
      "Epoch: 19/20... Training loss: 0.0936\n",
      "Epoch: 19/20... Training loss: 0.0951\n",
      "Epoch: 19/20... Training loss: 0.0926\n",
      "Epoch: 19/20... Training loss: 0.0918\n",
      "Epoch: 19/20... Training loss: 0.0963\n",
      "Epoch: 19/20... Training loss: 0.0905\n",
      "Epoch: 19/20... Training loss: 0.0892\n",
      "Epoch: 19/20... Training loss: 0.0935\n",
      "Epoch: 19/20... Training loss: 0.0954\n",
      "Epoch: 19/20... Training loss: 0.0910\n",
      "Epoch: 19/20... Training loss: 0.0935\n",
      "Epoch: 19/20... Training loss: 0.0902\n",
      "Epoch: 19/20... Training loss: 0.0932\n",
      "Epoch: 19/20... Training loss: 0.0902\n",
      "Epoch: 19/20... Training loss: 0.0940\n",
      "Epoch: 19/20... Training loss: 0.0919\n",
      "Epoch: 19/20... Training loss: 0.0933\n",
      "Epoch: 19/20... Training loss: 0.0953\n",
      "Epoch: 19/20... Training loss: 0.0933\n",
      "Epoch: 19/20... Training loss: 0.0923\n",
      "Epoch: 19/20... Training loss: 0.0955\n",
      "Epoch: 19/20... Training loss: 0.0921\n",
      "Epoch: 19/20... Training loss: 0.0970\n",
      "Epoch: 19/20... Training loss: 0.0932\n",
      "Epoch: 19/20... Training loss: 0.0938\n",
      "Epoch: 19/20... Training loss: 0.0896\n",
      "Epoch: 19/20... Training loss: 0.0911\n",
      "Epoch: 20/20... Training loss: 0.0922\n",
      "Epoch: 20/20... Training loss: 0.0953\n",
      "Epoch: 20/20... Training loss: 0.0955\n",
      "Epoch: 20/20... Training loss: 0.0906\n",
      "Epoch: 20/20... Training loss: 0.0932\n",
      "Epoch: 20/20... Training loss: 0.0917\n",
      "Epoch: 20/20... Training loss: 0.0933\n",
      "Epoch: 20/20... Training loss: 0.0926\n",
      "Epoch: 20/20... Training loss: 0.0907\n",
      "Epoch: 20/20... Training loss: 0.0933\n",
      "Epoch: 20/20... Training loss: 0.0886\n",
      "Epoch: 20/20... Training loss: 0.0932\n",
      "Epoch: 20/20... Training loss: 0.0951\n",
      "Epoch: 20/20... Training loss: 0.0939\n",
      "Epoch: 20/20... Training loss: 0.0946\n",
      "Epoch: 20/20... Training loss: 0.0928\n",
      "Epoch: 20/20... Training loss: 0.0937\n",
      "Epoch: 20/20... Training loss: 0.0922\n",
      "Epoch: 20/20... Training loss: 0.0927\n",
      "Epoch: 20/20... Training loss: 0.0926\n",
      "Epoch: 20/20... Training loss: 0.0959\n",
      "Epoch: 20/20... Training loss: 0.0961\n",
      "Epoch: 20/20... Training loss: 0.0936\n",
      "Epoch: 20/20... Training loss: 0.0940\n",
      "Epoch: 20/20... Training loss: 0.0916\n",
      "Epoch: 20/20... Training loss: 0.0931\n",
      "Epoch: 20/20... Training loss: 0.0964\n",
      "Epoch: 20/20... Training loss: 0.0921\n",
      "Epoch: 20/20... Training loss: 0.0916\n",
      "Epoch: 20/20... Training loss: 0.0927\n",
      "Epoch: 20/20... Training loss: 0.0915\n",
      "Epoch: 20/20... Training loss: 0.0937\n",
      "Epoch: 20/20... Training loss: 0.0954\n",
      "Epoch: 20/20... Training loss: 0.0980\n",
      "Epoch: 20/20... Training loss: 0.0930\n",
      "Epoch: 20/20... Training loss: 0.0929\n",
      "Epoch: 20/20... Training loss: 0.0946\n",
      "Epoch: 20/20... Training loss: 0.0935\n",
      "Epoch: 20/20... Training loss: 0.0930\n",
      "Epoch: 20/20... Training loss: 0.0982\n",
      "Epoch: 20/20... Training loss: 0.0932\n",
      "Epoch: 20/20... Training loss: 0.0924\n",
      "Epoch: 20/20... Training loss: 0.0953\n",
      "Epoch: 20/20... Training loss: 0.0963\n",
      "Epoch: 20/20... Training loss: 0.0919\n",
      "Epoch: 20/20... Training loss: 0.0900\n",
      "Epoch: 20/20... Training loss: 0.0937\n",
      "Epoch: 20/20... Training loss: 0.0919\n",
      "Epoch: 20/20... Training loss: 0.0927\n",
      "Epoch: 20/20... Training loss: 0.0939\n",
      "Epoch: 20/20... Training loss: 0.0958\n",
      "Epoch: 20/20... Training loss: 0.0943\n",
      "Epoch: 20/20... Training loss: 0.0915\n",
      "Epoch: 20/20... Training loss: 0.0931\n",
      "Epoch: 20/20... Training loss: 0.0948\n",
      "Epoch: 20/20... Training loss: 0.0943\n",
      "Epoch: 20/20... Training loss: 0.0907\n",
      "Epoch: 20/20... Training loss: 0.0899\n",
      "Epoch: 20/20... Training loss: 0.0969\n",
      "Epoch: 20/20... Training loss: 0.0896\n",
      "Epoch: 20/20... Training loss: 0.0957\n",
      "Epoch: 20/20... Training loss: 0.0964\n",
      "Epoch: 20/20... Training loss: 0.0932\n",
      "Epoch: 20/20... Training loss: 0.0957\n",
      "Epoch: 20/20... Training loss: 0.0924\n",
      "Epoch: 20/20... Training loss: 0.0984\n",
      "Epoch: 20/20... Training loss: 0.0935\n",
      "Epoch: 20/20... Training loss: 0.0946\n",
      "Epoch: 20/20... Training loss: 0.0943\n",
      "Epoch: 20/20... Training loss: 0.0902\n",
      "Epoch: 20/20... Training loss: 0.0915\n",
      "Epoch: 20/20... Training loss: 0.0924\n",
      "Epoch: 20/20... Training loss: 0.0933\n",
      "Epoch: 20/20... Training loss: 0.0959\n",
      "Epoch: 20/20... Training loss: 0.0956\n",
      "Epoch: 20/20... Training loss: 0.0919\n",
      "Epoch: 20/20... Training loss: 0.0934\n",
      "Epoch: 20/20... Training loss: 0.0942\n",
      "Epoch: 20/20... Training loss: 0.0943\n",
      "Epoch: 20/20... Training loss: 0.0935\n",
      "Epoch: 20/20... Training loss: 0.0937\n",
      "Epoch: 20/20... Training loss: 0.0915\n",
      "Epoch: 20/20... Training loss: 0.0919\n",
      "Epoch: 20/20... Training loss: 0.0926\n",
      "Epoch: 20/20... Training loss: 0.0952\n",
      "Epoch: 20/20... Training loss: 0.0916\n",
      "Epoch: 20/20... Training loss: 0.0952\n",
      "Epoch: 20/20... Training loss: 0.0950\n",
      "Epoch: 20/20... Training loss: 0.0959\n",
      "Epoch: 20/20... Training loss: 0.0910\n",
      "Epoch: 20/20... Training loss: 0.0895\n",
      "Epoch: 20/20... Training loss: 0.0886\n",
      "Epoch: 20/20... Training loss: 0.0959\n",
      "Epoch: 20/20... Training loss: 0.0897\n",
      "Epoch: 20/20... Training loss: 0.0940\n",
      "Epoch: 20/20... Training loss: 0.0973\n",
      "Epoch: 20/20... Training loss: 0.0924\n",
      "Epoch: 20/20... Training loss: 0.0934\n",
      "Epoch: 20/20... Training loss: 0.0922\n",
      "Epoch: 20/20... Training loss: 0.0910\n",
      "Epoch: 20/20... Training loss: 0.0908\n",
      "Epoch: 20/20... Training loss: 0.0937\n",
      "Epoch: 20/20... Training loss: 0.0899\n",
      "Epoch: 20/20... Training loss: 0.0924\n",
      "Epoch: 20/20... Training loss: 0.0926\n",
      "Epoch: 20/20... Training loss: 0.0927\n",
      "Epoch: 20/20... Training loss: 0.0924\n",
      "Epoch: 20/20... Training loss: 0.0951\n",
      "Epoch: 20/20... Training loss: 0.0966\n",
      "Epoch: 20/20... Training loss: 0.0955\n",
      "Epoch: 20/20... Training loss: 0.0941\n",
      "Epoch: 20/20... Training loss: 0.0951\n",
      "Epoch: 20/20... Training loss: 0.0896\n",
      "Epoch: 20/20... Training loss: 0.0964\n",
      "Epoch: 20/20... Training loss: 0.0926\n",
      "Epoch: 20/20... Training loss: 0.0929\n",
      "Epoch: 20/20... Training loss: 0.0912\n",
      "Epoch: 20/20... Training loss: 0.0941\n",
      "Epoch: 20/20... Training loss: 0.0964\n",
      "Epoch: 20/20... Training loss: 0.0928\n",
      "Epoch: 20/20... Training loss: 0.0935\n",
      "Epoch: 20/20... Training loss: 0.0890\n",
      "Epoch: 20/20... Training loss: 0.0961\n",
      "Epoch: 20/20... Training loss: 0.0930\n",
      "Epoch: 20/20... Training loss: 0.0943\n",
      "Epoch: 20/20... Training loss: 0.0937\n",
      "Epoch: 20/20... Training loss: 0.0930\n",
      "Epoch: 20/20... Training loss: 0.0937\n",
      "Epoch: 20/20... Training loss: 0.0942\n",
      "Epoch: 20/20... Training loss: 0.0902\n",
      "Epoch: 20/20... Training loss: 0.0907\n",
      "Epoch: 20/20... Training loss: 0.0949\n",
      "Epoch: 20/20... Training loss: 0.0942\n",
      "Epoch: 20/20... Training loss: 0.0958\n",
      "Epoch: 20/20... Training loss: 0.0942\n",
      "Epoch: 20/20... Training loss: 0.0945\n",
      "Epoch: 20/20... Training loss: 0.0934\n",
      "Epoch: 20/20... Training loss: 0.0939\n",
      "Epoch: 20/20... Training loss: 0.0916\n",
      "Epoch: 20/20... Training loss: 0.0982\n",
      "Epoch: 20/20... Training loss: 0.0919\n",
      "Epoch: 20/20... Training loss: 0.0909\n",
      "Epoch: 20/20... Training loss: 0.0904\n",
      "Epoch: 20/20... Training loss: 0.0933\n",
      "Epoch: 20/20... Training loss: 0.0926\n",
      "Epoch: 20/20... Training loss: 0.0963\n",
      "Epoch: 20/20... Training loss: 0.0931\n",
      "Epoch: 20/20... Training loss: 0.0932\n",
      "Epoch: 20/20... Training loss: 0.0929\n",
      "Epoch: 20/20... Training loss: 0.0890\n",
      "Epoch: 20/20... Training loss: 0.0941\n",
      "Epoch: 20/20... Training loss: 0.0930\n",
      "Epoch: 20/20... Training loss: 0.0961\n",
      "Epoch: 20/20... Training loss: 0.0965\n",
      "Epoch: 20/20... Training loss: 0.0923\n",
      "Epoch: 20/20... Training loss: 0.0940\n",
      "Epoch: 20/20... Training loss: 0.0885\n",
      "Epoch: 20/20... Training loss: 0.0945\n",
      "Epoch: 20/20... Training loss: 0.0900\n",
      "Epoch: 20/20... Training loss: 0.0942\n",
      "Epoch: 20/20... Training loss: 0.0925\n",
      "Epoch: 20/20... Training loss: 0.0916\n",
      "Epoch: 20/20... Training loss: 0.0949\n",
      "Epoch: 20/20... Training loss: 0.0922\n",
      "Epoch: 20/20... Training loss: 0.0919\n",
      "Epoch: 20/20... Training loss: 0.0926\n",
      "Epoch: 20/20... Training loss: 0.0923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/20... Training loss: 0.0964\n",
      "Epoch: 20/20... Training loss: 0.0965\n",
      "Epoch: 20/20... Training loss: 0.0916\n",
      "Epoch: 20/20... Training loss: 0.0914\n",
      "Epoch: 20/20... Training loss: 0.0931\n",
      "Epoch: 20/20... Training loss: 0.0959\n",
      "Epoch: 20/20... Training loss: 0.0918\n",
      "Epoch: 20/20... Training loss: 0.0922\n",
      "Epoch: 20/20... Training loss: 0.0961\n",
      "Epoch: 20/20... Training loss: 0.0914\n",
      "Epoch: 20/20... Training loss: 0.0965\n",
      "Epoch: 20/20... Training loss: 0.0945\n",
      "Epoch: 20/20... Training loss: 0.0929\n",
      "Epoch: 20/20... Training loss: 0.0919\n",
      "Epoch: 20/20... Training loss: 0.0912\n",
      "Epoch: 20/20... Training loss: 0.0918\n",
      "Epoch: 20/20... Training loss: 0.0911\n",
      "Epoch: 20/20... Training loss: 0.0917\n",
      "Epoch: 20/20... Training loss: 0.0960\n",
      "Epoch: 20/20... Training loss: 0.0946\n",
      "Epoch: 20/20... Training loss: 0.0941\n",
      "Epoch: 20/20... Training loss: 0.0976\n",
      "Epoch: 20/20... Training loss: 0.0937\n",
      "Epoch: 20/20... Training loss: 0.0944\n",
      "Epoch: 20/20... Training loss: 0.0928\n",
      "Epoch: 20/20... Training loss: 0.0937\n",
      "Epoch: 20/20... Training loss: 0.0933\n",
      "Epoch: 20/20... Training loss: 0.0902\n",
      "Epoch: 20/20... Training loss: 0.0907\n",
      "Epoch: 20/20... Training loss: 0.0926\n",
      "Epoch: 20/20... Training loss: 0.0934\n",
      "Epoch: 20/20... Training loss: 0.0922\n",
      "Epoch: 20/20... Training loss: 0.0960\n",
      "Epoch: 20/20... Training loss: 0.0933\n",
      "Epoch: 20/20... Training loss: 0.0976\n",
      "Epoch: 20/20... Training loss: 0.0937\n",
      "Epoch: 20/20... Training loss: 0.0909\n",
      "Epoch: 20/20... Training loss: 0.0972\n",
      "Epoch: 20/20... Training loss: 0.0947\n",
      "Epoch: 20/20... Training loss: 0.0918\n",
      "Epoch: 20/20... Training loss: 0.0941\n",
      "Epoch: 20/20... Training loss: 0.0967\n",
      "Epoch: 20/20... Training loss: 0.0926\n",
      "Epoch: 20/20... Training loss: 0.0953\n",
      "Epoch: 20/20... Training loss: 0.0951\n",
      "Epoch: 20/20... Training loss: 0.0934\n",
      "Epoch: 20/20... Training loss: 0.0940\n",
      "Epoch: 20/20... Training loss: 0.0966\n",
      "Epoch: 20/20... Training loss: 0.0932\n",
      "Epoch: 20/20... Training loss: 0.0920\n",
      "Epoch: 20/20... Training loss: 0.0926\n",
      "Epoch: 20/20... Training loss: 0.0919\n",
      "Epoch: 20/20... Training loss: 0.0954\n",
      "Epoch: 20/20... Training loss: 0.0940\n",
      "Epoch: 20/20... Training loss: 0.0947\n",
      "Epoch: 20/20... Training loss: 0.0940\n",
      "Epoch: 20/20... Training loss: 0.0948\n",
      "Epoch: 20/20... Training loss: 0.0936\n",
      "Epoch: 20/20... Training loss: 0.0914\n",
      "Epoch: 20/20... Training loss: 0.0967\n",
      "Epoch: 20/20... Training loss: 0.0946\n",
      "Epoch: 20/20... Training loss: 0.0929\n",
      "Epoch: 20/20... Training loss: 0.0928\n",
      "Epoch: 20/20... Training loss: 0.0942\n",
      "Epoch: 20/20... Training loss: 0.0955\n",
      "Epoch: 20/20... Training loss: 0.0927\n",
      "Epoch: 20/20... Training loss: 0.0954\n",
      "Epoch: 20/20... Training loss: 0.0956\n",
      "Epoch: 20/20... Training loss: 0.0923\n",
      "Epoch: 20/20... Training loss: 0.0938\n",
      "Epoch: 20/20... Training loss: 0.0912\n",
      "Epoch: 20/20... Training loss: 0.0922\n",
      "Epoch: 20/20... Training loss: 0.0933\n",
      "Epoch: 20/20... Training loss: 0.0945\n",
      "Epoch: 20/20... Training loss: 0.0909\n",
      "Epoch: 20/20... Training loss: 0.0935\n",
      "Epoch: 20/20... Training loss: 0.0918\n",
      "Epoch: 20/20... Training loss: 0.0900\n",
      "Epoch: 20/20... Training loss: 0.0937\n",
      "Epoch: 20/20... Training loss: 0.0913\n",
      "Epoch: 20/20... Training loss: 0.0941\n",
      "Epoch: 20/20... Training loss: 0.0916\n",
      "Epoch: 20/20... Training loss: 0.0920\n",
      "Epoch: 20/20... Training loss: 0.0936\n",
      "Epoch: 20/20... Training loss: 0.0909\n",
      "Epoch: 20/20... Training loss: 0.0952\n",
      "Epoch: 20/20... Training loss: 0.0931\n",
      "Epoch: 20/20... Training loss: 0.0902\n",
      "Epoch: 20/20... Training loss: 0.0920\n",
      "Epoch: 20/20... Training loss: 0.0926\n",
      "Epoch: 20/20... Training loss: 0.0930\n",
      "Epoch: 20/20... Training loss: 0.0908\n",
      "Epoch: 20/20... Training loss: 0.0930\n",
      "Epoch: 20/20... Training loss: 0.0910\n",
      "Epoch: 20/20... Training loss: 0.0918\n",
      "Epoch: 20/20... Training loss: 0.0926\n",
      "Epoch: 20/20... Training loss: 0.0962\n",
      "Epoch: 20/20... Training loss: 0.0936\n",
      "Epoch: 20/20... Training loss: 0.0918\n",
      "Epoch: 20/20... Training loss: 0.0973\n",
      "Epoch: 20/20... Training loss: 0.0940\n",
      "Epoch: 20/20... Training loss: 0.0946\n",
      "Epoch: 20/20... Training loss: 0.0935\n",
      "Epoch: 20/20... Training loss: 0.0948\n",
      "Epoch: 20/20... Training loss: 0.0952\n",
      "Epoch: 20/20... Training loss: 0.0952\n",
      "Epoch: 20/20... Training loss: 0.0949\n",
      "Epoch: 20/20... Training loss: 0.0945\n",
      "Epoch: 20/20... Training loss: 0.0959\n",
      "Epoch: 20/20... Training loss: 0.0959\n",
      "Epoch: 20/20... Training loss: 0.0930\n",
      "Epoch: 20/20... Training loss: 0.0894\n",
      "Epoch: 20/20... Training loss: 0.0925\n",
      "Epoch: 20/20... Training loss: 0.0938\n",
      "Epoch: 20/20... Training loss: 0.0928\n",
      "Epoch: 20/20... Training loss: 0.0924\n",
      "Epoch: 20/20... Training loss: 0.0946\n",
      "Epoch: 20/20... Training loss: 0.0938\n",
      "Epoch: 20/20... Training loss: 0.0914\n",
      "Epoch: 20/20... Training loss: 0.0943\n",
      "Epoch: 20/20... Training loss: 0.0921\n",
      "Epoch: 20/20... Training loss: 0.0936\n",
      "Epoch: 20/20... Training loss: 0.0972\n",
      "Epoch: 20/20... Training loss: 0.0940\n",
      "Epoch: 20/20... Training loss: 0.0956\n",
      "Epoch: 20/20... Training loss: 0.0923\n",
      "Epoch: 20/20... Training loss: 0.0959\n",
      "Epoch: 20/20... Training loss: 0.0924\n",
      "Epoch: 20/20... Training loss: 0.0936\n",
      "Epoch: 20/20... Training loss: 0.0928\n",
      "Epoch: 20/20... Training loss: 0.0904\n",
      "Epoch: 20/20... Training loss: 0.0912\n",
      "Epoch: 20/20... Training loss: 0.0917\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 200\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for e in range(epochs):\n",
    "    for ii in range(mnist.train.num_examples//batch_size):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        feed = {inputs_: batch[0], targets_: batch[0]}\n",
    "        batch_cost, _ = sess.run([cost, opt], feed_dict=feed)\n",
    "\n",
    "        print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "              \"Training loss: {:.4f}\".format(batch_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking out the results\n",
    "\n",
    "Below I've plotted some of the test images along with their reconstructions. For the most part these look pretty good except for some blurriness in some parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABawAAAEsCAYAAAAvofT2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAEAksGANAAAAAAAAAIiE/w+CvV5FRMHKVAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29c55b75400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(20,4))\n",
    "in_imgs = mnist.test.images[:10]\n",
    "reconstructed, compressed = sess.run([decoded, encoded], feed_dict={inputs_: in_imgs})\n",
    "\n",
    "for images, row in zip([in_imgs, reconstructed], axes):\n",
    "    for img, ax in zip(images, row):\n",
    "        ax.imshow(img.reshape((28, 28)), cmap='Greys_r')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "fig.tight_layout(pad=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Up Next\n",
    "\n",
    "We're dealing with images here, so we can (usually) get better performance using convolution layers. So, next we'll build a better autoencoder with convolutional layers.\n",
    "\n",
    "In practice, autoencoders aren't actually better at compression compared to typical methods like JPEGs and MP3s. But, they are being used for noise reduction, which you'll also build."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
